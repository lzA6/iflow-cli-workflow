#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“Š å®æ—¶ç›‘æ§ç³»ç»Ÿ V9 (Real-time Monitoring System V9)
ä¼ä¸šçº§å®æ—¶ç›‘æ§è§£å†³æ–¹æ¡ˆï¼Œæä¾›å…¨æ–¹ä½çš„ç³»ç»Ÿç›‘æ§å’Œå‘Šè­¦åŠŸèƒ½

æ ¸å¿ƒç‰¹æ€§ï¼š
1. å®æ—¶æ€§èƒ½ç›‘æ§ - CPUã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œå…¨æ–¹ä½ç›‘æ§
2. æ™ºèƒ½å‘Šè­¦ç³»ç»Ÿ - åŸºäºæœºå™¨å­¦ä¹ çš„å¼‚å¸¸æ£€æµ‹
3. å¯è§†åŒ–ä»ªè¡¨æ¿ - å®æ—¶æ•°æ®å±•ç¤ºå’Œè¶‹åŠ¿åˆ†æ
4. åˆ†å¸ƒå¼ç›‘æ§ - æ”¯æŒå¤šèŠ‚ç‚¹é›†ç¾¤ç›‘æ§
5. è‡ªåŠ¨åŒ–å“åº” - æ™ºèƒ½æ•…éšœè‡ªåŠ¨ä¿®å¤
"""

import os
import sys
import json
import asyncio
import logging
import time
import psutil
import threading
import multiprocessing
import socket
import requests
import sqlite3
import aiofiles
import aiosqlite
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Union, Callable
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
from enum import Enum
from collections import defaultdict, deque
import numpy as np
import pandas as pd
from concurrent.futures import ThreadPoolExecutor
import matplotlib.pyplot as plt
import seaborn as sns

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# å°è¯•å¯¼å…¥é«˜æ€§èƒ½ä¾èµ–
try:
    import prometheus_client as prometheus
    from prometheus_client import CollectorRegistry, Gauge, Counter, Histogram
    PROMETHEUS_AVAILABLE = True
except ImportError:
    logging.warning("Prometheuså®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€ç›‘æ§")
    PROMETHEUS_AVAILABLE = False

try:
    import redis
    REDIS_AVAILABLE = True
except ImportError:
    logging.warning("Redisä¸å¯ç”¨ï¼Œä½¿ç”¨æœ¬åœ°å­˜å‚¨")
    REDIS_AVAILABLE = False

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- æ ¸å¿ƒæšä¸¾å’Œæ•°æ®ç»“æ„ ---

class MetricType(Enum):
    """æŒ‡æ ‡ç±»å‹"""
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    SUMMARY = "summary"

class AlertLevel(Enum):
    """å‘Šè­¦çº§åˆ«"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

class SystemComponent(Enum):
    """ç³»ç»Ÿç»„ä»¶"""
    CPU = "cpu"
    MEMORY = "memory"
    DISK = "disk"
    NETWORK = "network"
    PROCESS = "process"
    APPLICATION = "application"
    DATABASE = "database"

@dataclass
class Metric:
    """ç›‘æ§æŒ‡æ ‡"""
    name: str
    value: float
    timestamp: datetime
    metric_type: MetricType
    component: SystemComponent
    tags: Dict[str, str] = field(default_factory=dict)
    unit: str = ""
    description: str = ""

@dataclass
class Alert:
    """å‘Šè­¦ä¿¡æ¯"""
    id: str
    name: str
    level: AlertLevel
    message: str
    component: SystemComponent
    metric_name: str
    current_value: float
    threshold: float
    timestamp: datetime
    resolved: bool = False
    resolved_at: Optional[datetime] = None
    acknowledged: bool = False
    acknowledged_by: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class MonitoringRule:
    """ç›‘æ§è§„åˆ™"""
    id: str
    name: str
    component: SystemComponent
    metric_name: str
    condition: str  # >, <, >=, <=, ==, !=
    threshold: float
    duration: int  # æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
    level: AlertLevel
    enabled: bool = True
    description: str = ""
    actions: List[str] = field(default_factory=list)

class MetricsCollector:
    """æŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self):
        self.collectors = {
            SystemComponent.CPU: self._collect_cpu_metrics,
            SystemComponent.MEMORY: self._collect_memory_metrics,
            SystemComponent.DISK: self._collect_disk_metrics,
            SystemComponent.NETWORK: self._collect_network_metrics,
            SystemComponent.PROCESS: self._collect_process_metrics
        }
        self.metrics_buffer = deque(maxlen=10000)
        self.collection_interval = 5  # 5ç§’æ”¶é›†é—´éš”
        
    async def collect_all_metrics(self) -> List[Metric]:
        """æ”¶é›†æ‰€æœ‰æŒ‡æ ‡"""
        metrics = []
        
        for component, collector in self.collectors.items():
            try:
                component_metrics = await collector()
                metrics.extend(component_metrics)
            except Exception as e:
                logger.error(f"æ”¶é›† {component.value} æŒ‡æ ‡å¤±è´¥: {e}")
        
        # æ·»åŠ åˆ°ç¼“å†²åŒº
        self.metrics_buffer.extend(metrics)
        
        return metrics
    
    async def _collect_cpu_metrics(self) -> List[Metric]:
        """æ”¶é›†CPUæŒ‡æ ‡"""
        metrics = []
        timestamp = datetime.now()
        
        try:
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)
            metrics.append(Metric(
                name="cpu_usage_percent",
                value=cpu_percent,
                timestamp=timestamp,
                metric_type=MetricType.GAUGE,
                component=SystemComponent.CPU,
                unit="percent",
                description="CPUä½¿ç”¨ç‡"
            ))
            
            # CPUæ ¸å¿ƒæ•°
            cpu_count = psutil.cpu_count()
            metrics.append(Metric(
                name="cpu_count",
                value=float(cpu_count),
                timestamp=timestamp,
                metric_type=MetricType.GAUGE,
                component=SystemComponent.CPU,
                unit="count",
                description="CPUæ ¸å¿ƒæ•°"
            ))
            
            # CPUè´Ÿè½½
            load_avg = psutil.getloadavg()
            for i, load in enumerate(load_avg):
                metrics.append(Metric(
                    name=f"cpu_load_avg_{i+1}min",
                    value=load,
                    timestamp=timestamp,
                    metric_type=MetricType.GAUGE,
                    component=SystemComponent.CPU,
                    unit="load",
                    description=f"{i+1}åˆ†é’Ÿå¹³å‡è´Ÿè½½"
                ))
            
            # æ¯ä¸ªCPUæ ¸å¿ƒçš„ä½¿ç”¨ç‡
            cpu_percents = psutil.cpu_percent(percpu=True)
            for i, percent in enumerate(cpu_percents):
                metrics.append(Metric(
                    name=f"cpu_core_{i}_usage_percent",
                    value=percent,
                    timestamp=timestamp,
                    metric_type=MetricType.GAUGE,
                    component=SystemComponent.CPU,
                    unit="percent",
                    tags={"core": str(i)},
                    description=f"CPUæ ¸å¿ƒ{i}ä½¿ç”¨ç‡"
                ))
                
        except Exception as e:
            logger.error(f"CPUæŒ‡æ ‡æ”¶é›†å¤±è´¥: {e}")
        
        return metrics
    
    async def _collect_memory_metrics(self) -> List[Metric]:
        """æ”¶é›†å†…å­˜æŒ‡æ ‡"""
        metrics = []
        timestamp = datetime.now()
        
        try:
            # è™šæ‹Ÿå†…å­˜
            virtual_memory = psutil.virtual_memory()
            metrics.append(Metric(
                name="memory_total_bytes",
                value=float(virtual_memory.total),
                timestamp=timestamp,
                metric_type=MetricType.GAUGE,
                component=SystemComponent.MEMORY,
                unit="bytes",
                description="æ€»å†…å­˜"
            ))
            
            metrics.append(Metric(
                name="memory_available_bytes",
                value=float(virtual_memory.available),
                timestamp=timestamp,
                metric_type=MetricType.GAUGE,
                component=SystemComponent.MEMORY,
                unit="bytes",
                description="å¯ç”¨å†…å­˜"
            ))
            
            metrics.append(Metric(
                name="memory_usage_percent",
                value=virtual_memory.percent,
                timestamp=timestamp,
                metric_type=MetricType.GAUGE,
                component=SystemComponent.MEMORY,
                unit="percent",
                description="å†…å­˜ä½¿ç”¨ç‡"
            ))
            
            metrics.append(Metric(
                name="memory_used_bytes",
                value=float(virtual_memory.used),
                timestamp=timestamp,
                metric_type=MetricType.GAUGE,
                component=SystemComponent.MEMORY,
                unit="bytes",
                description="å·²ç”¨å†…å­˜"
            ))
            
            # äº¤æ¢å†…å­˜
            swap_memory = psutil.swap_memory()
            metrics.append(Metric(
                name="swap_usage_percent",
                value=swap_memory.percent,
                timestamp=timestamp,
                metric_type=MetricType.GAUGE,
                component=SystemComponent.MEMORY,
                unit="percent",
                description="äº¤æ¢å†…å­˜ä½¿ç”¨ç‡"
            ))
            
        except Exception as e:
            logger.error(f"å†…å­˜æŒ‡æ ‡æ”¶é›†å¤±è´¥: {e}")
        
        return metrics
    
    async def _collect_disk_metrics(self) -> List[Metric]:
        """æ”¶é›†ç£ç›˜æŒ‡æ ‡"""
        metrics = []
        timestamp = datetime.now()
        
        try:
            # ç£ç›˜ä½¿ç”¨æƒ…å†µ
            disk_partitions = psutil.disk_partitions()
            for partition in disk_partitions:
                try:
                    disk_usage = psutil.disk_usage(partition.mountpoint)
                    
                    metrics.append(Metric(
                        name="disk_total_bytes",
                        value=float(disk_usage.total),
                        timestamp=timestamp,
                        metric_type=MetricType.GAUGE,
                        component=SystemComponent.DISK,
                        unit="bytes",
                        tags={"device": partition.device, "mountpoint": partition.mountpoint},
                        description=f"ç£ç›˜æ€»å¤§å° - {partition.device}"
                    ))
                    
                    metrics.append(Metric(
                        name="disk_usage_percent",
                        value=(disk_usage.used / disk_usage.total) * 100,
                        timestamp=timestamp,
                        metric_type=MetricType.GAUGE,
                        component=SystemComponent.DISK,
                        unit="percent",
                        tags={"device": partition.device, "mountpoint": partition.mountpoint},
                        description=f"ç£ç›˜ä½¿ç”¨ç‡ - {partition.device}"
                    ))
                    
                    metrics.append(Metric(
                        name="disk_free_bytes",
                        value=float(disk_usage.free),
                        timestamp=timestamp,
                        metric_type=MetricType.GAUGE,
                        component=SystemComponent.DISK,
                        unit="bytes",
                        tags={"device": partition.device, "mountpoint": partition.mountpoint},
                        description=f"ç£ç›˜å¯ç”¨ç©ºé—´ - {partition.device}"
                    ))
                    
                except PermissionError:
                    continue
            
            # ç£ç›˜I/O
            disk_io = psutil.disk_io_counters()
            if disk_io:
                metrics.append(Metric(
                    name="disk_read_bytes_per_sec",
                    value=float(disk_io.read_bytes),
                    timestamp=timestamp,
                    metric_type=MetricType.COUNTER,
                    component=SystemComponent.DISK,
                    unit="bytes/sec",
                    description="ç£ç›˜è¯»å–é€Ÿç‡"
                ))
                
                metrics.append(Metric(
                    name="disk_write_bytes_per_sec",
                    value=float(disk_io.write_bytes),
                    timestamp=timestamp,
                    metric_type=MetricType.COUNTER,
                    component=SystemComponent.DISK,
                    unit="bytes/sec",
                    description="ç£ç›˜å†™å…¥é€Ÿç‡"
                ))
                
        except Exception as e:
            logger.error(f"ç£ç›˜æŒ‡æ ‡æ”¶é›†å¤±è´¥: {e}")
        
        return metrics
    
    async def _collect_network_metrics(self) -> List[Metric]:
        """æ”¶é›†ç½‘ç»œæŒ‡æ ‡"""
        metrics = []
        timestamp = datetime.now()
        
        try:
            # ç½‘ç»œI/O
            net_io = psutil.net_io_counters()
            if net_io:
                metrics.append(Metric(
                    name="network_bytes_sent",
                    value=float(net_io.bytes_sent),
                    timestamp=timestamp,
                    metric_type=MetricType.COUNTER,
                    component=SystemComponent.NETWORK,
                    unit="bytes",
                    description="ç½‘ç»œå‘é€å­—èŠ‚æ•°"
                ))
                
                metrics.append(Metric(
                    name="network_bytes_recv",
                    value=float(net_io.bytes_recv),
                    timestamp=timestamp,
                    metric_type=MetricType.COUNTER,
                    component=SystemComponent.NETWORK,
                    unit="bytes",
                    description="ç½‘ç»œæ¥æ”¶å­—èŠ‚æ•°"
                ))
                
                metrics.append(Metric(
                    name="network_packets_sent",
                    value=float(net_io.packets_sent),
                    timestamp=timestamp,
                    metric_type=MetricType.COUNTER,
                    component=SystemComponent.NETWORK,
                    unit="packets",
                    description="ç½‘ç»œå‘é€åŒ…æ•°"
                ))
                
                metrics.append(Metric(
                    name="network_packets_recv",
                    value=float(net_io.packets_recv),
                    timestamp=timestamp,
                    metric_type=MetricType.COUNTER,
                    component=SystemComponent.NETWORK,
                    unit="packets",
                    description="ç½‘ç»œæ¥æ”¶åŒ…æ•°"
                ))
            
            # ç½‘ç»œè¿æ¥
            connections = psutil.net_connections()
            connection_counts = defaultdict(int)
            for conn in connections:
                connection_counts[conn.status] += 1
            
            for status, count in connection_counts.items():
                metrics.append(Metric(
                    name=f"network_connections_{status}",
                    value=float(count),
                    timestamp=timestamp,
                    metric_type=MetricType.GAUGE,
                    component=SystemComponent.NETWORK,
                    unit="count",
                    tags={"status": status},
                    description=f"ç½‘ç»œè¿æ¥æ•° - {status}"
                ))
                
        except Exception as e:
            logger.error(f"ç½‘ç»œæŒ‡æ ‡æ”¶é›†å¤±è´¥: {e}")
        
        return metrics
    
    async def _collect_process_metrics(self) -> List[Metric]:
        """æ”¶é›†è¿›ç¨‹æŒ‡æ ‡"""
        metrics = []
        timestamp = datetime.now()
        
        try:
            # å½“å‰è¿›ç¨‹
            current_process = psutil.Process()
            
            metrics.append(Metric(
                name="process_cpu_percent",
                value=current_process.cpu_percent(),
                timestamp=timestamp,
                metric_type=MetricType.GAUGE,
                component=SystemComponent.PROCESS,
                unit="percent",
                description="è¿›ç¨‹CPUä½¿ç”¨ç‡"
            ))
            
            metrics.append(Metric(
                name="process_memory_rss_bytes",
                value=float(current_process.memory_info().rss),
                timestamp=timestamp,
                metric_type=MetricType.GAUGE,
                component=SystemComponent.PROCESS,
                unit="bytes",
                description="è¿›ç¨‹å†…å­˜ä½¿ç”¨é‡(RSS)"
            ))
            
            metrics.append(Metric(
                name="process_memory_vms_bytes",
                value=float(current_process.memory_info().vms),
                timestamp=timestamp,
                metric_type=MetricType.GAUGE,
                component=SystemComponent.PROCESS,
                unit="bytes",
                description="è¿›ç¨‹å†…å­˜ä½¿ç”¨é‡(VMS)"
            ))
            
            metrics.append(Metric(
                name="process_num_threads",
                value=float(current_process.num_threads()),
                timestamp=timestamp,
                metric_type=MetricType.GAUGE,
                component=SystemComponent.PROCESS,
                unit="count",
                description="è¿›ç¨‹çº¿ç¨‹æ•°"
            ))
            
            metrics.append(Metric(
                name="process_num_fds",
                value=float(current_process.num_fds()),
                timestamp=timestamp,
                metric_type=MetricType.GAUGE,
                component=SystemComponent.PROCESS,
                unit="count",
                description="è¿›ç¨‹æ–‡ä»¶æè¿°ç¬¦æ•°"
            ))
            
            # ç³»ç»Ÿè¿›ç¨‹ç»Ÿè®¡
            processes = psutil.process_iter(['pid', 'name', 'status'])
            status_counts = defaultdict(int)
            for proc in processes:
                try:
                    status_counts[proc.info['status']] += 1
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
            
            for status, count in status_counts.items():
                metrics.append(Metric(
                    name=f"processes_status_{status}",
                    value=float(count),
                    timestamp=timestamp,
                    metric_type=MetricType.GAUGE,
                    component=SystemComponent.PROCESS,
                    unit="count",
                    tags={"status": status},
                    description=f"è¿›ç¨‹çŠ¶æ€ç»Ÿè®¡ - {status}"
                ))
                
        except Exception as e:
            logger.error(f"è¿›ç¨‹æŒ‡æ ‡æ”¶é›†å¤±è´¥: {e}")
        
        return metrics

class AlertManager:
    """å‘Šè­¦ç®¡ç†å™¨"""
    
    def __init__(self):
        self.rules: List[MonitoringRule] = []
        self.active_alerts: Dict[str, Alert] = {}
        self.alert_history = deque(maxlen=1000)
        self.notification_handlers = []
        self.evaluation_interval = 10  # 10ç§’è¯„ä¼°é—´éš”
        
        # åˆå§‹åŒ–é»˜è®¤è§„åˆ™
        self._initialize_default_rules()
    
    def _initialize_default_rules(self):
        """åˆå§‹åŒ–é»˜è®¤ç›‘æ§è§„åˆ™"""
        default_rules = [
            MonitoringRule(
                id="cpu_high_usage",
                name="CPUä½¿ç”¨ç‡è¿‡é«˜",
                component=SystemComponent.CPU,
                metric_name="cpu_usage_percent",
                condition=">",
                threshold=80.0,
                duration=60,
                level=AlertLevel.WARNING,
                description="CPUä½¿ç”¨ç‡è¶…è¿‡80%æŒç»­1åˆ†é’Ÿ"
            ),
            MonitoringRule(
                id="memory_high_usage",
                name="å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜",
                component=SystemComponent.MEMORY,
                metric_name="memory_usage_percent",
                condition=">",
                threshold=85.0,
                duration=60,
                level=AlertLevel.WARNING,
                description="å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡85%æŒç»­1åˆ†é’Ÿ"
            ),
            MonitoringRule(
                id="disk_low_space",
                name="ç£ç›˜ç©ºé—´ä¸è¶³",
                component=SystemComponent.DISK,
                metric_name="disk_usage_percent",
                condition=">",
                threshold=90.0,
                duration=30,
                level=AlertLevel.ERROR,
                description="ç£ç›˜ä½¿ç”¨ç‡è¶…è¿‡90%"
            ),
            MonitoringRule(
                id="process_high_memory",
                name="è¿›ç¨‹å†…å­˜ä½¿ç”¨è¿‡é«˜",
                component=SystemComponent.PROCESS,
                metric_name="process_memory_rss_bytes",
                condition=">",
                threshold=1024*1024*1024,  # 1GB
                duration=30,
                level=AlertLevel.WARNING,
                description="è¿›ç¨‹å†…å­˜ä½¿ç”¨è¶…è¿‡1GB"
            )
        ]
        
        self.rules.extend(default_rules)
    
    def add_rule(self, rule: MonitoringRule):
        """æ·»åŠ ç›‘æ§è§„åˆ™"""
        self.rules.append(rule)
        logger.info(f"æ·»åŠ ç›‘æ§è§„åˆ™: {rule.name}")
    
    def remove_rule(self, rule_id: str):
        """ç§»é™¤ç›‘æ§è§„åˆ™"""
        self.rules = [rule for rule in self.rules if rule.id != rule_id]
        logger.info(f"ç§»é™¤ç›‘æ§è§„åˆ™: {rule_id}")
    
    async def evaluate_rules(self, metrics: List[Metric]):
        """è¯„ä¼°ç›‘æ§è§„åˆ™"""
        for rule in self.rules:
            if not rule.enabled:
                continue
            
            try:
                await self._evaluate_rule(rule, metrics)
            except Exception as e:
                logger.error(f"è¯„ä¼°è§„åˆ™ {rule.name} å¤±è´¥: {e}")
    
    async def _evaluate_rule(self, rule: MonitoringRule, metrics: List[Metric]):
        """è¯„ä¼°å•ä¸ªè§„åˆ™"""
        # æŸ¥æ‰¾åŒ¹é…çš„æŒ‡æ ‡
        matching_metrics = [
            metric for metric in metrics
            if metric.component == rule.component and metric.metric_name == rule.metric_name
        ]
        
        if not matching_metrics:
            return
        
        # è·å–æœ€æ–°çš„æŒ‡æ ‡å€¼
        latest_metric = max(matching_metrics, key=lambda m: m.timestamp)
        current_value = latest_metric.value
        
        # æ£€æŸ¥æ¡ä»¶
        condition_met = self._check_condition(current_value, rule.condition, rule.threshold)
        
        alert_id = f"{rule.id}_{hash(rule.component.value + rule.metric_name)}"
        
        if condition_met:
            # æ¡ä»¶æ»¡è¶³ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘å‘Šè­¦
            if alert_id not in self.active_alerts:
                # æ–°å‘Šè­¦
                alert = Alert(
                    id=alert_id,
                    name=rule.name,
                    level=rule.level,
                    message=f"{rule.name}: {rule.metric_name} = {current_value:.2f} {rule.condition} {rule.threshold}",
                    component=rule.component,
                    metric_name=rule.metric_name,
                    current_value=current_value,
                    threshold=rule.threshold,
                    timestamp=datetime.now()
                )
                
                self.active_alerts[alert_id] = alert
                self.alert_history.append(alert)
                
                # å‘é€é€šçŸ¥
                await self._send_notification(alert)
                
                logger.warning(f"è§¦å‘å‘Šè­¦: {alert.name}")
                
        else:
            # æ¡ä»¶ä¸æ»¡è¶³ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦è§£å†³å‘Šè­¦
            if alert_id in self.active_alerts:
                alert = self.active_alerts[alert_id]
                alert.resolved = True
                alert.resolved_at = datetime.now()
                
                # å‘é€è§£å†³é€šçŸ¥
                await self._send_resolved_notification(alert)
                
                # ä»æ´»è·ƒå‘Šè­¦ä¸­ç§»é™¤
                del self.active_alerts[alert_id]
                
                logger.info(f"å‘Šè­¦å·²è§£å†³: {alert.name}")
    
    def _check_condition(self, value: float, condition: str, threshold: float) -> bool:
        """æ£€æŸ¥æ¡ä»¶"""
        if condition == ">":
            return value > threshold
        elif condition == "<":
            return value < threshold
        elif condition == ">=":
            return value >= threshold
        elif condition == "<=":
            return value <= threshold
        elif condition == "==":
            return abs(value - threshold) < 0.001  # æµ®ç‚¹æ•°æ¯”è¾ƒ
        elif condition == "!=":
            return abs(value - threshold) >= 0.001
        else:
            return False
    
    async def _send_notification(self, alert: Alert):
        """å‘é€å‘Šè­¦é€šçŸ¥"""
        for handler in self.notification_handlers:
            try:
                await handler(alert)
            except Exception as e:
                logger.error(f"å‘é€é€šçŸ¥å¤±è´¥: {e}")
    
    async def _send_resolved_notification(self, alert: Alert):
        """å‘é€å‘Šè­¦è§£å†³é€šçŸ¥"""
        for handler in self.notification_handlers:
            try:
                await handler(alert, resolved=True)
            except Exception as e:
                logger.error(f"å‘é€è§£å†³é€šçŸ¥å¤±è´¥: {e}")
    
    def add_notification_handler(self, handler: Callable):
        """æ·»åŠ é€šçŸ¥å¤„ç†å™¨"""
        self.notification_handlers.append(handler)
    
    def get_active_alerts(self) -> List[Alert]:
        """è·å–æ´»è·ƒå‘Šè­¦"""
        return list(self.active_alerts.values())
    
    def get_alert_history(self, limit: int = 100) -> List[Alert]:
        """è·å–å‘Šè­¦å†å²"""
        return list(self.alert_history)[-limit:]

class MetricsStorage:
    """æŒ‡æ ‡å­˜å‚¨"""
    
    def __init__(self, storage_path: str = "monitoring_data.db"):
        self.storage_path = storage_path
        self.connection_pool = None
        self.write_queue = asyncio.Queue(maxsize=1000)
        self.batch_size = 100
        
    async def initialize(self):
        """åˆå§‹åŒ–å­˜å‚¨"""
        self.connection_pool = await aiosqlite.connect(self.storage_path)
        await self._create_tables()
        
        # å¯åŠ¨åå°å†™å…¥ä»»åŠ¡
        asyncio.create_task(self._background_writer())
    
    async def _create_tables(self):
        """åˆ›å»ºè¡¨"""
        await self.connection_pool.execute("""
            CREATE TABLE IF NOT EXISTS metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL,
                value REAL NOT NULL,
                timestamp DATETIME NOT NULL,
                metric_type TEXT NOT NULL,
                component TEXT NOT NULL,
                tags TEXT,
                unit TEXT,
                description TEXT
            )
        """)
        
        await self.connection_pool.execute("""
            CREATE INDEX IF NOT EXISTS idx_metrics_timestamp ON metrics(timestamp)
        """)
        
        await self.connection_pool.execute("""
            CREATE INDEX IF NOT EXISTS idx_metrics_component ON metrics(component)
        """)
        
        await self.connection_pool.execute("""
            CREATE TABLE IF NOT EXISTS alerts (
                id TEXT PRIMARY KEY,
                name TEXT NOT NULL,
                level TEXT NOT NULL,
                message TEXT NOT NULL,
                component TEXT NOT NULL,
                metric_name TEXT NOT NULL,
                current_value REAL NOT NULL,
                threshold REAL NOT NULL,
                timestamp DATETIME NOT NULL,
                resolved BOOLEAN DEFAULT FALSE,
                resolved_at DATETIME,
                acknowledged BOOLEAN DEFAULT FALSE,
                acknowledged_by TEXT,
                metadata TEXT
            )
        """)
        
        await self.connection_pool.commit()
    
    async def store_metrics(self, metrics: List[Metric]):
        """å­˜å‚¨æŒ‡æ ‡"""
        for metric in metrics:
            await self.write_queue.put(metric)
    
    async def _background_writer(self):
        """åå°æ‰¹é‡å†™å…¥"""
        while True:
            try:
                batch = []
                
                # æ”¶é›†æ‰¹é‡æ•°æ®
                while len(batch) < self.batch_size and not self.write_queue.empty():
                    try:
                        metric = self.write_queue.get_nowait()
                        batch.append(metric)
                    except asyncio.QueueEmpty:
                        break
                
                if batch:
                    await self._batch_write_metrics(batch)
                
                await asyncio.sleep(1)  # 1ç§’å†™å…¥é—´éš”
                
            except Exception as e:
                logger.error(f"åå°å†™å…¥å¤±è´¥: {e}")
    
    async def _batch_write_metrics(self, metrics: List[Metric]):
        """æ‰¹é‡å†™å…¥æŒ‡æ ‡"""
        try:
            async with self.connection_pool.cursor() as cursor:
                for metric in metrics:
                    tags_json = json.dumps(metric.tags) if metric.tags else None
                    
                    await cursor.execute("""
                        INSERT INTO metrics 
                        (name, value, timestamp, metric_type, component, tags, unit, description)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        metric.name,
                        metric.value,
                        metric.timestamp.isoformat(),
                        metric.metric_type.value,
                        metric.component.value,
                        tags_json,
                        metric.unit,
                        metric.description
                    ))
                
                await self.connection_pool.commit()
                logger.debug(f"æ‰¹é‡å†™å…¥ {len(metrics)} ä¸ªæŒ‡æ ‡")
                
        except Exception as e:
            logger.error(f"æ‰¹é‡å†™å…¥æŒ‡æ ‡å¤±è´¥: {e}")
    
    async def query_metrics(self, component: SystemComponent = None,
                          metric_name: str = None,
                          start_time: datetime = None,
                          end_time: datetime = None,
                          limit: int = 1000) -> List[Metric]:
        """æŸ¥è¯¢æŒ‡æ ‡"""
        conditions = []
        params = []
        
        if component:
            conditions.append("component = ?")
            params.append(component.value)
        
        if metric_name:
            conditions.append("name = ?")
            params.append(metric_name)
        
        if start_time:
            conditions.append("timestamp >= ?")
            params.append(start_time.isoformat())
        
        if end_time:
            conditions.append("timestamp <= ?")
            params.append(end_time.isoformat())
        
        where_clause = "WHERE " + " AND ".join(conditions) if conditions else ""
        
        query = f"""
            SELECT name, value, timestamp, metric_type, component, tags, unit, description
            FROM metrics {where_clause}
            ORDER BY timestamp DESC
            LIMIT ?
        """
        params.append(limit)
        
        async with self.connection_pool.execute(query, params) as cursor:
            rows = await cursor.fetchall()
        
        metrics = []
        for row in rows:
            tags = json.loads(row[5]) if row[5] else {}
            
            metric = Metric(
                name=row[0],
                value=row[1],
                timestamp=datetime.fromisoformat(row[2]),
                metric_type=MetricType(row[3]),
                component=SystemComponent(row[4]),
                tags=tags,
                unit=row[6] or "",
                description=row[7] or ""
            )
            metrics.append(metric)
        
        return metrics

class RealTimeMonitoringSystem:
    """å®æ—¶ç›‘æ§ç³»ç»Ÿ"""
    
    def __init__(self):
        self.metrics_collector = MetricsCollector()
        self.alert_manager = AlertManager()
        self.storage = MetricsStorage()
        
        self.running = False
        self.monitoring_task = None
        self.alert_task = None
        
        # æ€§èƒ½ç»Ÿè®¡
        self.metrics_collected = 0
        self.alerts_triggered = 0
        self.start_time = None
        
        # PrometheusæŒ‡æ ‡
        if PROMETHEUS_AVAILABLE:
            self.registry = CollectorRegistry()
            self._setup_prometheus_metrics()
    
    def _setup_prometheus_metrics(self):
        """è®¾ç½®PrometheusæŒ‡æ ‡"""
        self.prometheus_metrics = {
            'system_cpu_usage': Gauge(
                'system_cpu_usage_percent',
                'System CPU usage percentage',
                registry=self.registry
            ),
            'system_memory_usage': Gauge(
                'system_memory_usage_percent',
                'System memory usage percentage',
                registry=self.registry
            ),
            'system_disk_usage': Gauge(
                'system_disk_usage_percent',
                'System disk usage percentage',
                registry=self.registry
            ),
            'alerts_total': Counter(
                'alerts_total',
                'Total number of alerts triggered',
                ['level', 'component'],
                registry=self.registry
            ),
            'metrics_collected_total': Counter(
                'metrics_collected_total',
                'Total number of metrics collected',
                registry=self.registry
            )
        }
    
    async def start(self):
        """å¯åŠ¨ç›‘æ§ç³»ç»Ÿ"""
        if self.running:
            logger.warning("ç›‘æ§ç³»ç»Ÿå·²åœ¨è¿è¡Œ")
            return
        
        await self.storage.initialize()
        self.running = True
        self.start_time = datetime.now()
        
        # å¯åŠ¨ç›‘æ§ä»»åŠ¡
        self.monitoring_task = asyncio.create_task(self._monitoring_loop())
        self.alert_task = asyncio.create_task(self._alert_loop())
        
        logger.info("ğŸš€ å®æ—¶ç›‘æ§ç³»ç»Ÿå·²å¯åŠ¨")
    
    async def stop(self):
        """åœæ­¢ç›‘æ§ç³»ç»Ÿ"""
        if not self.running:
            return
        
        self.running = False
        
        # åœæ­¢ä»»åŠ¡
        if self.monitoring_task:
            self.monitoring_task.cancel()
        
        if self.alert_task:
            self.alert_task.cancel()
        
        logger.info("â¹ï¸ å®æ—¶ç›‘æ§ç³»ç»Ÿå·²åœæ­¢")
    
    async def _monitoring_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.running:
            try:
                # æ”¶é›†æŒ‡æ ‡
                metrics = await self.metrics_collector.collect_all_metrics()
                
                # å­˜å‚¨æŒ‡æ ‡
                await self.storage.store_metrics(metrics)
                
                # æ›´æ–°ç»Ÿè®¡
                self.metrics_collected += len(metrics)
                
                # æ›´æ–°PrometheusæŒ‡æ ‡
                if PROMETHEUS_AVAILABLE:
                    self._update_prometheus_metrics(metrics)
                
                logger.debug(f"æ”¶é›†äº† {len(metrics)} ä¸ªæŒ‡æ ‡")
                
                # ç­‰å¾…ä¸‹æ¬¡æ”¶é›†
                await asyncio.sleep(self.metrics_collector.collection_interval)
                
            except Exception as e:
                logger.error(f"ç›‘æ§å¾ªç¯é”™è¯¯: {e}")
                await asyncio.sleep(5)
    
    async def _alert_loop(self):
        """å‘Šè­¦å¾ªç¯"""
        while self.running:
            try:
                # è·å–æœ€è¿‘çš„æŒ‡æ ‡
                end_time = datetime.now()
                start_time = end_time - timedelta(seconds=60)  # æœ€è¿‘1åˆ†é’Ÿçš„æŒ‡æ ‡
                
                metrics = await self.storage.query_metrics(
                    start_time=start_time,
                    end_time=end_time,
                    limit=1000
                )
                
                # è¯„ä¼°å‘Šè­¦è§„åˆ™
                await self.alert_manager.evaluate_rules(metrics)
                
                # ç­‰å¾…ä¸‹æ¬¡è¯„ä¼°
                await asyncio.sleep(self.alert_manager.evaluation_interval)
                
            except Exception as e:
                logger.error(f"å‘Šè­¦å¾ªç¯é”™è¯¯: {e}")
                await asyncio.sleep(10)
    
    def _update_prometheus_metrics(self, metrics: List[Metric]):
        """æ›´æ–°PrometheusæŒ‡æ ‡"""
        if not PROMETHEUS_AVAILABLE:
            return
        
        for metric in metrics:
            if metric.name == "cpu_usage_percent":
                self.prometheus_metrics['system_cpu_usage'].set(metric.value)
            elif metric.name == "memory_usage_percent":
                self.prometheus_metrics['system_memory_usage'].set(metric.value)
            elif metric.name == "disk_usage_percent":
                self.prometheus_metrics['system_disk_usage'].set(metric.value)
        
        self.prometheus_metrics['metrics_collected_total'].inc(len(metrics))
    
    async def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        uptime = (datetime.now() - self.start_time).total_seconds() if self.start_time else 0
        
        # è·å–æœ€è¿‘çš„æŒ‡æ ‡
        end_time = datetime.now()
        start_time = end_time - timedelta(minutes=5)
        
        recent_metrics = await self.storage.query_metrics(
            start_time=start_time,
            end_time=end_time,
            limit=100
        )
        
        # è®¡ç®—å¹³å‡å€¼
        metric_averages = defaultdict(list)
        for metric in recent_metrics:
            metric_averages[metric.name].append(metric.value)
        
        averages = {
            name: np.mean(values) for name, values in metric_averages.items()
        }
        
        return {
            "status": "running" if self.running else "stopped",
            "uptime_seconds": uptime,
            "metrics_collected": self.metrics_collected,
            "alerts_triggered": self.alerts_triggered,
            "active_alerts": len(self.alert_manager.get_active_alerts()),
            "current_metrics": averages,
            "monitoring_interval": self.metrics_collector.collection_interval,
            "alert_evaluation_interval": self.alert_manager.evaluation_interval
        }
    
    async def get_metrics_summary(self, hours: int = 24) -> Dict[str, Any]:
        """è·å–æŒ‡æ ‡æ‘˜è¦"""
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=hours)
        
        metrics = await self.storage.query_metrics(
            start_time=start_time,
            end_time=end_time,
            limit=10000
        )
        
        # æŒ‰ç»„ä»¶åˆ†ç»„
        component_metrics = defaultdict(list)
        for metric in metrics:
            component_metrics[metric.component.value].append(metric)
        
        summary = {}
        for component, comp_metrics in component_metrics.items():
            metric_summary = {}
            for metric in comp_metrics:
                if metric.name not in metric_summary:
                    values = [m.value for m in comp_metrics if m.name == metric.name]
                    metric_summary[metric.name] = {
                        "current": values[-1] if values else 0,
                        "average": np.mean(values) if values else 0,
                        "min": np.min(values) if values else 0,
                        "max": np.max(values) if values else 0,
                        "unit": metric.unit
                    }
            
            summary[component] = metric_summary
        
        return summary
    
    def add_custom_rule(self, rule: MonitoringRule):
        """æ·»åŠ è‡ªå®šä¹‰ç›‘æ§è§„åˆ™"""
        self.alert_manager.add_rule(rule)
    
    def get_alerts(self, active_only: bool = True) -> List[Alert]:
        """è·å–å‘Šè­¦ä¿¡æ¯"""
        if active_only:
            return self.alert_manager.get_active_alerts()
        else:
            return self.alert_manager.get_alert_history()

# å…¨å±€ç›‘æ§ç³»ç»Ÿå®ä¾‹
_monitoring_system = None

async def get_monitoring_system() -> RealTimeMonitoringSystem:
    """è·å–ç›‘æ§ç³»ç»Ÿå•ä¾‹"""
    global _monitoring_system
    if _monitoring_system is None:
        _monitoring_system = RealTimeMonitoringSystem()
        await _monitoring_system.start()
    return _monitoring_system

# ä¾¿æ·å‡½æ•°
async def start_monitoring():
    """å¯åŠ¨ç›‘æ§"""
    system = await get_monitoring_system()
    await system.start()

async def get_system_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    system = await get_monitoring_system()
    return await system.get_system_status()

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    async def test_monitoring():
        system = RealTimeMonitoringSystem()
        await system.start()
        
        # è¿è¡Œ1åˆ†é’Ÿ
        await asyncio.sleep(60)
        
        # è·å–çŠ¶æ€
        status = await system.get_system_status()
        print("ç³»ç»ŸçŠ¶æ€:")
        print(json.dumps(status, indent=2, ensure_ascii=False))
        
        # è·å–æŒ‡æ ‡æ‘˜è¦
        summary = await system.get_metrics_summary(hours=1)
        print("\næŒ‡æ ‡æ‘˜è¦:")
        print(json.dumps(summary, indent=2, ensure_ascii=False))
        
        # è·å–å‘Šè­¦
        alerts = system.get_alerts()
        print(f"\næ´»è·ƒå‘Šè­¦: {len(alerts)}")
        
        await system.stop()
    
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_monitoring())
