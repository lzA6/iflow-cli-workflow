#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤åçš„ä¿å®ˆæ¸…ç†è„šæœ¬
åªæ¸…ç†æ˜æ˜¾çš„å†—ä½™æ–‡ä»¶ï¼Œä¿ç•™æ‰€æœ‰ç°æœ‰åŠŸèƒ½
"""

import os
import sys
import json
import shutil
import time
from pathlib import Path
from typing import List, Dict, Set, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

class ConservativeCleanup:
    """ä¿å®ˆæ¸…ç†å™¨"""
    
    def __init__(self, project_root: Optional[Path] = None):
        self.project_root = project_root or PROJECT_ROOT
        self.cleanup_log = []
        self.protected_files = set()
        self.setup_protected_files()
    
    def setup_protected_files(self):
        """è®¾ç½®å—ä¿æŠ¤çš„æ–‡ä»¶ï¼ˆä¸æ¸…ç†ï¼‰"""
        # å—ä¿æŠ¤çš„æ ¸å¿ƒæ–‡ä»¶
        protected_list = [
            # æ ¸å¿ƒå¼•æ“æ–‡ä»¶
            "ultimate_arq_engine.py",
            "ultimate_consciousness_system.py",
            "male_system.py",
            "dkcm_system.py",
            "rpfv_system.py",
            
            # å…³é”®å·¥å…·æ–‡ä»¶
            "intelligent_tool_caller.py",
            "multi_agent_orchestrator.py",
            
            # é‡è¦é…ç½®æ–‡ä»¶
            "settings.json",
            "principles.md",
            "rules.md",
        ]
        self.protected_files = set(protected_list)
    
    def find_duplicate_files(self) -> Dict[str, List[str]]:
        """æŸ¥æ‰¾é‡å¤æ–‡ä»¶"""
        duplicates = {}
        
        # æŸ¥æ‰¾ç‰ˆæœ¬å·é‡å¤çš„æ–‡ä»¶
        version_patterns = [
            ("README", ["README.md", "README_V4.md"]),
            ("CHANGELOG", ["CHANGELOG.md", "CHANGELOG_V4.md"]),
            ("Hookç®¡ç†å™¨", ["comprehensive_hook_manager.py", "comprehensive_hook_manager_v4.py", 
                           "comprehensive-hook-manager.py", "comprehensive-hook-manager-v4.py"]),
            ("è´¨é‡æ£€æŸ¥", ["auto_quality_check.py", "auto_quality_check_v6.py"]),
        ]
        
        for category, files in version_patterns:
            existing_files = []
            for file_pattern in files:
                file_path = self.project_root / ".iflow" / file_pattern
                if file_path.exists():
                    existing_files.append(str(file_path))
            
            if len(existing_files) > 1:
                duplicates[category] = existing_files
        
        return duplicates
    
    def analyze_file_importance(self, file_path: Path) -> Dict[str, any]:
        """åˆ†ææ–‡ä»¶é‡è¦æ€§"""
        if not file_path.exists():
            return {"status": "missing"}
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å—ä¿æŠ¤æ–‡ä»¶
        if file_path.name in self.protected_files:
            return {"status": "protected", "reason": "æ ¸å¿ƒæ–‡ä»¶"}
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°å’Œä¿®æ”¹æ—¶é—´
        stat = file_path.stat()
        return {
            "status": "analyzable",
            "size": stat.st_size,
            "mtime": stat.st_mtime,
            "is_recent": (stat.st_mtime > (time.time() - 86400 * 30))  # 30å¤©å†…
        }
    
    def should_keep_file(self, file_path: Path, duplicates: List[str]) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¿ç•™æ–‡ä»¶"""
        analysis = self.analyze_file_importance(file_path)
        
        if analysis["status"] == "protected":
            return True
        
        if analysis["status"] == "missing":
            return False
        
        # å¦‚æœæ˜¯æœ€æ–°çš„æ–‡ä»¶ï¼Œä¿ç•™
        if analysis.get("is_recent", False):
            return True
        
        # å¦‚æœæ–‡ä»¶è¾ƒå¤§ï¼ˆå¯èƒ½åŒ…å«æ›´å¤šå†…å®¹ï¼‰ï¼Œä¿ç•™
        if analysis.get("size", 0) > 10000:  # 10KB
            return True
        
        # å¦‚æœæ˜¯å”¯ä¸€å­˜åœ¨çš„æ–‡ä»¶ï¼Œä¿ç•™
        if len(duplicates) == 1:
            return True
        
        return False
    
    def cleanup_duplicates(self) -> Dict[str, any]:
        """æ¸…ç†é‡å¤æ–‡ä»¶"""
        results = {
            "kept_files": [],
            "removed_files": [],
            "errors": [],
            "summary": {}
        }
        
        duplicates = self.find_duplicate_files()
        
        for category, file_list in duplicates.items():
            if len(file_list) <= 1:
                continue
            
            kept = None
            removed = []
            
            for file_path_str in file_list:
                file_path = Path(file_path_str)
                
                if self.should_keep_file(file_path, file_list):
                    if not kept:
                        kept = file_path_str
                        results["kept_files"].append({
                            "file": file_path_str,
                            "reason": "ä¿ç•™æœ€æ–°/æœ€é‡è¦çš„ç‰ˆæœ¬",
                            "category": category
                        })
                        print(f"âœ… ä¿ç•™: {file_path_str} (ç±»åˆ«: {category})")
                    else:
                        # å·²ç»æœ‰ä¸€ä¸ªä¿ç•™çš„æ–‡ä»¶ï¼Œè¿™ä¸ªæ ‡è®°ä¸ºåˆ é™¤
                        removed.append(file_path_str)
                else:
                    removed.append(file_path_str)
            
            # å¤‡ä»½å¹¶åˆ é™¤å†—ä½™æ–‡ä»¶
            for remove_path in removed:
                try:
                    backup_path = remove_path + ".backup"
                    shutil.move(remove_path, backup_path)
                    results["removed_files"].append({
                        "file": remove_path,
                        "backup": backup_path,
                        "category": category
                    })
                    print(f"ğŸ—‘ï¸  å¤‡ä»½å¹¶åˆ é™¤: {remove_path} -> {backup_path}")
                except Exception as e:
                    error_msg = f"åˆ é™¤å¤±è´¥: {remove_path} - {e}"
                    results["errors"].append(error_msg)
                    print(f"âŒ {error_msg}")
            
            results["summary"][category] = {
                "original_count": len(file_list),
                "kept_count": 1 if kept else 0,
                "removed_count": len(removed)
            }
        
        return results
    
    def cleanup_temp_files(self) -> Dict[str, any]:
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        temp_patterns = [
            "*.tmp",
            "*.temp",
            "*.log.bak",
            "temp_delete.py",
            "*.pyc",
            "__pycache__"
        ]
        
        results = {
            "removed_files": [],
            "errors": []
        }
        
        for pattern in temp_patterns:
            for file_path in self.project_root.glob(f"**/{pattern}"):
                if file_path.is_file():
                    try:
                        backup_path = str(file_path) + ".backup"
                        shutil.move(str(file_path), backup_path)
                        results["removed_files"].append({
                            "file": str(file_path),
                            "backup": backup_path
                        })
                        print(f"ğŸ—‘ï¸  æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {file_path}")
                    except Exception as e:
                        error_msg = f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {file_path} - {e}"
                        results["errors"].append(error_msg)
                        print(f"âŒ {error_msg}")
        
        return results
    
    def generate_cleanup_report(self) -> Dict[str, any]:
        """ç”Ÿæˆæ¸…ç†æŠ¥å‘Š"""
        report = {
            "timestamp": time.time(),
            "project_root": str(self.project_root),
            "duplicate_cleanup": self.cleanup_duplicates(),
            "temp_cleanup": self.cleanup_temp_files(),
            "recommendations": []
        }
        
        # æ·»åŠ å»ºè®®
        report["recommendations"] = [
            "âœ… å·²å®Œæˆä¿å®ˆæ¸…ç†ï¼Œåªåˆ é™¤äº†æ˜æ˜¾çš„é‡å¤æ–‡ä»¶",
            "ğŸ“¦ æ‰€æœ‰åˆ é™¤çš„æ–‡ä»¶éƒ½å·²å¤‡ä»½ï¼Œæ‰©å±•åä¸º.backup",
            "ğŸ“ å»ºè®®åç»­å¯ä»¥æ‰‹åŠ¨æ£€æŸ¥å¤‡ä»½æ–‡ä»¶ï¼Œç¡®è®¤æ— è¯¯åå†åˆ é™¤",
            "ğŸ“ å»ºè®®æ›´æ–°ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼Œæäº¤æ¸…ç†åçš„ç»“æœ"
        ]
        
        return report
    
    def save_cleanup_report(self, report: Dict[str, any]):
        """ä¿å­˜æ¸…ç†æŠ¥å‘Š"""
        report_path = self.project_root / ".iflow" / "conservative_cleanup_report.json"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ æ¸…ç†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ä¿å®ˆæ¸…ç†Aé¡¹ç›®...")
    print("=" * 50)
    
    cleanup = ConservativeCleanup()
    report = cleanup.generate_cleanup_report()
    cleanup.save_cleanup_report(report)
    
    print("\n" + "=" * 50)
    print("ğŸ“Š æ¸…ç†æ€»ç»“:")
    
    # ç»Ÿè®¡ç»“æœ
    total_removed = 0
    total_kept = 0
    
    for category, summary in report["duplicate_cleanup"]["summary"].items():
        print(f"  {category}: åŸ{summary['original_count']}ä¸ª -> ä¿ç•™{summary['kept_count']}ä¸ª -> åˆ é™¤{summary['removed_count']}ä¸ª")
        total_removed += summary["removed_count"]
        total_kept += summary["kept_count"]
    
    print(f"\nğŸ—‘ï¸  æ€»è®¡åˆ é™¤æ–‡ä»¶: {total_removed} ä¸ª")
    print(f"âœ… æ€»è®¡ä¿ç•™æ–‡ä»¶: {total_kept} ä¸ª")
    
    if report["temp_cleanup"]["removed_files"]:
        print(f"ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {len(report['temp_cleanup']['removed_files'])} ä¸ª")
    
    if report["duplicate_cleanup"]["errors"]:
        print(f"âš ï¸  æ¸…ç†é”™è¯¯: {len(report['duplicate_cleanup']['errors'])} ä¸ª")
    
    print("\nğŸ’¡ æ¸…ç†å®Œæˆï¼æ‰€æœ‰åˆ é™¤çš„æ–‡ä»¶éƒ½å·²å¤‡ä»½ã€‚")
    print("   å»ºè®®æ£€æŸ¥å¤‡ä»½æ–‡ä»¶ç¡®è®¤æ— è¯¯åï¼Œå†æ‰‹åŠ¨åˆ é™¤.backupæ–‡ä»¶ã€‚")

if __name__ == "__main__":
    main()