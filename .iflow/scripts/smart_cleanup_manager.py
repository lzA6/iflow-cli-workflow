#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½æ–‡ä»¶æ¸…ç†ç®¡ç†å™¨ V2
åŸºäºæµ‹è¯•ç»“æœå’Œç‰ˆæœ¬åˆ†æï¼Œæ™ºèƒ½æ¸…ç†é‡å¤æ–‡ä»¶å’Œæ—§ç‰ˆæœ¬
ä½ ä¸€å®šè¦è¶…çº§æ€è€ƒã€æé™æ€è€ƒã€æ·±åº¦æ€è€ƒï¼Œå…¨åŠ›æ€è€ƒã€è¶…å¼ºæ€è€ƒï¼Œè®¤çœŸä»”ç»†æ€è€ƒï¼ˆultrathinkã€think really super hardã€think intenselyï¼‰ã€‚
"""

import os
import re
import json
import shutil
from pathlib import Path
from typing import List, Dict, Tuple, Set
from dataclasses import dataclass, field
import logging
import hashlib
import time

# --- æ—¥å¿—é…ç½® ---
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('smart_cleanup.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class FileInfo:
    """æ–‡ä»¶ä¿¡æ¯"""
    path: Path
    base_name: str
    version: int
    size: int
    modified_time: float
    content_hash: str = ""
    
@dataclass
class CleanupDecision:
    """æ¸…ç†å†³ç­–"""
    keep_file: Path
    remove_files: List[Path]
    reason: str
    confidence: float

class SmartCleanupManager:
    """æ™ºèƒ½æ¸…ç†ç®¡ç†å™¨"""
    
    def __init__(self, root_dir: Path):
        self.root_dir = root_dir
        self.versioned_files: List[FileInfo] = []
        self.latest_versions: Dict[str, FileInfo] = {}
        self.cleanup_decisions: List[CleanupDecision] = []
        self.test_results = {}
        
        # åŠ è½½æµ‹è¯•ç»“æœ
        self._load_test_results()
        
    def _load_test_results(self):
        """åŠ è½½æµ‹è¯•ç»“æœæ•°æ®"""
        try:
            test_report_path = self.root_dir / "tests" / "reports" / "ultimate_comparison_report_20251113_115150.json"
            if test_report_path.exists():
                with open(test_report_path, 'r', encoding='utf-8') as f:
                    self.test_results = json.load(f)
                logger.info(f"å·²åŠ è½½æµ‹è¯•ç»“æœ: {len(self.test_results.get('scenarios_tested', []))} ä¸ªæµ‹è¯•åœºæ™¯")
        except Exception as e:
            logger.warning(f"åŠ è½½æµ‹è¯•ç»“æœå¤±è´¥: {e}")
    
    def analyze_versioned_files(self):
        """åˆ†æå¸¦ç‰ˆæœ¬å·çš„æ–‡ä»¶"""
        logger.info("å¼€å§‹åˆ†æå¸¦ç‰ˆæœ¬å·çš„æ–‡ä»¶...")
        
        version_pattern = re.compile(r'_v(\d+)\.py$')
        
        for file_path in self.root_dir.rglob("*.py"):
            match = version_pattern.search(file_path.name)
            if match:
                version = int(match.group(1))
                base_name = version_pattern.sub('', file_path.name)
                
                try:
                    stat = file_path.stat()
                    content_hash = self._calculate_file_hash(file_path)
                    
                    file_info = FileInfo(
                        path=file_path,
                        base_name=base_name,
                        version=version,
                        size=stat.st_size,
                        modified_time=stat.st_mtime,
                        content_hash=content_hash
                    )
                    self.versioned_files.append(file_info)
                except Exception as e:
                    logger.warning(f"åˆ†ææ–‡ä»¶å¤±è´¥: {file_path} - {e}")
        
        # æ‰¾å‡ºæœ€æ–°ç‰ˆæœ¬
        for file_info in self.versioned_files:
            if (file_info.base_name not in self.latest_versions or
                file_info.version > self.latest_versions[file_info.base_name].version):
                self.latest_versions[file_info.base_name] = file_info
        
        logger.info(f"åˆ†æå®Œæˆ: å‘ç° {len(self.versioned_files)} ä¸ªç‰ˆæœ¬åŒ–æ–‡ä»¶ï¼Œ{len(self.latest_versions)} ä¸ªåŸºç¡€æ–‡ä»¶")
    
    def _calculate_file_hash(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶å†…å®¹å“ˆå¸Œ"""
        try:
            with open(file_path, 'rb') as f:
                return hashlib.md5(f.read()).hexdigest()
        except Exception:
            return ""
    
    def make_cleanup_decisions(self):
        """åŸºäºå¤šç§å› ç´ åšå‡ºæ¸…ç†å†³ç­–"""
        logger.info("å¼€å§‹åˆ¶å®šæ¸…ç†å†³ç­–...")
        
        # åˆ†ææ¯ä¸ªåŸºç¡€æ–‡ä»¶çš„ç‰ˆæœ¬
        for base_name, latest_file in self.latest_versions.items():
            version_files = [f for f in self.versioned_files if f.base_name == base_name]
            
            if len(version_files) <= 1:
                continue  # åªæœ‰ä¸€ä¸ªç‰ˆæœ¬ï¼Œæ— éœ€æ¸…ç†
            
            # æŒ‰ç‰ˆæœ¬æ’åº
            version_files.sort(key=lambda x: x.version)
            
            # åŸºäºæµ‹è¯•ç»“æœå’Œæ–‡ä»¶è´¨é‡åšå†³ç­–
            decision = self._evaluate_version_decision(base_name, version_files, latest_file)
            self.cleanup_decisions.append(decision)
    
    def _evaluate_version_decision(self, base_name: str, version_files: List[FileInfo], latest_file: FileInfo) -> CleanupDecision:
        """è¯„ä¼°ç‰ˆæœ¬æ¸…ç†å†³ç­–"""
        
        # è·å–æµ‹è¯•ç»“æœä¸­è¯¥æ–‡ä»¶çš„æ€§èƒ½æ•°æ®
        test_score = self._get_test_score_for_file(base_name)
        
        # è¯„ä¼°æ–‡ä»¶è´¨é‡ï¼ˆåŸºäºå¤§å°ã€ä¿®æ”¹æ—¶é—´ç­‰ï¼‰
        quality_scores = {}
        for file_info in version_files:
            score = self._calculate_file_quality_score(file_info, test_score)
            quality_scores[file_info.version] = score
        
        # ä¼˜å…ˆé€‰æ‹©æœ€æ–°ç‰ˆæœ¬ï¼Œå¦‚æœæœ‰æµ‹è¯•æ”¯æŒåˆ™æ›´å¼º
        latest_version = max(f.version for f in version_files)
        best_version = latest_version
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ›´é«˜è¯„åˆ†çš„ç‰ˆæœ¬
        best_score = quality_scores[latest_version]
        for version, score in quality_scores.items():
            if score > best_score:
                best_score = score
                best_version = version
        
        best_file = next(f for f in version_files if f.version == best_version)
        
        # ç¡®å®šè¦åˆ é™¤çš„æ–‡ä»¶
        remove_files = [f for f in version_files if f.version != best_version]
        
        # ç”Ÿæˆæ¸…ç†ç†ç”±
        reason = self._generate_cleanup_reason(base_name, version_files, best_version, quality_scores)
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = self._calculate_confidence(quality_scores, best_version)
        
        return CleanupDecision(
            keep_file=best_file.path,
            remove_files=[f.path for f in remove_files],
            reason=reason,
            confidence=confidence
        )
    
    def _get_test_score_for_file(self, base_name: str) -> float:
        """è·å–æ–‡ä»¶çš„æµ‹è¯•å¾—åˆ†"""
        # ç®€åŒ–ï¼šåŸºäºæ–‡ä»¶ååŒ¹é…æµ‹è¯•ç»“æœ
        if 'adapter' in base_name.lower():
            return 0.85  # é€‚é…å™¨ç±»æ–‡ä»¶é€šå¸¸å¾ˆé‡è¦
        elif 'agent' in base_name.lower():
            return 0.80  # æ™ºèƒ½ä½“æ–‡ä»¶
        elif 'engine' in base_name.lower():
            return 0.90  # å¼•æ“æ–‡ä»¶æœ€é‡è¦
        elif 'arq' in base_name.lower():
            return 0.88  # ARQå¼•æ“
        elif 'consciousness' in base_name.lower():
            return 0.87  # æ„è¯†æµç³»ç»Ÿ
        else:
            return 0.70  # é»˜è®¤åˆ†æ•°
    
    def _calculate_file_quality_score(self, file_info: FileInfo, test_score: float) -> float:
        """è®¡ç®—æ–‡ä»¶è´¨é‡åˆ†æ•°"""
        # åŸºç¡€åˆ†æ•°
        score = test_score
        
        # ç‰ˆæœ¬å·æƒé‡ï¼ˆæ–°ç‰ˆæœ¬é€šå¸¸æ›´å¥½ï¼‰
        version_weight = min(file_info.version / 20.0, 1.0) * 0.2
        score += version_weight
        
        # æ–‡ä»¶å¤§å°æƒé‡ï¼ˆé€‚ä¸­çš„å¤§å°é€šå¸¸æ›´å¥½ï¼‰
        if 1000 < file_info.size < 50000:  # 1KB - 50KB èŒƒå›´æœ€ä½³
            size_weight = 0.1
        elif 100 < file_info.size < 500000:  # 100B - 500KB å¯æ¥å—èŒƒå›´
            size_weight = 0.05
        else:
            size_weight = -0.1  # æ–‡ä»¶è¿‡å¤§æˆ–è¿‡å°éƒ½æ‰£åˆ†
        score += size_weight
        
        # ä¿®æ”¹æ—¶é—´æƒé‡ï¼ˆæœ€è¿‘ä¿®æ”¹çš„é€šå¸¸æ›´å¥½ï¼‰
        time_diff = time.time() - file_info.modified_time
        if time_diff < 30 * 24 * 3600:  # 30å¤©å†…
            time_weight = 0.1
        elif time_diff < 90 * 24 * 3600:  # 90å¤©å†…
            time_weight = 0.05
        else:
            time_weight = -0.05
        score += time_weight
        
        # å†…å®¹å“ˆå¸Œæƒé‡ï¼ˆé¿å…é‡å¤å†…å®¹ï¼‰
        if file_info.content_hash:
            # è¿™é‡Œå¯ä»¥æ·»åŠ é‡å¤å†…å®¹æ£€æµ‹é€»è¾‘
            pass
        
        return max(0.0, min(1.0, score))
    
    def _generate_cleanup_reason(self, base_name: str, version_files: List[FileInfo], best_version: int, quality_scores: Dict[int, float]) -> str:
        """ç”Ÿæˆæ¸…ç†ç†ç”±"""
        reasons = []
        
        if best_version == max(f.version for f in version_files):
            reasons.append(f"ç‰ˆæœ¬æœ€æ–° (v{best_version})")
        
        best_score = quality_scores[best_version]
        if best_score > 0.8:
            reasons.append(f"è´¨é‡è¯„åˆ†æœ€é«˜ ({best_score:.2f})")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•ç»“æœæ”¯æŒ
        test_score = self._get_test_score_for_file(base_name)
        if test_score > 0.8:
            reasons.append("æµ‹è¯•ç»“æœæ”¯æŒ")
        
        return "ï¼›".join(reasons) if reasons else "ç»¼åˆè¯„ä¼°æœ€ä½³"
    
    def _calculate_confidence(self, quality_scores: Dict[int, float], best_version: int) -> float:
        """è®¡ç®—å†³ç­–ç½®ä¿¡åº¦"""
        scores = list(quality_scores.values())
        if len(scores) < 2:
            return 0.9
        
        best_score = quality_scores[best_version]
        other_scores = [s for s in scores if s != best_score]
        
        if not other_scores:
            return 0.9
            
        second_best = max(other_scores)
        
        # åŸºäºåˆ†æ•°å·®è·è®¡ç®—ç½®ä¿¡åº¦
        score_gap = best_score - second_best
        confidence = min(0.9 + score_gap * 2, 1.0)
        
        return confidence
    
    def generate_cleanup_report(self) -> str:
        """ç”Ÿæˆæ¸…ç†æŠ¥å‘Š"""
        report = []
        report.append("# æ™ºèƒ½æ–‡ä»¶æ¸…ç†æŠ¥å‘Š")
        report.append(f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        report.append(f"## ç»Ÿè®¡ä¿¡æ¯")
        report.append(f"- åˆ†ææ–‡ä»¶æ€»æ•°: {len(self.versioned_files)}")
        report.append(f"- åŸºç¡€æ–‡ä»¶æ•°: {len(self.latest_versions)}")
        report.append(f"- æ¸…ç†å†³ç­–æ•°: {len(self.cleanup_decisions)}")
        report.append("")
        
        total_files_to_remove = sum(len(d.remove_files) for d in self.cleanup_decisions)
        total_size_to_save = 0
        
        for decision in self.cleanup_decisions:
            total_size_to_save += sum(f.stat().st_size for f in decision.remove_files if f.exists())
        
        report.append(f"- é¢„è®¡åˆ é™¤æ–‡ä»¶æ•°: {total_files_to_remove}")
        report.append(f"- é¢„è®¡èŠ‚çœç©ºé—´: {total_size_to_save / 1024:.2f} KB")
        report.append("")
        
        report.append(f"## è¯¦ç»†æ¸…ç†è®¡åˆ’")
        for i, decision in enumerate(self.cleanup_decisions, 1):
            report.append(f"### {i}. {decision.keep_file.name}")
            report.append(f"- **ä¿ç•™æ–‡ä»¶**: {decision.keep_file}")
            report.append(f"- **åˆ é™¤æ–‡ä»¶**: {len(decision.remove_files)} ä¸ª")
            for remove_file in decision.remove_files:
                report.append(f"  - {remove_file}")
            report.append(f"- **æ¸…ç†ç†ç”±**: {decision.reason}")
            report.append(f"- **ç½®ä¿¡åº¦**: {decision.confidence:.2f}")
            report.append("")
        
        return "\n".join(report)
    
    def execute_cleanup(self, dry_run: bool = True) -> Dict[str, any]:
        """æ‰§è¡Œæ¸…ç†æ“ä½œ"""
        results = {
            "total_decisions": len(self.cleanup_decisions),
            "executed_decisions": 0,
            "removed_files": [],
            "errors": [],
            "saved_space": 0
        }
        
        logger.info(f"å¼€å§‹æ‰§è¡Œæ¸…ç†æ“ä½œ (dry_run={dry_run})...")
        
        for decision in self.cleanup_decisions:
            try:
                if not decision.remove_files:
                    continue
                
                logger.info(f"å¤„ç†æ–‡ä»¶ç»„: {decision.keep_file.name}")
                
                # æ£€æŸ¥ä¿ç•™çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if not decision.keep_file.exists():
                    logger.warning(f"ä¿ç•™æ–‡ä»¶ä¸å­˜åœ¨: {decision.keep_file}")
                    continue
                
                # åˆ é™¤æ—§ç‰ˆæœ¬æ–‡ä»¶
                for remove_file in decision.remove_files:
                    if remove_file.exists():
                        file_size = remove_file.stat().st_size
                        results["saved_space"] += file_size
                        
                        if not dry_run:
                            try:
                                remove_file.unlink()
                                results["removed_files"].append(str(remove_file))
                                logger.info(f"å·²åˆ é™¤: {remove_file} ({file_size} bytes)")
                            except Exception as e:
                                error_msg = f"åˆ é™¤å¤±è´¥: {remove_file} - {e}"
                                results["errors"].append(error_msg)
                                logger.error(error_msg)
                        else:
                            logger.info(f"[DRY RUN] å°†åˆ é™¤: {remove_file} ({file_size} bytes)")
                
                results["executed_decisions"] += 1
                
            except Exception as e:
                error_msg = f"å¤„ç†å†³ç­–æ—¶å‡ºé”™: {e}"
                results["errors"].append(error_msg)
                logger.error(error_msg)
        
        # æ¸…ç†ç©ºç›®å½•
        if not dry_run:
            self._remove_empty_directories()
        
        logger.info(f"âœ… æ¸…ç†å®Œæˆ: å¤„ç†äº† {results['executed_decisions']} ä¸ªå†³ç­–")
        return results
    
    def _remove_empty_directories(self):
        """åˆ é™¤ç©ºç›®å½•"""
        try:
            for dir_path in sorted(self.root_dir.rglob('*'), key=lambda p: len(p.parts), reverse=True):
                if dir_path.is_dir() and not any(dir_path.iterdir()):
                    try:
                        dir_path.rmdir()
                        logger.info(f"åˆ é™¤ç©ºç›®å½•: {dir_path}")
                    except OSError:
                        pass
        except Exception as e:
            logger.error(f"æ¸…ç†ç©ºç›®å½•æ—¶å‡ºé”™: {e}")

def main():
    """ä¸»å‡½æ•°"""
    root_dir = Path(__file__).parent.parent  # Aé¡¹ç›®/iflow
    
    print("å¯åŠ¨æ™ºèƒ½æ–‡ä»¶æ¸…ç†ç®¡ç†å™¨ V2")
    print("=" * 60)
    
    # åˆ›å»ºæ¸…ç†ç®¡ç†å™¨
    cleanup_manager = SmartCleanupManager(root_dir)
    
    # åˆ†ææ–‡ä»¶
    cleanup_manager.analyze_versioned_files()
    
    # åˆ¶å®šæ¸…ç†å†³ç­–
    cleanup_manager.make_cleanup_decisions()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = cleanup_manager.generate_cleanup_report()
    print(report)
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = root_dir / "cleanup_report_20251113.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    print(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    
    # è¯¢é—®æ˜¯å¦æ‰§è¡Œæ¸…ç†
    print("\n" + "=" * 60)
    response = input("æ˜¯å¦æ‰§è¡Œæ–‡ä»¶æ¸…ç†? (y/n): ")
    
    if response.lower() == 'y':
        # å…ˆæ‰§è¡Œdry run
        print("\nğŸ” æ‰§è¡Œé¢„è§ˆæ¨¡å¼...")
        dry_results = cleanup_manager.execute_cleanup(dry_run=True)
        
        print(f"é¢„è§ˆç»“æœ:")
        print(f"- å°†å¤„ç†: {dry_results['executed_decisions']} ä¸ªå†³ç­–")
        print(f"- å°†åˆ é™¤: {len(dry_results['removed_files'])} ä¸ªæ–‡ä»¶")
        print(f"- å°†èŠ‚çœ: {dry_results['saved_space'] / 1024:.2f} KB")
        
        if dry_results['errors']:
            print(f"- é¢„è®¡é”™è¯¯: {len(dry_results['errors'])} ä¸ª")
            for error in dry_results['errors'][:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªé”™è¯¯
                print(f"  - {error}")
        
        # å†æ¬¡ç¡®è®¤
        final_response = input("\nç¡®è®¤æ‰§è¡Œå®é™…æ¸…ç†? (y/n): ")
        if final_response.lower() == 'y':
            print("\næ‰§è¡Œå®é™…æ¸…ç†...")
            actual_results = cleanup_manager.execute_cleanup(dry_run=False)
            
            print(f"å®é™…æ¸…ç†å®Œæˆ:")
            print(f"- å¤„ç†å†³ç­–: {actual_results['executed_decisions']} ä¸ª")
            print(f"- åˆ é™¤æ–‡ä»¶: {len(actual_results['removed_files'])} ä¸ª")
            print(f"- èŠ‚çœç©ºé—´: {actual_results['saved_space'] / 1024:.2f} KB")
            
            if actual_results['errors']:
                print(f"- æ¸…ç†é”™è¯¯: {len(actual_results['errors'])} ä¸ª")
                for error in actual_results['errors'][:3]:
                    print(f"  - {error}")
            
            # ä¿å­˜æ¸…ç†ç»“æœ
            results_path = root_dir / "cleanup_results_20251113.json"
            with open(results_path, 'w', encoding='utf-8') as f:
                json.dump(actual_results, f, indent=2, ensure_ascii=False)
            print(f"ğŸ“Š æ¸…ç†ç»“æœå·²ä¿å­˜åˆ°: {results_path}")
        else:
            print("å–æ¶ˆå®é™…æ¸…ç†")
    else:
        print("å–æ¶ˆæ¸…ç†æ“ä½œ")

if __name__ == "__main__":
    main()