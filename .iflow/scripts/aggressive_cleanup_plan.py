#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¿€è¿›æ¸…ç†è®¡åˆ’ - æ¸è¿›å¼æ¸…ç†é‡å¤æ–‡ä»¶å’Œæ—§ç‰ˆæœ¬
ä½ ä¸€å®šè¦è¶…çº§æ€è€ƒã€æé™æ€è€ƒã€æ·±åº¦æ€è€ƒï¼Œå…¨åŠ›æ€è€ƒã€è¶…å¼ºæ€è€ƒï¼Œè®¤çœŸä»”ç»†æ€è€ƒï¼ˆultrathinkã€think really super hardã€think intenselyï¼‰ã€‚
"""

import os
import sys
import shutil
from pathlib import Path
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

def get_duplicate_files_analysis():
    """åˆ†æé‡å¤æ–‡ä»¶"""
    duplicates = {
        "hook_managers": [
            "iflow/hooks/comprehensive_hook_manager.py",
            "iflow/hooks/comprehensive_hook_manager_v4.py", 
            "iflow/hooks/comprehensive-hook-manager.py",
            "iflow/hooks/comprehensive-hook-manager-v4.py"
        ],
        "auto_quality_checks": [
            "iflow/hooks/auto_quality_check.py",
            "iflow/hooks/auto_quality_check_v6.py"
        ],
        "cleanup_scripts": [
            "iflow/scripts/cleanup_v4.py",
            "iflow/scripts/conservative_cleanup_v2.py",
            "iflow/scripts/simple_cleanup.py",
            "iflow/scripts/intelligent_cleanup.py",
            "iflow/scripts/fixed_cleanup_script.py",
            "iflow/scripts/smart_cleanup_manager.py",
            "iflow/scripts/refactor_agents.py",
            "iflow/scripts/cleanup_old_files.py"
        ],
        "test_versions": [
            "iflow/tests/simple_test_v4.py"
        ],
        "ultimate_versions": {
            "consciousness_system": [
                "iflow/core/ultimate_consciousness_system_v4.py",
                "iflow/core/ultimate_consciousness_system_v5.py", 
                "iflow/core/ultimate_consciousness_system_v6.py"
            ],
            "workflow_engine": [
                "iflow/core/ultimate_workflow_engine_v4.py",
                "iflow/core/ultimate_workflow_engine_v6.py"
            ],
            "arq_engine": [
                "iflow/core/ultimate_arq_engine_v4.py",
                "iflow/core/ultimate_arq_engine_v5.py",
                "iflow/core/ultimate_arq_engine_v6.py"
            ],
            "llm_adapter": [
                "iflow/adapters/universal_llm_adapter_v11.py",
                "iflow/adapters/universal_llm_adapter_v12.py", 
                "iflow/adapters/universal_llm_adapter_v13.py",
                "iflow/adapters/ultimate_llm_adapter_v14.py"
            ]
        }
    }
    return duplicates

def analyze_file_versions(duplicates):
    """åˆ†ææ–‡ä»¶ç‰ˆæœ¬ï¼Œç¡®å®šä¿ç•™å“ªä¸ª"""
    retention_plan = {
        "keep": [],
        "delete": [],
        "analyze": []  # éœ€è¦è¿›ä¸€æ­¥åˆ†æçš„
    }
    
    # Hookç®¡ç†å™¨ - ä¿ç•™æœ€æ–°ç‰ˆæœ¬
    hook_files = duplicates["hook_managers"]
    hook_files.sort()
    retention_plan["keep"].append(hook_files[-1])  # ä¿ç•™æœ€åä¸€ä¸ªï¼ˆæœ€æ–°ï¼‰
    retention_plan["delete"].extend(hook_files[:-1])
    
    # è´¨é‡æ£€æŸ¥ - ä¿ç•™æœ€æ–°ç‰ˆæœ¬
    quality_files = duplicates["auto_quality_checks"]
    quality_files.sort()
    retention_plan["keep"].append(quality_files[-1])
    retention_plan["delete"].extend(quality_files[:-1])
    
    # æ¸…ç†è„šæœ¬ - åªä¿ç•™ä¸€ä¸ªæœ€å®Œæ•´çš„
    cleanup_files = duplicates["cleanup_scripts"]
    # ä¿ç•™ aggressive_cleanup_plan.py å’Œ intelligent_cleanup.py
    retention_plan["keep"].extend([
        "iflow/scripts/intelligent_cleanup.py"
    ])
    retention_plan["delete"].extend([f for f in cleanup_files if f != "iflow/scripts/intelligent_cleanup.py"])
    
    # æµ‹è¯•æ–‡ä»¶ - åˆ é™¤æ—§ç‰ˆæœ¬
    retention_plan["delete"].extend(duplicates["test_versions"])
    
    # æ ¸å¿ƒç»„ä»¶ç‰ˆæœ¬åˆ†æ
    for component, files in duplicates["ultimate_versions"].items():
        files.sort()
        # ä¿ç•™æœ€é«˜ç‰ˆæœ¬å·
        latest = files[-1]
        retention_plan["keep"].append(latest)
        retention_plan["delete"].extend(files[:-1])
        
        print(f"ç»„ä»¶ {component}: ä¿ç•™ {latest}")
    
    return retention_plan

def execute_cleanup(retention_plan):
    """æ‰§è¡Œæ¸…ç†"""
    deleted_files = []
    errors = []
    
    print("ğŸ—‘ï¸ å¼€å§‹æ‰§è¡Œæ¸…ç†è®¡åˆ’...")
    print(f"å°†åˆ é™¤ {len(retention_plan['delete'])} ä¸ªæ–‡ä»¶")
    print(f"å°†ä¿ç•™ {len(retention_plan['keep'])} ä¸ªæ–‡ä»¶")
    
    # æ˜¾ç¤ºå°†è¦åˆ é™¤çš„æ–‡ä»¶
    print("\nğŸ“‹ å°†åˆ é™¤çš„æ–‡ä»¶:")
    for file_path in retention_plan["delete"]:
        full_path = PROJECT_ROOT / file_path
        if full_path.exists():
            print(f"  - {file_path}")
        else:
            print(f"  - {file_path} (ä¸å­˜åœ¨)")
    
    # æ˜¾ç¤ºå°†è¦ä¿ç•™çš„æ–‡ä»¶
    print("\nâœ… å°†ä¿ç•™çš„æ–‡ä»¶:")
    for file_path in retention_plan["keep"]:
        full_path = PROJECT_ROOT / file_path
        if full_path.exists():
            print(f"  + {file_path}")
        else:
            print(f"  + {file_path} (ä¸å­˜åœ¨)")
            retention_plan["analyze"].append(file_path)
    
    # ç¡®è®¤åˆ é™¤
    confirm = input("\nâš ï¸ ç¡®è®¤æ‰§è¡Œæ¸…ç†ï¼Ÿ(è¾“å…¥ 'yes' ç¡®è®¤): ")
    if confirm.lower() != 'yes':
        print("âŒ æ¸…ç†å·²å–æ¶ˆ")
        return False
    
    # æ‰§è¡Œåˆ é™¤
    for file_path in retention_plan["delete"]:
        full_path = PROJECT_ROOT / file_path
        try:
            if full_path.exists():
                # å¤‡ä»½åˆ°å›æ”¶ç«™ç›®å½•
                trash_dir = PROJECT_ROOT / ".trash"
                trash_dir.mkdir(exist_ok=True)
                
                backup_name = file_path.replace('/', '_').replace('\\', '_')
                backup_path = trash_dir / backup_name
                shutil.move(str(full_path), str(backup_path))
                deleted_files.append(file_path)
                print(f"ğŸ—‘ï¸ å·²ç§»åŠ¨: {file_path} -> .trash/{backup_path.name}")
        except Exception as e:
            error_msg = f"åˆ é™¤ {file_path} å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            errors.append(error_msg)
    
    # ç”Ÿæˆæ¸…ç†æŠ¥å‘Š
    generate_cleanup_report(deleted_files, errors, retention_plan)
    
    return len(errors) == 0

def generate_cleanup_report(deleted_files, errors, retention_plan):
    """ç”Ÿæˆæ¸…ç†æŠ¥å‘Š"""
    report = {
        "cleanup_date": "2025-11-13",
        "strategy": "æ¸è¿›å¼æ¿€è¿›æ¸…ç†",
        "deleted_files": deleted_files,
        "kept_files": retention_plan["keep"],
        "errors": errors,
        "summary": {
            "total_deleted": len(deleted_files),
            "total_kept": len(retention_plan["keep"]),
            "errors_count": len(errors)
        }
    }
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = PROJECT_ROOT / "æ¸…ç†æŠ¥å‘Š_20251113.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“Š æ¸…ç†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§¹ å¼€å§‹Aé¡¹ç›®æ¸è¿›å¼æ¸…ç†")
    print("=" * 50)
    
    # åˆ†æé‡å¤æ–‡ä»¶
    duplicates = get_duplicate_files_analysis()
    print(f"ğŸ” å‘ç° {len(duplicates)} ç±»é‡å¤æ–‡ä»¶")
    
    # åˆ†æç‰ˆæœ¬å¹¶åˆ¶å®šä¿ç•™è®¡åˆ’
    retention_plan = analyze_file_versions(duplicates)
    
    # æ‰§è¡Œæ¸…ç†
    success = execute_cleanup(retention_plan)
    
    if success:
        print("\nâœ… æ¸…ç†å®Œæˆï¼é¡¹ç›®ç»“æ„å·²ä¼˜åŒ–")
    else:
        print("\nâš ï¸ æ¸…ç†å®Œæˆä½†æœ‰é”™è¯¯ï¼Œè¯·æŸ¥çœ‹æŠ¥å‘Š")
    
    return success

if __name__ == "__main__":
    main()