#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ§  å†…å­˜ä¼˜åŒ–å·¥å…· (Memory Optimization Tools)
=============================================

æä¾›å†…å­˜ä½¿ç”¨ä¼˜åŒ–å’Œç®¡ç†åŠŸèƒ½ï¼š
- å†…å­˜ä½¿ç”¨ç›‘æ§
- è‡ªåŠ¨åƒåœ¾å›æ”¶
- å†…å­˜æ³„æ¼æ£€æµ‹
- å¤§å¯¹è±¡ä¼˜åŒ–
- å†…å­˜æ± ç®¡ç†

ç‰¹æ€§ï¼š
- å®æ—¶å†…å­˜ç›‘æ§
- æ™ºèƒ½åƒåœ¾å›æ”¶
- å†…å­˜ä½¿ç”¨åˆ†æ
- æ€§èƒ½ä¼˜åŒ–å»ºè®®

ä½œè€…: iFlowæ€§èƒ½ä¼˜åŒ–å›¢é˜Ÿ
ç‰ˆæœ¬: 1.0.0
æ—¥æœŸ: 2025-11-16
"""

import gc
import sys
import time
import threading
import psutil
import traceback
from pathlib import Path
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, field
from datetime import datetime
import weakref
import logging

logger = logging.getLogger(__name__)

@dataclass
class MemoryStats:
    """å†…å­˜ç»Ÿè®¡ä¿¡æ¯"""
    total_mb: float = 0.0
    used_mb: float = 0.0
    available_mb: float = 0.0
    percent_used: float = 0.0
    process_mb: float = 0.0
    gc_counts: Dict[int, int] = field(default_factory=dict)
    object_count: int = 0
    large_objects: List[str] = field(default_factory=list)

@dataclass
class MemoryLeakInfo:
    """å†…å­˜æ³„æ¼ä¿¡æ¯"""
    object_type: str
    count: int
    size_mb: float
    growth_rate: float
    suspicious: bool = False

class MemoryMonitor:
    """å†…å­˜ç›‘æ§å™¨"""
    
    def __init__(self, check_interval: float = 30.0, alert_threshold: float = 80.0):
        """
        åˆå§‹åŒ–å†…å­˜ç›‘æ§å™¨
        
        Args:
            check_interval: æ£€æŸ¥é—´éš”(ç§’)
            alert_threshold: å†…å­˜ä½¿ç”¨è­¦å‘Šé˜ˆå€¼(%)
        """
        self.check_interval = check_interval
        self.alert_threshold = alert_threshold
        self.process = psutil.Process()
        
        # ç›‘æ§å†å²
        self.history: List[MemoryStats] = []
        self.max_history = 100
        
        # ç›‘æ§çº¿ç¨‹
        self.monitoring = False
        self.monitor_thread = None
        
        # å›è°ƒå‡½æ•°
        self.alert_callbacks: List[Callable[[MemoryStats], None]] = []
        
        # å¯¹è±¡è·Ÿè¸ª
        self.object_tracker = ObjectTracker()
    
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        if self.monitoring:
            return
        
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_worker, daemon=True)
        self.monitor_thread.start()
        logger.info("å†…å­˜ç›‘æ§å·²å¯åŠ¨")
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5)
        logger.info("å†…å­˜ç›‘æ§å·²åœæ­¢")
    
    def add_alert_callback(self, callback: Callable[[MemoryStats], None]):
        """æ·»åŠ è­¦å‘Šå›è°ƒ"""
        self.alert_callbacks.append(callback)
    
    def get_current_stats(self) -> MemoryStats:
        """è·å–å½“å‰å†…å­˜ç»Ÿè®¡"""
        # ç³»ç»Ÿå†…å­˜
        memory = psutil.virtual_memory()
        
        # è¿›ç¨‹å†…å­˜
        process_memory = self.process.memory_info()
        
        # GCç»Ÿè®¡
        gc_stats = gc.get_count()
        gc_counts = {i: gc_stats[i] for i in range(len(gc_stats))}
        
        # å¯¹è±¡è®¡æ•°
        object_count = len(gc.get_objects())
        
        # å¤§å¯¹è±¡æ£€æµ‹
        large_objects = self._detect_large_objects()
        
        return MemoryStats(
            total_mb=memory.total / (1024 * 1024),
            used_mb=memory.used / (1024 * 1024),
            available_mb=memory.available / (1024 * 1024),
            percent_used=memory.percent,
            process_mb=process_memory.rss / (1024 * 1024),
            gc_counts=gc_counts,
            object_count=object_count,
            large_objects=large_objects
        )
    
    def _detect_large_objects(self, threshold_mb: float = 1.0) -> List[str]:
        """æ£€æµ‹å¤§å¯¹è±¡"""
        large_objects = []
        threshold_bytes = threshold_mb * 1024 * 1024
        
        try:
            all_objects = gc.get_objects()
            for obj in all_objects[:1000]:  # é™åˆ¶æ£€æŸ¥æ•°é‡ä»¥é¿å…æ€§èƒ½é—®é¢˜
                try:
                    size = sys.getsizeof(obj)
                    if size > threshold_bytes:
                        obj_type = type(obj).__name__
                        obj_id = id(obj)
                        large_objects.append(f"{obj_type}:{obj_id}:{size/1024/1024:.2f}MB")
                except:
                    continue
        except Exception as e:
            logger.debug(f"å¤§å¯¹è±¡æ£€æµ‹å¤±è´¥: {e}")
        
        return large_objects[:10]  # è¿”å›å‰10ä¸ªæœ€å¤§çš„å¯¹è±¡
    
    def _monitor_worker(self):
        """ç›‘æ§å·¥ä½œçº¿ç¨‹"""
        while self.monitoring:
            try:
                stats = self.get_current_stats()
                
                # æ·»åŠ åˆ°å†å²
                self.history.append(stats)
                if len(self.history) > self.max_history:
                    self.history.pop(0)
                
                # æ£€æŸ¥è­¦å‘Šé˜ˆå€¼
                if stats.percent_used > self.alert_threshold:
                    self._trigger_alert(stats)
                
                # è‡ªåŠ¨åƒåœ¾å›æ”¶
                if stats.percent_used > 90:
                    self._auto_gc()
                
                time.sleep(self.check_interval)
                
            except Exception as e:
                logger.error(f"å†…å­˜ç›‘æ§é”™è¯¯: {e}")
                time.sleep(self.check_interval)
    
    def _trigger_alert(self, stats: MemoryStats):
        """è§¦å‘å†…å­˜è­¦å‘Š"""
        logger.warning(f"å†…å­˜ä½¿ç”¨è¿‡é«˜: {stats.percent_used:.1f}%")
        
        for callback in self.alert_callbacks:
            try:
                callback(stats)
            except Exception as e:
                logger.error(f"å†…å­˜è­¦å‘Šå›è°ƒå¤±è´¥: {e}")
    
    def _auto_gc(self):
        """è‡ªåŠ¨åƒåœ¾å›æ”¶"""
        logger.info("æ‰§è¡Œè‡ªåŠ¨åƒåœ¾å›æ”¶")
        
        # æ‰§è¡Œå¤šä»£åƒåœ¾å›æ”¶
        collected = gc.collect()
        logger.info(f"åƒåœ¾å›æ”¶å®Œæˆ: å›æ”¶äº† {collected} ä¸ªå¯¹è±¡")
    
    def detect_memory_leaks(self, window_minutes: int = 10) -> List[MemoryLeakInfo]:
        """æ£€æµ‹å†…å­˜æ³„æ¼"""
        if len(self.history) < 2:
            return []
        
        # è®¡ç®—æ—¶é—´çª—å£
        current_time = time.time()
        window_start = current_time - (window_minutes * 60)
        
        # è¿‡æ»¤å†å²æ•°æ®
        recent_stats = [
            stat for stat in self.history
            if current_time - (len(self.history) - list(reversed(self.history)).index(stat)) * self.check_interval >= window_start
        ]
        
        if len(recent_stats) < 2:
            return []
        
        # åˆ†æå†…å­˜å¢é•¿
        leaks = []
        
        # è¿›ç¨‹å†…å­˜å¢é•¿
        first_process = recent_stats[0].process_mb
        last_process = recent_stats[-1].process_mb
        process_growth = (last_process - first_process) / first_process if first_process > 0 else 0
        
        if process_growth > 0.5:  # 50%å¢é•¿
            leaks.append(MemoryLeakInfo(
                object_type="ProcessMemory",
                count=1,
                size_mb=last_process - first_process,
                growth_rate=process_growth,
                suspicious=process_growth > 1.0
            ))
        
        # å¯¹è±¡æ•°é‡å¢é•¿
        first_objects = recent_stats[0].object_count
        last_objects = recent_stats[-1].object_count
        object_growth = (last_objects - first_objects) / first_objects if first_objects > 0 else 0
        
        if object_growth > 0.3:  # 30%å¢é•¿
            leaks.append(MemoryLeakInfo(
                object_type="ObjectCount",
                count=last_objects - first_objects,
                size_mb=0,  # æ— æ³•ç²¾ç¡®è®¡ç®—
                growth_rate=object_growth,
                suspicious=object_growth > 0.5
            ))
        
        return leaks

class ObjectTracker:
    """å¯¹è±¡è·Ÿè¸ªå™¨"""
    
    def __init__(self):
        self.tracked_objects: Dict[int, weakref.ref] = {}
        self.object_types: Dict[str, int] = {}
    
    def track_object(self, obj: Any, name: Optional[str] = None):
        """è·Ÿè¸ªå¯¹è±¡"""
        obj_id = id(obj)
        obj_type = type(obj).__name__
        
        # ä½¿ç”¨å¼±å¼•ç”¨é¿å…å½±å“åƒåœ¾å›æ”¶
        def cleanup(ref):
            if obj_id in self.tracked_objects:
                del self.tracked_objects[obj_id]
                self.object_types[obj_type] = self.object_types.get(obj_type, 0) - 1
                if self.object_types[obj_type] <= 0:
                    del self.object_types[obj_type]
        
        self.tracked_objects[obj_id] = weakref.ref(obj, cleanup)
        self.object_types[obj_type] = self.object_types.get(obj_type, 0) + 1
    
    def get_tracked_counts(self) -> Dict[str, int]:
        """è·å–è·Ÿè¸ªçš„å¯¹è±¡è®¡æ•°"""
        return self.object_types.copy()
    
    def cleanup_dead_references(self):
        """æ¸…ç†æ­»å¼•ç”¨"""
        dead_refs = [obj_id for obj_id, ref in self.tracked_objects.items() if ref() is None]
        for obj_id in dead_refs:
            del self.tracked_objects[obj_id]

class MemoryPool:
    """å†…å­˜æ± """
    
    def __init__(self, max_size: int = 100):
        self.max_size = max_size
        self.pool: List[Any] = []
        self.lock = threading.Lock()
    
    def get_object(self, object_type: type, *args, **kwargs) -> Any:
        """ä»æ± ä¸­è·å–å¯¹è±¡"""
        with self.lock:
            for obj in self.pool:
                if isinstance(obj, object_type):
                    self.pool.remove(obj)
                    return obj
            
            # æ± ä¸­æ²¡æœ‰ï¼Œåˆ›å»ºæ–°å¯¹è±¡
            return object_type(*args, **kwargs)
    
    def return_object(self, obj: Any):
        """å°†å¯¹è±¡è¿”å›æ± ä¸­"""
        with self.lock:
            if len(self.pool) < self.max_size:
                # é‡ç½®å¯¹è±¡çŠ¶æ€
                if hasattr(obj, 'reset'):
                    obj.reset()
                self.pool.append(obj)
    
    def clear_pool(self):
        """æ¸…ç©ºæ± """
        with self.lock:
            self.pool.clear()

class MemoryOptimizer:
    """å†…å­˜ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.monitor = MemoryMonitor()
        self.object_tracker = ObjectTracker()
        self.pools: Dict[str, MemoryPool] = {}
        
        # ä¼˜åŒ–ç­–ç•¥
        self.optimization_strategies = {
            'gc_tuning': self._tune_gc,
            'object_pooling': self._optimize_object_pooling,
            'large_object_handling': self._optimize_large_objects,
            'memory_pressure_handling': self._handle_memory_pressure
        }
    
    def start_optimization(self):
        """å¼€å§‹å†…å­˜ä¼˜åŒ–"""
        self.monitor.start_monitoring()
        self.monitor.add_alert_callback(self._on_memory_alert)
        logger.info("å†…å­˜ä¼˜åŒ–å·²å¯åŠ¨")
    
    def stop_optimization(self):
        """åœæ­¢å†…å­˜ä¼˜åŒ–"""
        self.monitor.stop_monitoring()
        logger.info("å†…å­˜ä¼˜åŒ–å·²åœæ­¢")
    
    def get_memory_stats(self) -> MemoryStats:
        """è·å–å†…å­˜ç»Ÿè®¡"""
        return self.monitor.get_current_stats()
    
    def detect_leaks(self) -> List[MemoryLeakInfo]:
        """æ£€æµ‹å†…å­˜æ³„æ¼"""
        return self.monitor.detect_memory_leaks()
    
    def optimize_memory(self, strategies: Optional[List[str]] = None):
        """æ‰§è¡Œå†…å­˜ä¼˜åŒ–"""
        if strategies is None:
            strategies = list(self.optimization_strategies.keys())
        
        for strategy in strategies:
            if strategy in self.optimization_strategies:
                try:
                    self.optimization_strategies[strategy]()
                    logger.info(f"æ‰§è¡Œå†…å­˜ä¼˜åŒ–ç­–ç•¥: {strategy}")
                except Exception as e:
                    logger.error(f"å†…å­˜ä¼˜åŒ–ç­–ç•¥å¤±è´¥ {strategy}: {e}")
    
    def _on_memory_alert(self, stats: MemoryStats):
        """å†…å­˜è­¦å‘Šå›è°ƒ"""
        logger.warning(f"å†…å­˜è­¦å‘Š: {stats.percent_used:.1f}% ä½¿ç”¨ç‡")
        
        # è‡ªåŠ¨ä¼˜åŒ–
        if stats.percent_used > 85:
            self.optimize_memory(['gc_tuning', 'memory_pressure_handling'])
    
    def _tune_gc(self):
        """è°ƒä¼˜åƒåœ¾å›æ”¶"""
        # è®¾ç½®åƒåœ¾å›æ”¶é˜ˆå€¼
        gc.set_threshold(700, 10, 10)
        
        # æ‰§è¡Œåƒåœ¾å›æ”¶
        collected = gc.collect()
        logger.info(f"åƒåœ¾å›æ”¶è°ƒä¼˜å®Œæˆ: å›æ”¶ {collected} ä¸ªå¯¹è±¡")
    
    def _optimize_object_pooling(self):
        """ä¼˜åŒ–å¯¹è±¡æ± """
        # æ¸…ç†æ­»å¼•ç”¨
        self.object_tracker.cleanup_dead_references()
        
        # æ¸…ç†è¿‡å¤§çš„æ± 
        for pool in self.pools.values():
            if len(pool.pool) > pool.max_size * 0.8:
                pool.clear_pool()
    
    def _optimize_large_objects(self):
        """ä¼˜åŒ–å¤§å¯¹è±¡"""
        stats = self.monitor.get_current_stats()
        
        # å¤„ç†å¤§å¯¹è±¡
        for obj_info in stats.large_objects:
            try:
                obj_type, obj_id, size = obj_info.split(':')
                logger.warning(f"å‘ç°å¤§å¯¹è±¡: {obj_type} {size}MB")
            except:
                continue
    
    def _handle_memory_pressure(self):
        """å¤„ç†å†…å­˜å‹åŠ›"""
        stats = self.monitor.get_current_stats()
        
        if stats.percent_used > 90:
            # ç´§æ€¥å†…å­˜æ¸…ç†
            logger.warning("æ‰§è¡Œç´§æ€¥å†…å­˜æ¸…ç†")
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()
            
            # æ¸…ç†æ‰€æœ‰å¯¹è±¡æ± 
            for pool in self.pools.values():
                pool.clear_pool()
            
            # æ¸…ç†è·Ÿè¸ªå™¨
            self.object_tracker.cleanup_dead_references()

# å…¨å±€å†…å­˜ä¼˜åŒ–å™¨
_global_optimizer: Optional[MemoryOptimizer] = None

def get_memory_optimizer() -> MemoryOptimizer:
    """è·å–å…¨å±€å†…å­˜ä¼˜åŒ–å™¨"""
    global _global_optimizer
    if _global_optimizer is None:
        _global_optimizer = MemoryOptimizer()
    return _global_optimizer

def start_memory_optimization():
    """å¯åŠ¨å†…å­˜ä¼˜åŒ–"""
    optimizer = get_memory_optimizer()
    optimizer.start_optimization()
    return optimizer

def stop_memory_optimization():
    """åœæ­¢å†…å­˜ä¼˜åŒ–"""
    optimizer = get_memory_optimizer()
    optimizer.stop_optimization()

# è£…é¥°å™¨
def memory_efficient(max_size_mb: float = 10.0):
    """å†…å­˜æ•ˆç‡è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            # æ£€æŸ¥å†…å­˜ä½¿ç”¨
            optimizer = get_memory_optimizer()
            stats = optimizer.get_memory_stats()
            
            if stats.process_mb > max_size_mb:
                optimizer.optimize_memory()
            
            return func(*args, **kwargs)
        return wrapper
    return decorator

if __name__ == "__main__":
    # æµ‹è¯•å†…å­˜ä¼˜åŒ–å·¥å…·
    print("ğŸ§  æµ‹è¯•å†…å­˜ä¼˜åŒ–å·¥å…·")
    
    # å¯åŠ¨å†…å­˜ä¼˜åŒ–
    optimizer = start_memory_optimization()
    
    # è·å–å†…å­˜ç»Ÿè®¡
    stats = optimizer.get_memory_stats()
    print(f"å½“å‰å†…å­˜ä½¿ç”¨: {stats.process_mb:.2f}MB ({stats.percent_used:.1f}%)")
    print(f"å¯¹è±¡æ•°é‡: {stats.object_count}")
    print(f"GCç»Ÿè®¡: {stats.gc_counts}")
    
    # æµ‹è¯•å¯¹è±¡è·Ÿè¸ª
    test_data = []
    for i in range(1000):
        data = {"id": i, "data": "x" * 100}
        optimizer.object_tracker.track_object(data)
        test_data.append(data)
    
    # æ£€æŸ¥è·Ÿè¸ªç»“æœ
    counts = optimizer.object_tracker.get_tracked_counts()
    print(f"è·Ÿè¸ªçš„å¯¹è±¡ç±»å‹: {counts}")
    
    # æ¨¡æ‹Ÿå†…å­˜å‹åŠ›
    large_data = "x" * (10 * 1024 * 1024)  # 10MB
    print(f"åˆ›å»ºå¤§å¯¹è±¡åå†…å­˜: {optimizer.get_memory_stats().process_mb:.2f}MB")
    
    # æ‰§è¡Œå†…å­˜ä¼˜åŒ–
    optimizer.optimize_memory()
    
    # æ¸…ç†
    del large_data
    del test_data
    
    print("âœ… å†…å­˜ä¼˜åŒ–å·¥å…·æµ‹è¯•å®Œæˆ")