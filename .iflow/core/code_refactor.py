#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ”§ ä»£ç é‡æ„å·¥å…· (Code Refactoring Tools)
=======================================

æä¾›ä»£ç é‡æ„å’Œè§„èŒƒåŒ–åŠŸèƒ½ï¼š
- é‡å¤ä»£ç æ£€æµ‹
- å‘½åè§„èŒƒç»Ÿä¸€
- ä»£ç ç»“æ„ä¼˜åŒ–
- è‡ªåŠ¨é‡æ„å»ºè®®
- ä»£ç è´¨é‡åˆ†æ

ç‰¹æ€§ï¼š
- æ™ºèƒ½é‡å¤ä»£ç æ£€æµ‹
- å‘½åè§„èŒƒæ£€æŸ¥å’Œä¿®å¤
- ä»£ç å¤æ‚åº¦åˆ†æ
- é‡æ„å»ºè®®ç”Ÿæˆ

ä½œè€…: iFlowä»£ç è´¨é‡å›¢é˜Ÿ
ç‰ˆæœ¬: 1.0.0
æ—¥æœŸ: 2025-11-16
"""

import os
import ast
import re
import json
import difflib
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from collections import defaultdict
import logging

logger = logging.getLogger(__name__)

@dataclass
class CodeIssue:
    """ä»£ç é—®é¢˜"""
    file_path: str
    line_number: int
    issue_type: str
    description: str
    severity: str  # low, medium, high, critical
    suggestion: str
    code_snippet: str

@dataclass
class DuplicateCodeBlock:
    """é‡å¤ä»£ç å—"""
    files: List[Tuple[str, int, int]]  # (file_path, start_line, end_line)
    similarity: float
    code_hash: str
    line_count: int

@dataclass
class NamingIssue:
    """å‘½åé—®é¢˜"""
    file_path: str
    line_number: int
    current_name: str
    issue_type: str
    suggestion: str
    severity: str

class CodeAnalyzer:
    """ä»£ç åˆ†æå™¨"""
    
    def __init__(self):
        self.issues: List[CodeIssue] = []
        self.duplicates: List[DuplicateCodeBlock] = []
        self.naming_issues: List[NamingIssue] = []
        
        # å‘½åè§„èŒƒ
        self.naming_patterns = {
            'variable': re.compile(r'^[a-z_][a-z0-9_]*$'),  # snake_case
            'function': re.compile(r'^[a-z_][a-z0-9_]*$'),  # snake_case
            'class': re.compile(r'^[A-Z][a-zA-Z0-9]*$'),  # PascalCase
            'constant': re.compile(r'^[A-Z_][A-Z0-9_]*$'),  # UPPER_CASE
            'private': re.compile(r'^_[a-z_][a-z0-9_]*$'),  # _snake_case
            'dunder': re.compile(r'^__[a-z_][a-z0-9_]*__$'),  # __snake_case__
        }
    
    def analyze_directory(self, directory: str, patterns: List[str] = None) -> Dict[str, Any]:
        """åˆ†æç›®å½•ä¸­çš„ä»£ç """
        if patterns is None:
            patterns = ['*.py']
        
        python_files = []
        for pattern in patterns:
            python_files.extend(Path(directory).rglob(pattern))
        
        logger.info(f"åˆ†æ {len(python_files)} ä¸ªPythonæ–‡ä»¶")
        
        # åˆ†ææ¯ä¸ªæ–‡ä»¶
        for file_path in python_files:
            self.analyze_file(str(file_path))
        
        # æ£€æµ‹é‡å¤ä»£ç 
        self.detect_duplicates(python_files)
        
        return {
            'issues': len(self.issues),
            'duplicates': len(self.duplicates),
            'naming_issues': len(self.naming_issues),
            'files_analyzed': len(python_files)
        }
    
    def analyze_file(self, file_path: str):
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è§£æAST
            tree = ast.parse(content)
            
            # åˆ†æå‘½åè§„èŒƒ
            self._analyze_naming(tree, file_path, content)
            
            # åˆ†æä»£ç ç»“æ„
            self._analyze_structure(tree, file_path, content)
            
        except Exception as e:
            logger.error(f"åˆ†ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
    
    def _analyze_naming(self, tree: ast.AST, file_path: str, content: str):
        """åˆ†æå‘½åè§„èŒƒ"""
        lines = content.split('\n')
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                self._check_function_naming(node, file_path, lines)
            elif isinstance(node, ast.ClassDef):
                self._check_class_naming(node, file_path, lines)
            elif isinstance(node, ast.Name):
                if isinstance(node.ctx, ast.Store):
                    self._check_variable_naming(node, file_path, lines)
    
    def _check_function_naming(self, node: ast.FunctionDef, file_path: str, lines: List[str]):
        """æ£€æŸ¥å‡½æ•°å‘½å"""
        name = node.name
        
        # æ£€æŸ¥æ˜¯å¦ç¬¦åˆè§„èŒƒ
        if not self.naming_patterns['function'].match(name):
            severity = 'high' if name.isupper() else 'medium'
            
            suggestion = self._suggest_function_name(name)
            
            self.naming_issues.append(NamingIssue(
                file_path=file_path,
                line_number=node.lineno,
                current_name=name,
                issue_type='function_naming',
                suggestion=suggestion,
                severity=severity
            ))
    
    def _check_class_naming(self, node: ast.ClassDef, file_path: str, lines: List[str]):
        """æ£€æŸ¥ç±»å‘½å"""
        name = node.name
        
        if not self.naming_patterns['class'].match(name):
            severity = 'high'
            
            suggestion = self._suggest_class_name(name)
            
            self.naming_issues.append(NamingIssue(
                file_path=file_path,
                line_number=node.lineno,
                current_name=name,
                issue_type='class_naming',
                suggestion=suggestion,
                severity=severity
            ))
    
    def _check_variable_naming(self, node: ast.Name, file_path: str, lines: List[str]):
        """æ£€æŸ¥å˜é‡å‘½å"""
        name = node.id
        
        # è·³è¿‡ç‰¹æ®Šå˜é‡
        if name.startswith('__') and name.endswith('__'):
            return
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸é‡
        if name.isupper():
            if not self.naming_patterns['constant'].match(name):
                suggestion = self._suggest_constant_name(name)
                self.naming_issues.append(NamingIssue(
                    file_path=file_path,
                    line_number=node.lineno,
                    current_name=name,
                    issue_type='constant_naming',
                    suggestion=suggestion,
                    severity='medium'
                ))
        else:
            # æ™®é€šå˜é‡
            if not self.naming_patterns['variable'].match(name):
                suggestion = self._suggest_variable_name(name)
                self.naming_issues.append(NamingIssue(
                    file_path=file_path,
                    line_number=node.lineno,
                    current_name=name,
                    issue_type='variable_naming',
                    suggestion=suggestion,
                    severity='low'
                ))
    
    def _suggest_function_name(self, name: str) -> str:
        """å»ºè®®å‡½æ•°å"""
        # è½¬æ¢ä¸ºsnake_case
        suggested = re.sub(r'(?<!^)(?=[A-Z])', '_', name).lower()
        return suggested if suggested != name else f"{name.lower()}_function"
    
    def _suggest_class_name(self, name: str) -> str:
        """å»ºè®®ç±»å"""
        # è½¬æ¢ä¸ºPascalCase
        suggested = ''.join(word.capitalize() for word in name.split('_'))
        return suggested if suggested != name else f"{name.capitalize()}Class"
    
    def _suggest_variable_name(self, name: str) -> str:
        """å»ºè®®å˜é‡å"""
        if name.isupper():
            return name.lower()
        elif name[0].isupper():
            return name[0].lower() + name[1:]
        else:
            return f"{name}_var"
    
    def _suggest_constant_name(self, name: str) -> str:
        """å»ºè®®å¸¸é‡å"""
        return name.upper()
    
    def _analyze_structure(self, tree: ast.AST, file_path: str, content: str):
        """åˆ†æä»£ç ç»“æ„"""
        lines = content.split('\n')
        
        # æ£€æŸ¥å‡½æ•°å¤æ‚åº¦
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                self._check_function_complexity(node, file_path, lines)
            elif isinstance(node, ast.ClassDef):
                self._check_class_complexity(node, file_path, lines)
    
    def _check_function_complexity(self, node: ast.FunctionDef, file_path: str, lines: List[str]):
        """æ£€æŸ¥å‡½æ•°å¤æ‚åº¦"""
        # è®¡ç®—åœˆå¤æ‚åº¦
        complexity = 1
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.ExceptHandler)):
                complexity += 1
        
        # æ£€æŸ¥å‡½æ•°é•¿åº¦
        func_lines = node.end_lineno - node.lineno + 1
        
        if complexity > 10:
            severity = 'high' if complexity > 20 else 'medium'
            self.issues.append(CodeIssue(
                file_path=file_path,
                line_number=node.lineno,
                issue_type='high_complexity',
                description=f"å‡½æ•° '{node.name}' åœˆå¤æ‚åº¦è¿‡é«˜: {complexity}",
                severity=severity,
                suggestion="è€ƒè™‘æ‹†åˆ†å‡½æ•°æˆ–ç®€åŒ–é€»è¾‘",
                code_snippet=lines[node.lineno - 1] if node.lineno <= len(lines) else ""
            ))
        
        if func_lines > 50:
            self.issues.append(CodeIssue(
                file_path=file_path,
                line_number=node.lineno,
                issue_type='long_function',
                description=f"å‡½æ•° '{node.name}' è¿‡é•¿: {func_lines} è¡Œ",
                severity='medium',
                suggestion="è€ƒè™‘æ‹†åˆ†ä¸ºæ›´å°çš„å‡½æ•°",
                code_snippet=lines[node.lineno - 1] if node.lineno <= len(lines) else ""
            ))
    
    def _check_class_complexity(self, node: ast.ClassDef, file_path: str, lines: List[str]):
        """æ£€æŸ¥ç±»å¤æ‚åº¦"""
        methods = [n for n in node.body if isinstance(n, ast.FunctionDef)]
        
        if len(methods) > 20:
            self.issues.append(CodeIssue(
                file_path=file_path,
                line_number=node.lineno,
                issue_type='large_class',
                description=f"ç±» '{node.name}' æ–¹æ³•è¿‡å¤š: {len(methods)}",
                severity='medium',
                suggestion="è€ƒè™‘æ‹†åˆ†ä¸ºå¤šä¸ªç±»æˆ–ä½¿ç”¨ç»„åˆæ¨¡å¼",
                code_snippet=lines[node.lineno - 1] if node.lineno <= len(lines) else ""
            ))
    
    def detect_duplicates(self, files: List[Path], min_lines: int = 5):
        """æ£€æµ‹é‡å¤ä»£ç """
        code_blocks = {}
        
        for file_path in files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                lines = content.split('\n')
                
                # æå–ä»£ç å—ï¼ˆå‡½æ•°ã€ç±»ç­‰ï¼‰
                for i, line in enumerate(lines):
                    if len(line.strip()) >= min_lines:
                        # ç®€å•çš„å“ˆå¸Œï¼ˆå®é™…ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„ç®—æ³•ï¼‰
                        block_hash = hash(line.strip())
                        
                        if block_hash not in code_blocks:
                            code_blocks[block_hash] = []
                        
                        code_blocks[block_hash].append((str(file_path), i + 1, i + 1))
                        
            except Exception as e:
                logger.error(f"æ£€æµ‹é‡å¤ä»£ç å¤±è´¥ {file_path}: {e}")
        
        # æ‰¾å‡ºé‡å¤çš„ä»£ç å—
        for block_hash, occurrences in code_blocks.items():
            if len(occurrences) > 1:
                self.duplicates.append(DuplicateCodeBlock(
                    files=occurrences,
                    similarity=1.0,  # ç®€åŒ–å¤„ç†
                    code_hash=str(block_hash),
                    line_count=1
                ))

class CodeRefactor:
    """ä»£ç é‡æ„å™¨"""
    
    def __init__(self):
        self.analyzer = CodeAnalyzer()
        self.refactoring_rules = {
            'extract_function': self._extract_function,
            'rename_variable': self._rename_variable,
            'simplify_condition': self._simplify_condition,
            'remove_duplicates': self._remove_duplicates
        }
    
    def refactor_directory(self, directory: str, auto_fix: bool = False) -> Dict[str, Any]:
        """é‡æ„ç›®å½•ä¸­çš„ä»£ç """
        # åˆ†æä»£ç 
        analysis_result = self.analyzer.analyze_directory(directory)
        
        refactoring_plan = {
            'analysis': analysis_result,
            'fixes': [],
            'auto_fixes': []
        }
        
        # ç”Ÿæˆä¿®å¤å»ºè®®
        for issue in self.analyzer.issues:
            fix = self._generate_fix_suggestion(issue)
            refactoring_plan['fixes'].append(fix)
        
        for naming_issue in self.analyzer.naming_issues:
            fix = self._generate_naming_fix(naming_issue)
            refactoring_plan['fixes'].append(fix)
        
        for duplicate in self.analyzer.duplicates:
            fix = self._generate_duplicate_fix(duplicate)
            refactoring_plan['fixes'].append(fix)
        
        # è‡ªåŠ¨ä¿®å¤
        if auto_fix:
            auto_fixes = self._apply_auto_fixes(directory)
            refactoring_plan['auto_fixes'] = auto_fixes
        
        return refactoring_plan
    
    def _generate_fix_suggestion(self, issue: CodeIssue) -> Dict[str, Any]:
        """ç”Ÿæˆä¿®å¤å»ºè®®"""
        return {
            'type': 'issue_fix',
            'file_path': issue.file_path,
            'line_number': issue.line_number,
            'issue_type': issue.issue_type,
            'description': issue.description,
            'suggestion': issue.suggestion,
            'severity': issue.severity,
            'auto_fixable': issue.issue_type in ['long_function', 'large_class']
        }
    
    def _generate_naming_fix(self, naming_issue: NamingIssue) -> Dict[str, Any]:
        """ç”Ÿæˆå‘½åä¿®å¤å»ºè®®"""
        return {
            'type': 'naming_fix',
            'file_path': naming_issue.file_path,
            'line_number': naming_issue.line_number,
            'current_name': naming_issue.current_name,
            'suggested_name': naming_issue.suggestion,
            'issue_type': naming_issue.issue_type,
            'severity': naming_issue.severity,
            'auto_fixable': naming_issue.severity in ['low', 'medium']
        }
    
    def _generate_duplicate_fix(self, duplicate: DuplicateCodeBlock) -> Dict[str, Any]:
        """ç”Ÿæˆé‡å¤ä»£ç ä¿®å¤å»ºè®®"""
        return {
            'type': 'duplicate_fix',
            'files': duplicate.files,
            'similarity': duplicate.similarity,
            'suggestion': "æå–å…¬å…±å‡½æ•°æˆ–ä½¿ç”¨ç»§æ‰¿",
            'auto_fixable': False
        }
    
    def _apply_auto_fixes(self, directory: str) -> List[Dict[str, Any]]:
        """åº”ç”¨è‡ªåŠ¨ä¿®å¤"""
        auto_fixes = []
        
        # è¿™é‡Œå¯ä»¥å®ç°å…·ä½“çš„è‡ªåŠ¨ä¿®å¤é€»è¾‘
        # ä¾‹å¦‚ï¼šè‡ªåŠ¨é‡å‘½åå˜é‡ã€æå–å‡½æ•°ç­‰
        
        return auto_fixes
    
    def _extract_function(self, file_path: str, start_line: int, end_line: int):
        """æå–å‡½æ•°"""
        # å®ç°å‡½æ•°æå–é€»è¾‘
        pass
    
    def _rename_variable(self, file_path: str, old_name: str, new_name: str):
        """é‡å‘½åå˜é‡"""
        # å®ç°å˜é‡é‡å‘½åé€»è¾‘
        pass
    
    def _simplify_condition(self, file_path: str, line_number: int):
        """ç®€åŒ–æ¡ä»¶"""
        # å®ç°æ¡ä»¶ç®€åŒ–é€»è¾‘
        pass
    
    def _remove_duplicates(self, duplicate: DuplicateCodeBlock):
        """ç§»é™¤é‡å¤ä»£ç """
        # å®ç°é‡å¤ä»£ç ç§»é™¤é€»è¾‘
        pass

class NamingStandardizer:
    """å‘½åè§„èŒƒåŒ–å™¨"""
    
    def __init__(self):
        self.conversion_rules = {
            'camel_to_snake': self._camel_to_snake,
            'snake_to_camel': self._snake_to_camel,
            'snake_to_pascal': self._snake_to_pascal,
            'normalize': self._normalize_name
        }
    
    def standardize_name(self, name: str, target_style: str) -> str:
        """æ ‡å‡†åŒ–åç§°"""
        if target_style in self.conversion_rules:
            return self.conversion_rules[target_style](name)
        return name
    
    def _camel_to_snake(self, name: str) -> str:
        """é©¼å³°è½¬ä¸‹åˆ’çº¿"""
        return re.sub(r'(?<!^)(?=[A-Z])', '_', name).lower()
    
    def _snake_to_camel(self, name: str) -> str:
        """ä¸‹åˆ’çº¿è½¬é©¼å³°"""
        components = name.split('_')
        return components[0] + ''.join(word.capitalize() for word in components[1:])
    
    def _snake_to_pascal(self, name: str) -> str:
        """ä¸‹åˆ’çº¿è½¬å¸•æ–¯å¡"""
        return ''.join(word.capitalize() for word in name.split('_'))
    
    def _normalize_name(self, name: str) -> str:
        """æ ‡å‡†åŒ–åç§°"""
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œè½¬æ¢ä¸ºä¸‹åˆ’çº¿
        normalized = re.sub(r'[^a-zA-Z0-9_]', '_', name)
        # ç§»é™¤å¤šä½™çš„ä¸‹åˆ’çº¿
        normalized = re.sub(r'_+', '_', normalized)
        # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„ä¸‹åˆ’çº¿
        normalized = normalized.strip('_')
        return normalized.lower()

def create_refactoring_report(directory: str) -> str:
    """åˆ›å»ºé‡æ„æŠ¥å‘Š"""
    refactor = CodeRefactor()
    result = refactor.refactor_directory(directory)
    
    report = f"""
# ä»£ç é‡æ„æŠ¥å‘Š

## åˆ†ææ¦‚è§ˆ
- åˆ†ææ–‡ä»¶æ•°: {result['analysis']['files_analyzed']}
- å‘ç°é—®é¢˜æ•°: {result['analysis']['issues']}
- é‡å¤ä»£ç å—: {result['analysis']['duplicates']}
- å‘½åé—®é¢˜: {result['analysis']['naming_issues']}

## ä¿®å¤å»ºè®®
"""
    
    for fix in result['fixes']:
        report += f"""
### {fix['issue_type'].replace('_', ' ').title()}
- **æ–‡ä»¶**: {fix['file_path']}
- **è¡Œå·**: {fix.get('line_number', 'N/A')}
- **ä¸¥é‡ç¨‹åº¦**: {fix['severity']}
- **æè¿°**: {fix.get('description', fix.get('current_name', 'N/A'))}
- **å»ºè®®**: {fix['suggestion']}
- **å¯è‡ªåŠ¨ä¿®å¤**: {'æ˜¯' if fix.get('auto_fixable') else 'å¦'}

"""
    
    return report

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç é‡æ„å·¥å…·
    print("ğŸ”§ æµ‹è¯•ä»£ç é‡æ„å·¥å…·")
    
    # åˆ†æå½“å‰ç›®å½•
    analyzer = CodeAnalyzer()
    result = analyzer.analyze_directory(".", ["*.py"])
    
    print(f"åˆ†æç»“æœ: {result}")
    
    # ç”Ÿæˆé‡æ„æŠ¥å‘Š
    report = create_refactoring_report(".")
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = "code_refactoring_report.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"âœ… é‡æ„æŠ¥å‘Šå·²ä¿å­˜: {report_file}")