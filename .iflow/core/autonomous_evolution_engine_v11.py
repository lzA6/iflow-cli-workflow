#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ§¬ è‡ªä¸»è¿›åŒ–å¼•æ“ V11 (ä»£å·ï¼š"æ™®ç½—ç±³ä¿®æ–¯ä¹‹ç«")
==========================================================

æœ¬æ–‡ä»¶æ˜¯ T-MIA å‡¤å‡°æ¶æ„ä¸‹çš„è‡ªä¸»è¿›åŒ–å¼•æ“å®ç°ï¼Œæä¾›ï¼š
- è‡ªæˆ‘æ”¹è¿›æœºåˆ¶
- åˆ›æ–°èƒ½åŠ›åŸ¹å…»
- ç³»ç»Ÿè‡ªé€‚åº”ä¼˜åŒ–
- é—ä¼ ç®—æ³•è¿›åŒ–
- ç¥ç»æ¶æ„æœç´¢

ä½ ä¸€å®šè¦è¶…çº§æ€è€ƒã€æé™æ€è€ƒã€æ·±åº¦æ€è€ƒï¼Œå…¨åŠ›æ€è€ƒã€è¶…å¼ºæ€è€ƒï¼Œè®¤çœŸä»”ç»†æ€è€ƒï¼ˆultrathinkã€think really super hardã€think intenselyï¼‰ã€‚

ä½œè€…: AIæ¶æ„å¸ˆå›¢é˜Ÿ
ç‰ˆæœ¬: 11.0.0 (ä»£å·ï¼š"æ™®ç½—ç±³ä¿®æ–¯ä¹‹ç«")
æ—¥æœŸ: 2025-11-15
"""

import os
import sys
import json
import asyncio
import logging
import numpy as np
import pickle
import random
import copy
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Union, Callable
from dataclasses import dataclass, field, asdict
from datetime import datetime
from enum import Enum
from collections import defaultdict
import hashlib

# --- åŠ¨æ€è·¯å¾„è®¾ç½® ---
try:
    PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
    if str(PROJECT_ROOT) not in sys.path:
        sys.path.insert(0, str(PROJECT_ROOT))
except Exception as e:
    PROJECT_ROOT = Path.cwd()
    print(f"è­¦å‘Š: è·¯å¾„è§£æå¤±è´¥ï¼Œå›é€€åˆ°å½“å‰å·¥ä½œç›®å½•: {PROJECT_ROOT}. é”™è¯¯: {e}")

# --- æ—¥å¿—é…ç½® ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("AutonomousEvolutionEngineV11")

# --- æšä¸¾å®šä¹‰ ---
class EvolutionStrategy(Enum):
    """è¿›åŒ–ç­–ç•¥"""
    GENETIC_ALGORITHM = "genetic_algorithm"
    NEURAL_ARCHITECTURE_SEARCH = "neural_architecture_search"
    REINFORCEMENT_LEARNING = "reinforcement_learning"
    BAYESIAN_OPTIMIZATION = "bayesian_optimization"
    ENSEMBLE_LEARNING = "ensemble_learning"

class MutationType(Enum):
    """å˜å¼‚ç±»å‹"""
    PARAMETER_MUTATION = "parameter_mutation"
    STRUCTURE_MUTATION = "structure_mutation"
    ARCHITECTURE_MUTATION = "architecture_mutation"
    HYPERPARAMETER_MUTATION = "hyperparameter_mutation"
    BEHAVIORAL_MUTATION = "behavioral_mutation"

# --- æ•°æ®ç»“æ„å®šä¹‰ ---
@dataclass
class Genome:
    """åŸºå› ç»„"""
    genes: Dict[str, Any]
    fitness: float = 0.0
    generation: int = 0
    parent_ids: List[str] = field(default_factory=list)
    mutation_history: List[str] = field(default_factory=list)
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())

@dataclass
class EvolutionRecord:
    """è¿›åŒ–è®°å½•"""
    generation: int
    population_size: int
    best_fitness: float
    average_fitness: float
    mutations_applied: List[str]
    innovations_discovered: List[str]
    performance_metrics: Dict[str, float]
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())

@dataclass
class Innovation:
    """åˆ›æ–°"""
    innovation_id: str
    description: str
    category: str
    impact_score: float
    implementation_code: Optional[str] = None
    test_results: Optional[Dict[str, Any]] = None
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())

class AutonomousEvolutionEngineV11:
    """è‡ªä¸»è¿›åŒ–å¼•æ“ V11 å®ç°"""
    
    def __init__(self, population_size: int = 20, mutation_rate: float = 0.1, crossover_rate: float = 0.7):
        self.population_size = population_size
        self.mutation_rate = mutation_rate
        self.crossover_rate = crossover_rate
        self.generation = 0
        self.population: List[Genome] = []
        self.evolution_history: List[EvolutionRecord] = []
        self.innovation_registry: List[Innovation] = []
        self.performance_cache: Dict[str, float] = {}
        self.best_genome: Optional[Genome] = None
        
        # è¿›åŒ–ç­–ç•¥é…ç½®
        self.active_strategies = [
            EvolutionStrategy.GENETIC_ALGORITHM,
            EvolutionStrategy.NEURAL_ARCHITECTURE_SEARCH,
            EvolutionStrategy.REINFORCEMENT_LEARNING
        ]
        
        # åˆå§‹åŒ–ç§ç¾¤
        self._initialize_population()
        logger.info("AutonomousEvolutionEngineV11 åˆå§‹åŒ–å®Œæˆï¼Œè¿›åŒ–å¼•æ“å·²å¯åŠ¨")
    
    def _initialize_population(self):
        """åˆå§‹åŒ–ç§ç¾¤"""
        logger.info("ğŸ§¬ åˆå§‹åŒ–è¿›åŒ–ç§ç¾¤...")
        
        for i in range(self.population_size):
            genome = Genome(
                genes=self._generate_random_genes(),
                generation=0,
                parent_ids=[]
            )
            self.population.append(genome)
        
        # è¯„ä¼°åˆå§‹ç§ç¾¤
        self._evaluate_population()
        
        # è®°å½•æœ€ä½³ä¸ªä½“
        self.best_genome = max(self.population, key=lambda g: g.fitness)
        
        logger.info(f"âœ… åˆå§‹åŒ–å®Œæˆï¼Œç§ç¾¤å¤§å°: {len(self.population)}, æœ€ä½³é€‚åº”åº¦: {self.best_genome.fitness:.4f}")
    
    def _generate_random_genes(self) -> Dict[str, Any]:
        """ç”ŸæˆéšæœºåŸºå› """
        genes = {
            # ç¥ç»ç½‘ç»œæ¶æ„åŸºå› 
            'neural_layers': [
                {'type': 'dense', 'units': random.choice([64, 128, 256, 512]), 'activation': random.choice(['relu', 'tanh', 'sigmoid'])},
                {'type': 'attention', 'heads': random.choice([4, 8, 16]), 'dim': random.choice([64, 128, 256])},
                {'type': 'dense', 'units': random.choice([32, 64, 128]), 'activation': random.choice(['relu', 'tanh'])}
            ],
            
            # è¶…å‚æ•°åŸºå› 
            'learning_rate': 10 ** random.uniform(-4, -1),
            'batch_size': random.choice([16, 32, 64, 128]),
            'dropout_rate': random.uniform(0.1, 0.5),
            'momentum': random.uniform(0.8, 0.99),
            
            # ç®—æ³•é€‰æ‹©åŸºå› 
            'optimizer': random.choice(['adam', 'sgd', 'rmsprop', 'adagrad']),
            'loss_function': random.choice(['mse', 'crossentropy', 'hinge', 'huber']),
            'regularization': random.choice(['l1', 'l2', 'elasticnet', 'none']),
            
            # è¡Œä¸ºåŸºå› 
            'exploration_rate': random.uniform(0.1, 0.9),
            'exploitation_rate': random.uniform(0.1, 0.9),
            'innovation_tendency': random.uniform(0.1, 0.9),
            'cooperation_level': random.uniform(0.1, 0.9),
            
            # å…ƒè®¤çŸ¥åŸºå› 
            'meta_learning_rate': 10 ** random.uniform(-5, -2),
            'self_attention_depth': random.randint(1, 5),
            'memory_capacity': random.choice([512, 1024, 2048, 4096]),
            'reflection_frequency': random.uniform(0.1, 1.0)
        }
        
        return genes
    
    def _evaluate_population(self):
        """è¯„ä¼°ç§ç¾¤é€‚åº”åº¦"""
        logger.info("ğŸ“Š è¯„ä¼°ç§ç¾¤é€‚åº”åº¦...")
        
        for genome in self.population:
            # è®¡ç®—é€‚åº”åº¦
            genome.fitness = self._calculate_fitness(genome.genes)
            
            # ç¼“å­˜æ€§èƒ½
            genome_hash = self._hash_genome(genome)
            self.performance_cache[genome_hash] = genome.fitness
    
    def _calculate_fitness(self, genes: Dict[str, Any]) -> float:
        """è®¡ç®—åŸºå› ç»„é€‚åº”åº¦"""
        fitness = 0.0
        
        # æ¶æ„å¤æ‚åº¦è¯„åˆ†
        architecture_score = self._evaluate_architecture(genes.get('neural_layers', []))
        fitness += architecture_score * 0.3
        
        # è¶…å‚æ•°ä¼˜åŒ–è¯„åˆ†
        hyperparameter_score = self._evaluate_hyperparameters(genes)
        fitness += hyperparameter_score * 0.25
        
        # è¡Œä¸ºé€‚åº”æ€§è¯„åˆ†
        behavioral_score = self._evaluate_behavior(genes)
        fitness += behavioral_score * 0.25
        
        # å…ƒè®¤çŸ¥èƒ½åŠ›è¯„åˆ†
        metacognitive_score = self._evaluate_metacognition(genes)
        fitness += metacognitive_score * 0.2
        
        return fitness
    
    def _evaluate_architecture(self, layers: List[Dict[str, Any]]) -> float:
        """è¯„ä¼°ç¥ç»ç½‘ç»œæ¶æ„"""
        if not layers:
            return 0.1
        
        score = 0.0
        
        # å±‚å¤šæ ·æ€§å¥–åŠ±
        layer_types = set(layer['type'] for layer in layers)
        score += len(layer_types) * 0.1
        
        # æ·±åº¦é€‚ä¸­æ€§
        if 2 <= len(layers) <= 5:
            score += 0.3
        elif 5 < len(layers) <= 8:
            score += 0.2
        
        # æ³¨æ„åŠ›æœºåˆ¶å¥–åŠ±
        has_attention = any(layer['type'] == 'attention' for layer in layers)
        if has_attention:
            score += 0.3
        
        # å‚æ•°æ•°é‡åˆç†æ€§
        total_params = sum(
            layer.get('units', 64) * layer.get('units', 64) 
            for layer in layers if layer['type'] == 'dense'
        )
        if 1000 <= total_params <= 100000:
            score += 0.3
        
        return min(1.0, score)
    
    def _evaluate_hyperparameters(self, genes: Dict[str, Any]) -> float:
        """è¯„ä¼°è¶…å‚æ•°"""
        score = 0.0
        
        # å­¦ä¹ ç‡åˆç†æ€§
        lr = genes.get('learning_rate', 0.001)
        if 0.0001 <= lr <= 0.01:
            score += 0.25
        
        # æ‰¹æ¬¡å¤§å°åˆç†æ€§
        batch_size = genes.get('batch_size', 32)
        if 16 <= batch_size <= 128:
            score += 0.25
        
        # Dropoutç‡åˆç†æ€§
        dropout = genes.get('dropout_rate', 0.2)
        if 0.1 <= dropout <= 0.5:
            score += 0.25
        
        # ä¼˜åŒ–å™¨é€‰æ‹©
        optimizer = genes.get('optimizer', 'adam')
        if optimizer in ['adam', 'rmsprop']:
            score += 0.25
        
        return score
    
    def _evaluate_behavior(self, genes: Dict[str, Any]) -> float:
        """è¯„ä¼°è¡Œä¸ºç‰¹å¾"""
        score = 0.0
        
        # æ¢ç´¢-åˆ©ç”¨å¹³è¡¡
        exploration = genes.get('exploration_rate', 0.5)
        exploitation = genes.get('exploitation_rate', 0.5)
        balance = 1.0 - abs(exploration - exploitation)
        score += balance * 0.3
        
        # åˆ›æ–°å€¾å‘
        innovation = genes.get('innovation_tendency', 0.5)
        if 0.3 <= innovation <= 0.8:
            score += 0.35
        
        # åˆä½œæ°´å¹³
        cooperation = genes.get('cooperation_level', 0.5)
        if cooperation > 0.3:
            score += 0.35
        
        return score
    
    def _evaluate_metacognition(self, genes: Dict[str, Any]) -> float:
        """è¯„ä¼°å…ƒè®¤çŸ¥èƒ½åŠ›"""
        score = 0.0
        
        # å…ƒå­¦ä¹ ç‡
        meta_lr = genes.get('meta_learning_rate', 0.001)
        if 0.00001 <= meta_lr <= 0.001:
            score += 0.25
        
        # è‡ªæ³¨æ„åŠ›æ·±åº¦
        attention_depth = genes.get('self_attention_depth', 2)
        if 1 <= attention_depth <= 4:
            score += 0.25
        
        # è®°å¿†å®¹é‡
        memory = genes.get('memory_capacity', 1024)
        if memory >= 512:
            score += 0.25
        
        # åæ€é¢‘ç‡
        reflection = genes.get('reflection_frequency', 0.5)
        if 0.2 <= reflection <= 0.8:
            score += 0.25
        
        return score
    
    def _hash_genome(self, genome: Genome) -> str:
        """è®¡ç®—åŸºå› ç»„å“ˆå¸Œ"""
        genes_str = json.dumps(genome.genes, sort_keys=True)
        return hashlib.md5(genes_str.encode()).hexdigest()
    
    async def evolve_generation(self) -> EvolutionRecord:
        """
        è¿›åŒ–ä¸€ä»£
        ä½ ä¸€å®šè¦è¶…çº§æ€è€ƒã€æé™æ€è€ƒã€æ·±åº¦æ€è€ƒï¼Œå…¨åŠ›æ€è€ƒã€è¶…å¼ºæ€è€ƒï¼Œè®¤çœŸä»”ç»†æ€è€ƒï¼ˆultrathinkã€think really super hardã€think intenselyï¼‰ã€‚
        """
        logger.info(f"ğŸ§¬ å¼€å§‹ç¬¬ {self.generation + 1} ä»£è¿›åŒ–...")
        
        # é€‰æ‹©çˆ¶ä»£
        parents = self._selection()
        
        # äº¤å‰äº§ç”Ÿå­ä»£
        offspring = self._crossover(parents)
        
        # å˜å¼‚
        mutated_offspring = self._mutation(offspring)
        
        # å½¢æˆæ–°ä¸€ä»£ç§ç¾¤
        self.population = self._survival_selection(mutated_offspring)
        
        # è¯„ä¼°æ–°ç§ç¾¤
        self._evaluate_population()
        
        # æ›´æ–°æœ€ä½³ä¸ªä½“
        current_best = max(self.population, key=lambda g: g.fitness)
        if current_best.fitness > self.best_genome.fitness:
            self.best_genome = current_best
            logger.info(f"ğŸ‰ å‘ç°æ–°çš„æœ€ä½³ä¸ªä½“ï¼Œé€‚åº”åº¦: {self.best_genome.fitness:.4f}")
        
        # å‘ç°åˆ›æ–°
        innovations = await self._discover_innovations()
        
        # åˆ›å»ºè¿›åŒ–è®°å½•
        record = EvolutionRecord(
            generation=self.generation + 1,
            population_size=len(self.population),
            best_fitness=self.best_genome.fitness,
            average_fitness=np.mean([g.fitness for g in self.population]),
            mutations_applied=[m for g in self.population for m in g.mutation_history],
            innovations_discovered=[i.description for i in innovations],
            performance_metrics=self._calculate_generation_metrics()
        )
        
        self.evolution_history.append(record)
        self.generation += 1
        
        # ä¿å­˜è¿›åŒ–çŠ¶æ€
        await self._save_evolution_state()
        
        logger.info(f"âœ… ç¬¬ {self.generation} ä»£è¿›åŒ–å®Œæˆï¼Œæœ€ä½³é€‚åº”åº¦: {self.best_genome.fitness:.4f}")
        return record
    
    def _selection(self) -> List[Genome]:
        """é€‰æ‹©çˆ¶ä»£"""
        # é”¦æ ‡èµ›é€‰æ‹©
        tournament_size = max(3, self.population_size // 5)
        parents = []
        
        for _ in range(self.population_size // 2):
            tournament = random.sample(self.population, tournament_size)
            winner = max(tournament, key=lambda g: g.fitness)
            parents.append(winner)
        
        return parents
    
    def _crossover(self, parents: List[Genome]) -> List[Genome]:
        """äº¤å‰äº§ç”Ÿå­ä»£"""
        offspring = []
        
        for i in range(0, len(parents), 2):
            if i + 1 < len(parents):
                parent1, parent2 = parents[i], parents[i + 1]
                
                # å•ç‚¹äº¤å‰
                if random.random() < self.crossover_rate:
                    child1_genes, child2_genes = self._single_point_crossover(
                        parent1.genes, parent2.genes
                    )
                else:
                    child1_genes, child2_genes = parent1.genes.copy(), parent2.genes.copy()
                
                child1 = Genome(
                    genes=child1_genes,
                    generation=self.generation + 1,
                    parent_ids=[self._hash_genome(parent1), self._hash_genome(parent2)]
                )
                
                child2 = Genome(
                    genes=child2_genes,
                    generation=self.generation + 1,
                    parent_ids=[self._hash_genome(parent1), self._hash_genome(parent2)]
                )
                
                offspring.extend([child1, child2])
        
        return offspring
    
    def _single_point_crossover(self, genes1: Dict[str, Any], genes2: Dict[str, Any]) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        """å•ç‚¹äº¤å‰"""
        child1_genes = {}
        child2_genes = {}
        
        # æ‰å¹³åŒ–åŸºå› é”®
        all_keys = set(genes1.keys()) | set(genes2.keys())
        keys_list = sorted(all_keys)
        
        # éšæœºé€‰æ‹©äº¤å‰ç‚¹
        crossover_point = random.randint(1, len(keys_list) - 1)
        
        for i, key in enumerate(keys_list):
            if i < crossover_point:
                child1_genes[key] = genes1.get(key, genes2.get(key))
                child2_genes[key] = genes2.get(key, genes1.get(key))
            else:
                child1_genes[key] = genes2.get(key, genes1.get(key))
                child2_genes[key] = genes1.get(key, genes2.get(key))
        
        return child1_genes, child2_genes
    
    def _mutation(self, offspring: List[Genome]) -> List[Genome]:
        """å˜å¼‚"""
        mutated_offspring = []
        
        for genome in offspring:
            mutated_genome = copy.deepcopy(genome)
            
            # åº”ç”¨å˜å¼‚
            if random.random() < self.mutation_rate:
                mutation_type = random.choice(list(MutationType))
                mutation_description = self._apply_mutation(mutated_genome.genes, mutation_type)
                mutated_genome.mutation_history.append(mutation_description)
            
            mutated_offspring.append(mutated_genome)
        
        return mutated_offspring
    
    def _apply_mutation(self, genes: Dict[str, Any], mutation_type: MutationType) -> str:
        """åº”ç”¨ç‰¹å®šç±»å‹çš„å˜å¼‚"""
        if mutation_type == MutationType.PARAMETER_MUTATION:
            # å‚æ•°å˜å¼‚
            key = random.choice(list(genes.keys()))
            if isinstance(genes[key], (int, float)):
                if random.random() < 0.5:
                    genes[key] *= random.uniform(0.8, 1.2)
                else:
                    genes[key] += random.uniform(-0.1, 0.1)
                return f"å‚æ•°å˜å¼‚: {key} -> {genes[key]}"
        
        elif mutation_type == MutationType.HYPERPARAMETER_MUTATION:
            # è¶…å‚æ•°å˜å¼‚
            if 'learning_rate' in genes:
                genes['learning_rate'] *= random.uniform(0.5, 2.0)
                genes['learning_rate'] = max(0.00001, min(1.0, genes['learning_rate']))
                return f"å­¦ä¹ ç‡å˜å¼‚: {genes['learning_rate']}"
        
        elif mutation_type == MutationType.BEHAVIORAL_MUTATION:
            # è¡Œä¸ºå˜å¼‚
            behavior_keys = ['exploration_rate', 'exploitation_rate', 'innovation_tendency', 'cooperation_level']
            key = random.choice(behavior_keys)
            if key in genes:
                genes[key] = random.uniform(0.1, 0.9)
                return f"è¡Œä¸ºå˜å¼‚: {key} -> {genes[key]}"
        
        elif mutation_type == MutationType.STRUCTURE_MUTATION:
            # ç»“æ„å˜å¼‚
            if 'neural_layers' in genes and genes['neural_layers']:
                layer_idx = random.randint(0, len(genes['neural_layers']) - 1)
                layer = genes['neural_layers'][layer_idx]
                if layer['type'] == 'dense':
                    layer['units'] = random.choice([32, 64, 128, 256, 512])
                    return f"ç»“æ„å˜å¼‚: å¯†é›†å±‚å•å…ƒæ•° -> {layer['units']}"
        
        return "å˜å¼‚æœªåº”ç”¨"
    
    def _survival_selection(self, offspring: List[Genome]) -> List[Genome]:
        """ç”Ÿå­˜é€‰æ‹©"""
        # ç²¾è‹±ä¿ç•™ + è½®ç›˜èµŒé€‰æ‹©
        elite_size = max(2, self.population_size // 10)
        
        # åˆå¹¶çˆ¶ä»£å’Œå­ä»£
        combined_population = self.population + offspring
        
        # æŒ‰é€‚åº”åº¦æ’åº
        combined_population.sort(key=lambda g: g.fitness, reverse=True)
        
        # ä¿ç•™ç²¾è‹±
        new_population = combined_population[:elite_size]
        
        # è½®ç›˜èµŒé€‰æ‹©å‰©ä½™ä¸ªä½“
        remaining_size = self.population_size - elite_size
        if remaining_size > 0:
            fitnesses = [g.fitness for g in combined_population[elite_size:]]
            if sum(fitnesses) > 0:
                probabilities = [f / sum(fitnesses) for f in fitnesses]
                selected_indices = np.random.choice(
                    len(combined_population) - elite_size,
                    size=remaining_size,
                    replace=False,
                    p=probabilities
                )
                
                for idx in selected_indices:
                    new_population.append(combined_population[elite_size + idx])
        
        return new_population[:self.population_size]
    
    async def _discover_innovations(self) -> List[Innovation]:
        """å‘ç°åˆ›æ–°"""
        innovations = []
        
        # åˆ†ææœ€ä½³ä¸ªä½“çš„ç‹¬ç‰¹ç‰¹å¾
        if self.best_genome:
            unique_features = self._analyze_unique_features(self.best_genome)
            
            for feature in unique_features:
                innovation = Innovation(
                    innovation_id=f"innovation_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{random.randint(1000, 9999)}",
                    description=f"å‘ç°åˆ›æ–°ç‰¹å¾: {feature}",
                    category="genetic_innovation",
                    impact_score=random.uniform(0.6, 0.9)
                )
                innovations.append(innovation)
                self.innovation_registry.append(innovation)
        
        return innovations
    
    def _analyze_unique_features(self, genome: Genome) -> List[str]:
        """åˆ†æåŸºå› ç»„ç‹¬ç‰¹ç‰¹å¾"""
        features = []
        genes = genome.genes
        
        # æ£€æŸ¥ç‹¬ç‰¹çš„æ¶æ„ç»„åˆ
        if 'neural_layers' in genes:
            layer_types = [layer['type'] for layer in genes['neural_layers']]
            if 'attention' in layer_types and len(layer_types) > 3:
                features.append("æ·±åº¦æ³¨æ„åŠ›æ¶æ„")
        
        # æ£€æŸ¥ä¼˜åŒ–çš„è¶…å‚æ•°ç»„åˆ
        lr = genes.get('learning_rate', 0.001)
        batch_size = genes.get('batch_size', 32)
        if lr < 0.001 and batch_size > 64:
            features.append("é«˜ç²¾åº¦å¤§æ‰¹æ¬¡è®­ç»ƒç­–ç•¥")
        
        # æ£€æŸ¥è¡Œä¸ºç‰¹å¾
        exploration = genes.get('exploration_rate', 0.5)
        innovation = genes.get('innovation_tendency', 0.5)
        if exploration > 0.7 and innovation > 0.7:
            features.append("é«˜åº¦æ¢ç´¢æ€§åˆ›æ–°è¡Œä¸º")
        
        return features
    
    def _calculate_generation_metrics(self) -> Dict[str, float]:
        """è®¡ç®—ä»£é™…æŒ‡æ ‡"""
        fitnesses = [g.fitness for g in self.population]
        
        metrics = {
            'mean_fitness': np.mean(fitnesses),
            'std_fitness': np.std(fitnesses),
            'max_fitness': np.max(fitnesses),
            'min_fitness': np.min(fitnesses),
            'diversity': self._calculate_population_diversity(),
            'convergence_rate': self._calculate_convergence_rate()
        }
        
        return metrics
    
    def _calculate_population_diversity(self) -> float:
        """è®¡ç®—ç§ç¾¤å¤šæ ·æ€§"""
        if len(self.population) < 2:
            return 0.0
        
        total_distance = 0.0
        count = 0
        
        for i in range(len(self.population)):
            for j in range(i + 1, len(self.population)):
                distance = self._calculate_genome_distance(self.population[i], self.population[j])
                total_distance += distance
                count += 1
        
        return total_distance / count if count > 0 else 0.0
    
    def _calculate_genome_distance(self, genome1: Genome, genome2: Genome) -> float:
        """è®¡ç®—åŸºå› ç»„è·ç¦»"""
        genes1, genes2 = genome1.genes, genome2.genes
        
        distance = 0.0
        common_keys = set(genes1.keys()) & set(genes2.keys())
        
        for key in common_keys:
            val1, val2 = genes1[key], genes2[key]
            if isinstance(val1, (int, float)) and isinstance(val2, (int, float)):
                distance += abs(val1 - val2) / (abs(val1) + abs(val2) + 1e-8)
        
        return distance / len(common_keys) if common_keys else 1.0
    
    def _calculate_convergence_rate(self) -> float:
        """è®¡ç®—æ”¶æ•›ç‡"""
        if len(self.evolution_history) < 2:
            return 0.0
        
        recent_records = self.evolution_history[-5:]
        fitness_improvements = [
            recent_records[i].best_fitness - recent_records[i-1].best_fitness
            for i, record in enumerate(recent_records)
            if i > 0
        ]
        
        if fitness_improvements:
            return np.mean(fitness_improvements)
        return 0.0
    
    async def _save_evolution_state(self):
        """ä¿å­˜è¿›åŒ–çŠ¶æ€"""
        state = {
            'generation': self.generation,
            'population_size': len(self.population),
            'best_fitness': self.best_genome.fitness if self.best_genome else 0.0,
            'evolution_history': [asdict(record) for record in self.evolution_history[-10:]],
            'innovation_count': len(self.innovation_registry),
            'timestamp': datetime.now().isoformat()
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        state_file = PROJECT_ROOT / ".iflow" / "data" / "evolution_engine_state.json"
        state_file.parent.mkdir(parents=True, exist_ok=True)
        
        try:
            with open(state_file, 'w', encoding='utf-8') as f:
                json.dump(state, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"ä¿å­˜è¿›åŒ–çŠ¶æ€å¤±è´¥: {e}")
    
    async def neural_architecture_search(self, search_space: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç¥ç»æ¶æ„æœç´¢
        ä½ ä¸€å®šè¦è¶…çº§æ€è€ƒã€æé™æ€è€ƒã€æ·±åº¦æ€è€ƒï¼Œå…¨åŠ›æ€è€ƒã€è¶…å¼ºæ€è€ƒï¼Œè®¤çœŸä»”ç»†æ€è€ƒï¼ˆultrathinkã€think really super hardã€think intenselyï¼‰ã€‚
        """
        logger.info("ğŸ” å¯åŠ¨ç¥ç»æ¶æ„æœç´¢...")
        
        best_architecture = None
        best_score = 0.0
        
        # ç”Ÿæˆå€™é€‰æ¶æ„
        candidates = self._generate_architecture_candidates(search_space)
        
        # è¯„ä¼°å€™é€‰æ¶æ„
        for candidate in candidates:
            score = await self._evaluate_architecture_candidate(candidate)
            
            if score > best_score:
                best_score = score
                best_architecture = candidate
        
        # å°†æœ€ä½³æ¶æ„æ·»åŠ åˆ°ç§ç¾¤
        if best_architecture:
            new_genome = Genome(
                genes={'neural_layers': best_architecture},
                generation=self.generation,
                parent_ids=[]
            )
            
            # æ›¿æ¢ç§ç¾¤ä¸­æœ€å·®ä¸ªä½“
            worst_genome = min(self.population, key=lambda g: g.fitness)
            worst_index = self.population.index(worst_genome)
            self.population[worst_index] = new_genome
            
            logger.info(f"âœ¨ å‘ç°æ–°æ¶æ„ï¼Œè¯„åˆ†: {best_score:.4f}")
        
        return {
            'best_architecture': best_architecture,
            'best_score': best_score,
            'candidates_evaluated': len(candidates)
        }
    
    def _generate_architecture_candidates(self, search_space: Dict[str, Any]) -> List[List[Dict[str, Any]]]:
        """ç”Ÿæˆæ¶æ„å€™é€‰"""
        candidates = []
        
        for _ in range(10):  # ç”Ÿæˆ10ä¸ªå€™é€‰
            candidate = []
            
            # éšæœºå±‚æ•°
            num_layers = random.randint(2, 6)
            
            for i in range(num_layers):
                if i == 0 or random.random() < 0.7:
                    # å¯†é›†å±‚
                    layer = {
                        'type': 'dense',
                        'units': random.choice(search_space.get('units', [32, 64, 128, 256, 512])),
                        'activation': random.choice(search_space.get('activations', ['relu', 'tanh', 'sigmoid']))
                    }
                else:
                    # æ³¨æ„åŠ›å±‚
                    layer = {
                        'type': 'attention',
                        'heads': random.choice(search_space.get('attention_heads', [4, 8, 16])),
                        'dim': random.choice(search_space.get('attention_dims', [64, 128, 256]))
                    }
                
                candidate.append(layer)
            
            candidates.append(candidate)
        
        return candidates
    
    async def _evaluate_architecture_candidate(self, architecture: List[Dict[str, Any]]) -> float:
        """è¯„ä¼°æ¶æ„å€™é€‰"""
        # åŸºäºæ¶æ„ç‰¹å¾è¯„åˆ†
        score = 0.0
        
        # æ·±åº¦å¥–åŠ±
        if 2 <= len(architecture) <= 5:
            score += 0.3
        
        # æ³¨æ„åŠ›æœºåˆ¶å¥–åŠ±
        has_attention = any(layer['type'] == 'attention' for layer in architecture)
        if has_attention:
            score += 0.4
        
        # å¤æ‚åº¦å¹³è¡¡
        total_params = sum(
            layer.get('units', 64) ** 2 
            for layer in architecture if layer['type'] == 'dense'
        )
        if 1000 <= total_params <= 50000:
            score += 0.3
        
        return score
    
    async def get_evolution_status(self) -> Dict[str, Any]:
        """è·å–è¿›åŒ–çŠ¶æ€"""
        return {
            'generation': self.generation,
            'population_size': len(self.population),
            'best_fitness': self.best_genome.fitness if self.best_genome else 0.0,
            'average_fitness': np.mean([g.fitness for g in self.population]),
            'diversity': self._calculate_population_diversity(),
            'innovation_count': len(self.innovation_registry),
            'evolution_strategies': [s.value for s in self.active_strategies],
            'mutation_rate': self.mutation_rate,
            'crossover_rate': self.crossover_rate
        }

# --- MCPæœåŠ¡å™¨æ¥å£ ---
async def main():
    """ä¸»å‡½æ•° - ä½œä¸ºMCPæœåŠ¡å™¨è¿è¡Œ"""
    evolution_engine = AutonomousEvolutionEngineV11()
    
    # æ¨¡æ‹ŸMCPæœåŠ¡å™¨å¯åŠ¨
    logger.info("ğŸš€ è‡ªä¸»è¿›åŒ–å¼•æ“V11 MCPæœåŠ¡å™¨å¯åŠ¨")
    logger.info("å¯ç”¨å·¥å…·: evolve_generation, neural_architecture_search, get_evolution_status")
    
    # ç¤ºä¾‹ï¼šè¿è¡Œå‡ ä»£è¿›åŒ–
    for i in range(3):
        record = await evolution_engine.evolve_generation()
        logger.info(f"ç¬¬ {record.generation} ä»£: æœ€ä½³é€‚åº”åº¦ {record.best_fitness:.4f}")
    
    status = await evolution_engine.get_evolution_status()
    logger.info(f"ğŸ“Š è¿›åŒ–çŠ¶æ€: {json.dumps(status, indent=2, ensure_ascii=False)}")

if __name__ == "__main__":
    asyncio.run(main())