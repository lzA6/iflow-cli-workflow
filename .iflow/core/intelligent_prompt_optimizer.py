#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ§  æ™ºèƒ½æç¤ºè¯ä¼˜åŒ–å™¨ V1.0 (Intelligent Prompt Optimizer)
====================================================

ä¸ºARPç³»ç»Ÿæ·»åŠ æ™ºèƒ½æç¤ºè¯ä¼˜åŒ–åŠŸèƒ½ï¼š
- ğŸ¯ è‡ªåŠ¨ä¼˜åŒ–ç”¨æˆ·æç¤ºè¯
- ğŸ‘¤ ç”¨æˆ·ç”»åƒå’Œåå¥½å­¦ä¹ 
- ğŸ”¤ 5ç§ä¼˜åŒ–æ¨¡å¼ï¼ˆæ ‡å‡†/ä¸“ä¸š/å°ç™½/AIæ ¼å¼/é‡æ–°ä¼˜åŒ–ï¼‰
- ğŸ’¾ æœ¬åœ°æ•°æ®æŒä¹…åŒ–å­˜å‚¨
- ğŸ“ˆ è‡ªåŠ¨è®­ç»ƒå’ŒæŒç»­å­¦ä¹ 
- ğŸŒŠ æ–­ç‚¹å¼äº¤äº’ä¼˜åŒ–
- ğŸ¨ ä¸ªæ€§åŒ–é€‚é…
- ğŸš€ è¶Šç”¨è¶Šæ‡‚ç”¨æˆ·

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æç¤ºè¯æ™ºèƒ½ä¼˜åŒ–
2. ç”¨æˆ·ç”»åƒæ„å»º
3. åå¥½å­¦ä¹ ç³»ç»Ÿ
4. æœ¬åœ°æ•°æ®ç®¡ç†
5. è‡ªåŠ¨è®­ç»ƒæœºåˆ¶
6. å¤šæ¨¡å¼é€‚é…

ä½œè€…: iFlowæ¶æ„å›¢é˜Ÿ
ç‰ˆæœ¬: 1.0.0
æ—¥æœŸ: 2025-11-17
"""

import os
import sys
import json
import asyncio
import logging
import time
import uuid
import re
import hashlib
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Set, Union, Callable
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
from collections import defaultdict, deque
from enum import Enum
import threading
from concurrent.futures import ThreadPoolExecutor

# é¡¹ç›®æ ¹è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OptimizationMode(Enum):
    """ä¼˜åŒ–æ¨¡å¼æšä¸¾"""
    STANDARD = "standard"           # æ ‡å‡†ä¼˜åŒ–
    PROFESSIONAL = "professional"   # ä¸“ä¸šæ–¹å‘
    BEGINNER = "beginner"          # å°ç™½å¬å¾—æ‡‚
    AI_FORMAT = "ai_format"       # AIå¬å¾—æ‡‚æ ¼å¼
    REOPTIMIZE = "reoptimize"     # é‡æ–°ä¼˜åŒ–

class UserExpertiseLevel(Enum):
    """ç”¨æˆ·ä¸“ä¸šæ°´å¹³"""
    EXPERT = "expert"      # ä¸“å®¶
    ADVANCED = "advanced"  # é«˜çº§
    INTERMEDIATE = "intermediate"  # ä¸­çº§
    BEGINNER = "beginner"  # åˆå­¦è€…

@dataclass
class UserProfile:
    """ç”¨æˆ·ç”»åƒ"""
    user_id: str
    name: Optional[str] = None
    expertise_level: UserExpertiseLevel = UserExpertiseLevel.INTERMEDIATE
    preferred_language: str = "zh"
    preferred_complexity: str = "balanced"  # simple, balanced, complex
    interaction_style: str = "direct"  # direct, detailed, casual
    field_of_interest: List[str] = field(default_factory=list)
    optimization_preferences: Dict[str, Any] = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.now)
    last_updated: datetime = field(default_factory=datetime.now)
    total_interactions: int = 0
    satisfaction_scores: List[float] = field(default_factory=list)

@dataclass
class PromptOptimizationRecord:
    """æç¤ºè¯ä¼˜åŒ–è®°å½•"""
    record_id: str
    user_id: str
    original_prompt: str
    optimized_prompt: str
    optimization_mode: OptimizationMode
    user_feedback: Optional[int] = None  # 1-5åˆ†
    user_accepted: bool = False
    optimization_reasoning: str = ""
    timestamp: datetime = field(default_factory=datetime.now)
    processing_time: float = 0.0

@dataclass
class OptimizationResult:
    """ä¼˜åŒ–ç»“æœ"""
    success: bool
    optimized_prompt: str
    optimization_mode: OptimizationMode
    reasoning: str
    confidence: float
    suggestions: List[str] = field(default_factory=list)
    next_steps: List[str] = field(default_factory=list)

class IntelligentPromptOptimizer:
    """æ™ºèƒ½æç¤ºè¯ä¼˜åŒ–å™¨"""
    
    def __init__(self, data_dir: Optional[Path] = None):
        self.data_dir = data_dir or PROJECT_ROOT / "data" / "prompt_optimizer"
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # æ•°æ®å­˜å‚¨è·¯å¾„
        self.profiles_file = self.data_dir / "user_profiles.json"
        self.history_file = self.data_dir / "optimization_history.json"
        self.training_data_file = self.data_dir / "training_data.json"
        self.models_dir = self.data_dir / "models"
        self.models_dir.mkdir(exist_ok=True)
        
        # å†…å­˜æ•°æ®
        self.user_profiles: Dict[str, UserProfile] = {}
        self.optimization_history: List[PromptOptimizationRecord] = []
        self.training_data: List[Dict[str, Any]] = []
        
        # ä¼˜åŒ–è§„åˆ™å’Œæ¨¡æ¿
        self.optimization_rules = self._load_optimization_rules()
        self.mode_templates = self._load_mode_templates()
        
        # åŠ è½½ç°æœ‰æ•°æ®
        self._load_data()
        
        # çº¿ç¨‹é”
        self._lock = threading.Lock()
        
        logger.info("ğŸ§  æ™ºèƒ½æç¤ºè¯ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_optimization_rules(self) -> Dict[str, List[str]]:
        """åŠ è½½ä¼˜åŒ–è§„åˆ™"""
        return {
            "clarity": [
                "ä½¿ç”¨æ˜ç¡®ã€å…·ä½“çš„è¯­è¨€",
                "é¿å…æ¨¡ç³Šå’Œæ­§ä¹‰çš„è¡¨è¾¾",
                "ç¡®ä¿é€»è¾‘ç»“æ„æ¸…æ™°"
            ],
            "completeness": [
                "åŒ…å«å¿…è¦çš„ä¸Šä¸‹æ–‡ä¿¡æ¯",
                "æ˜ç¡®æœŸæœ›çš„è¾“å‡ºæ ¼å¼",
                "æä¾›ç›¸å…³çš„çº¦æŸæ¡ä»¶"
            ],
            "effectiveness": [
                "ä½¿ç”¨è¡ŒåŠ¨å¯¼å‘çš„åŠ¨è¯",
                "åˆç†è®¾ç½®ä¼˜å…ˆçº§",
                "æä¾›ç¤ºä¾‹å’Œæ¨¡æ¿"
            ],
            "efficiency": [
                "å»é™¤å†—ä½™ä¿¡æ¯",
                "ç²¾ç®€è¡¨è¾¾æ–¹å¼",
                "ä¼˜åŒ–æç¤ºè¯ç»“æ„"
            ]
        }
    
    def _load_mode_templates(self) -> Dict[OptimizationMode, Dict[str, Any]]:
        """åŠ è½½æ¨¡å¼æ¨¡æ¿"""
        return {
            OptimizationMode.STANDARD: {
                "description": "æ ‡å‡†ä¼˜åŒ–æ¨¡å¼ï¼Œå¹³è¡¡æ¸…æ™°åº¦å’Œå®Œæ•´æ€§",
                "focus_areas": ["clarity", "completeness", "effectiveness"],
                "style": "balanced",
                "complexity": "medium"
            },
            OptimizationMode.PROFESSIONAL: {
                "description": "ä¸“ä¸šæ–¹å‘ä¼˜åŒ–ï¼Œä½¿ç”¨è¡Œä¸šæœ¯è¯­å’Œä¸“ä¸šè¡¨è¾¾",
                "focus_areas": ["completeness", "effectiveness"],
                "style": "formal",
                "complexity": "high",
                "additions": ["ä¸“ä¸šæœ¯è¯­", "æŠ€æœ¯ç»†èŠ‚", "è¡Œä¸šæ ‡å‡†"]
            },
            OptimizationMode.BEGINNER: {
                "description": "å°ç™½å‹å¥½æ¨¡å¼ï¼Œç®€å•æ˜“æ‡‚çš„è¡¨è¾¾",
                "focus_areas": ["clarity", "simplicity"],
                "style": "casual",
                "complexity": "low",
                "additions": ["ç®€å•è§£é‡Š", "æ­¥éª¤è¯´æ˜", "é€šä¿—æ¯”å–»"]
            },
            OptimizationMode.AI_FORMAT: {
                "description": "AIå‹å¥½æ ¼å¼ï¼Œç»“æ„åŒ–æç¤ºè¯",
                "focus_areas": ["structure", "precision"],
                "style": "structured",
                "complexity": "medium",
                "additions": ["ç»“æ„åŒ–æ ¼å¼", "æ˜ç¡®æŒ‡ä»¤", "è§’è‰²å®šä¹‰"]
            },
            OptimizationMode.REOPTIMIZE: {
                "description": "é‡æ–°ä¼˜åŒ–ï¼ŒåŸºäºåé¦ˆæ”¹è¿›",
                "focus_areas": ["all"],
                "style": "adaptive",
                "complexity": "variable",
                "additions": ["åé¦ˆæ•´åˆ", "é—®é¢˜ä¿®å¤", "æ€§èƒ½æå‡"]
            }
        }
    
    def _load_data(self):
        """åŠ è½½æŒä¹…åŒ–æ•°æ®"""
        try:
            # åŠ è½½ç”¨æˆ·ç”»åƒ
            if self.profiles_file.exists():
                with open(self.profiles_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for user_id, profile_data in data.items():
                        profile = UserProfile(**profile_data)
                        # è½¬æ¢æ—¥æœŸå­—ç¬¦ä¸²
                        if isinstance(profile.created_at, str):
                            profile.created_at = datetime.fromisoformat(profile.created_at)
                        if isinstance(profile.last_updated, str):
                            profile.last_updated = datetime.fromisoformat(profile.last_updated)
                        self.user_profiles[user_id] = profile
            
            # åŠ è½½ä¼˜åŒ–å†å²
            if self.history_file.exists():
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for record_data in data:
                        record = PromptOptimizationRecord(**record_data)
                        if isinstance(record.timestamp, str):
                            record.timestamp = datetime.fromisoformat(record.timestamp)
                        self.optimization_history.append(record)
            
            # åŠ è½½è®­ç»ƒæ•°æ®
            if self.training_data_file.exists():
                with open(self.training_data_file, 'r', encoding='utf-8') as f:
                    self.training_data = json.load(f)
            
            logger.info(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(self.user_profiles)}ä¸ªç”¨æˆ·, {len(self.optimization_history)}æ¡å†å²")
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
    
    def _save_data(self):
        """ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶"""
        try:
            with self._lock:
                # ä¿å­˜ç”¨æˆ·ç”»åƒ
                profiles_data = {}
                for user_id, profile in self.user_profiles.items():
                    profile_dict = asdict(profile)
                    profile_dict['created_at'] = profile.created_at.isoformat()
                    profile_dict['last_updated'] = profile.last_updated.isoformat()
                    # è½¬æ¢æšä¸¾ä¸ºå­—ç¬¦ä¸²
                    profile_dict['expertise_level'] = profile.expertise_level.value
                    profiles_data[user_id] = profile_dict
                
                with open(self.profiles_file, 'w', encoding='utf-8') as f:
                    json.dump(profiles_data, f, ensure_ascii=False, indent=2)
                
                # ä¿å­˜ä¼˜åŒ–å†å²
                history_data = []
                for record in self.optimization_history:
                    record_dict = asdict(record)
                    record_dict['timestamp'] = record.timestamp.isoformat()
                    # è½¬æ¢æšä¸¾ä¸ºå­—ç¬¦ä¸²
                    record_dict['optimization_mode'] = record.optimization_mode.value
                    history_data.append(record_dict)
                
                with open(self.history_file, 'w', encoding='utf-8') as f:
                    json.dump(history_data, f, ensure_ascii=False, indent=2)
                
                # ä¿å­˜è®­ç»ƒæ•°æ®
                with open(self.training_data_file, 'w', encoding='utf-8') as f:
                    json.dump(self.training_data, f, ensure_ascii=False, indent=2)
                
                logger.debug("ğŸ’¾ æ•°æ®ä¿å­˜å®Œæˆ")
                
        except Exception as e:
            logger.error(f"âŒ æ•°æ®ä¿å­˜å¤±è´¥: {e}")
    
    def get_or_create_user(self, user_id: str, name: Optional[str] = None) -> UserProfile:
        """è·å–æˆ–åˆ›å»ºç”¨æˆ·ç”»åƒ"""
        if user_id not in self.user_profiles:
            self.user_profiles[user_id] = UserProfile(
                user_id=user_id,
                name=name or f"ç”¨æˆ·_{user_id[:8]}"
            )
            self._save_data()
        
        return self.user_profiles[user_id]
    
    def update_user_profile(self, user_id: str, **kwargs):
        """æ›´æ–°ç”¨æˆ·ç”»åƒ"""
        if user_id in self.user_profiles:
            profile = self.user_profiles[user_id]
            for key, value in kwargs.items():
                if hasattr(profile, key):
                    setattr(profile, key, value)
            profile.last_updated = datetime.now()
            self._save_data()
    
    def _analyze_prompt(self, prompt: str) -> Dict[str, Any]:
        """åˆ†ææç¤ºè¯ç‰¹å¾"""
        analysis = {
            "length": len(prompt),
            "word_count": len(prompt.split()),
            "sentence_count": len(re.split(r'[ã€‚ï¼ï¼Ÿ.!?]+', prompt)),
            "has_context": bool(re.search(r'èƒŒæ™¯|ä¸Šä¸‹æ–‡|åœºæ™¯|æƒ…å†µ', prompt)),
            "has_constraints": bool(re.search(r'é™åˆ¶|è¦æ±‚|å¿…é¡»|é¿å…', prompt)),
            "has_examples": bool(re.search(r'ä¾‹å¦‚|æ¯”å¦‚|ç¤ºä¾‹|ä¾‹å­', prompt)),
            "has_format": bool(re.search(r'æ ¼å¼|ç»“æ„|æ¨¡æ¿|æ ·å¼', prompt)),
            "clarity_score": 0.0,
            "completeness_score": 0.0,
            "complexity": "medium"
        }
        
        # è®¡ç®—æ¸…æ™°åº¦åˆ†æ•°
        clarity_indicators = [
            analysis['has_context'],
            not len(prompt) < 10,
            analysis['word_count'] > 3,
            '?' not in prompt or prompt.count('?') <= 2
        ]
        analysis['clarity_score'] = sum(clarity_indicators) / len(clarity_indicators)
        
        # è®¡ç®—å®Œæ•´æ€§åˆ†æ•°
        completeness_indicators = [
            analysis['has_context'],
            analysis['has_constraints'],
            analysis['has_examples'] or analysis['has_format']
        ]
        analysis['completeness_score'] = sum(completeness_indicators) / len(completeness_indicators)
        
        # åˆ¤æ–­å¤æ‚åº¦
        if analysis['word_count'] < 20:
            analysis['complexity'] = "low"
        elif analysis['word_count'] > 100:
            analysis['complexity'] = "high"
        
        return analysis
    
    def _optimize_for_mode(self, prompt: str, mode: OptimizationMode, user_profile: UserProfile) -> Tuple[str, str]:
        """æ ¹æ®æ¨¡å¼ä¼˜åŒ–æç¤ºè¯"""
        analysis = self._analyze_prompt(prompt)
        template = self.mode_templates[mode]
        
        optimized = prompt
        reasoning_steps = []
        
        # åŸºç¡€ä¼˜åŒ–
        if "clarity" in template.get("focus_areas", []):
            if analysis['clarity_score'] < 0.7:
                optimized = self._improve_clarity(optimized)
                reasoning_steps.append("æå‡è¡¨è¾¾æ¸…æ™°åº¦")
        
        if "completeness" in template.get("focus_areas", []):
            if analysis['completeness_score'] < 0.7:
                optimized = self._improve_completeness(optimized)
                reasoning_steps.append("è¡¥å……å¿…è¦ä¿¡æ¯")
        
        # æ¨¡å¼ç‰¹å®šä¼˜åŒ–
        if mode == OptimizationMode.PROFESSIONAL:
            optimized = self._add_professional_elements(optimized, user_profile)
            reasoning_steps.append("æ·»åŠ ä¸“ä¸šæœ¯è¯­å’ŒæŠ€æœ¯ç»†èŠ‚")
        
        elif mode == OptimizationMode.BEGINNER:
            optimized = self._simplify_for_beginner(optimized)
            reasoning_steps.append("ç®€åŒ–è¡¨è¾¾ï¼Œå¢åŠ è§£é‡Š")
        
        elif mode == OptimizationMode.AI_FORMAT:
            optimized = self._structure_for_ai(optimized)
            reasoning_steps.append("ç»“æ„åŒ–æ ¼å¼ï¼Œæ˜ç¡®æŒ‡ä»¤")
        
        elif mode == OptimizationMode.REOPTIMIZE:
            optimized = self._apply_feedback_learning(optimized, user_profile)
            reasoning_steps.append("åŸºäºå†å²åé¦ˆä¼˜åŒ–")
        
        # é€šç”¨ä¼˜åŒ–
        optimized = self._general_optimization(optimized)
        if not reasoning_steps:
            reasoning_steps.append("é€šç”¨ä¼˜åŒ–æ”¹è¿›")
        
        reasoning = f"ä¼˜åŒ–æ­¥éª¤: {' â†’ '.join(reasoning_steps)}"
        return optimized, reasoning
    
    def _improve_clarity(self, prompt: str) -> str:
        """æå‡æ¸…æ™°åº¦"""
        # æ·»åŠ æ˜ç¡®çš„ç›®æ ‡
        if not any(word in prompt for word in ['è¯·', 'å¸®æˆ‘', 'éœ€è¦', 'è¦æ±‚']):
            prompt = f"è¯·{prompt}"
        
        # å»é™¤æ¨¡ç³Šè¡¨è¾¾
        replacements = {
            'ä¸€äº›': 'å…·ä½“çš„',
            'å¯èƒ½': 'ç¡®å®š',
            'å¤§æ¦‚': 'å‡†ç¡®',
            'å·¦å³': 'ç²¾ç¡®'
        }
        
        for old, new in replacements.items():
            prompt = prompt.replace(old, new)
        
        return prompt
    
    def _improve_completeness(self, prompt: str) -> str:
        """æå‡å®Œæ•´æ€§"""
        # æ·»åŠ ä¸Šä¸‹æ–‡è¦æ±‚
        if not any(word in prompt for word in ['èƒŒæ™¯', 'ä¸Šä¸‹æ–‡', 'åœºæ™¯']):
            prompt += "\nè¯·æä¾›ç›¸å…³èƒŒæ™¯ä¿¡æ¯ã€‚"
        
        # æ·»åŠ è¾“å‡ºæ ¼å¼è¦æ±‚
        if not any(word in prompt for word in ['æ ¼å¼', 'ç»“æ„', 'è¾“å‡º']):
            prompt += "\nè¯·æ˜ç¡®è¾“å‡ºæ ¼å¼ã€‚"
        
        return prompt
    
    def _add_professional_elements(self, prompt: str, user_profile: UserProfile) -> str:
        """æ·»åŠ ä¸“ä¸šå…ƒç´ """
        # æ ¹æ®ç”¨æˆ·å…´è¶£é¢†åŸŸæ·»åŠ ä¸“ä¸šæœ¯è¯­
        if user_profile.field_of_interest:
            field = user_profile.field_of_interest[0]  # ä½¿ç”¨ä¸»è¦å…´è¶£é¢†åŸŸ
            professional_additions = {
                "æŠ€æœ¯": ["æŠ€æœ¯å®ç°", "æ¶æ„è®¾è®¡", "æ€§èƒ½ä¼˜åŒ–"],
                "å•†ä¸š": ["å•†ä¸šä»·å€¼", "å¸‚åœºåˆ†æ", "ROI"],
                "å­¦æœ¯": ["ç ”ç©¶æ–¹æ³•", "ç†è®ºåŸºç¡€", "å®éªŒè®¾è®¡"],
                "è‰ºæœ¯": ["åˆ›æ„ç†å¿µ", "ç¾å­¦åŸåˆ™", "è¡¨ç°å½¢å¼"]
            }
            
            if field in professional_additions:
                additions = professional_additions[field]
                prompt += f"\nè¯·ä»{', '.join(additions)}è§’åº¦è¿›è¡Œåˆ†æã€‚"
        
        return prompt
    
    def _simplify_for_beginner(self, prompt: str) -> str:
        """ä¸ºåˆå­¦è€…ç®€åŒ–"""
        # æ·»åŠ è§£é‡Šæ€§è¦æ±‚
        prompt += "\nè¯·ç”¨ç®€å•æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šï¼Œé¿å…ä½¿ç”¨ä¸“ä¸šæœ¯è¯­ã€‚"
        prompt += "\nå¦‚æœéœ€è¦ï¼Œå¯ä»¥ä½¿ç”¨ç”Ÿæ´»ä¸­çš„ä¾‹å­æ¥è¯´æ˜ã€‚"
        
        return prompt
    
    def _structure_for_ai(self, prompt: str) -> str:
        """ä¸ºAIç»“æ„åŒ–"""
        # æ·»åŠ è§’è‰²å®šä¹‰
        if not prompt.startswith("ä½ æ˜¯") and "è§’è‰²" not in prompt:
            prompt = f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ©æ‰‹ã€‚\n{prompt}"
        
        # æ·»åŠ ä»»åŠ¡ç»“æ„
        structured_prompt = f"""
## ä»»åŠ¡ç›®æ ‡
{prompt}

## è¾“å‡ºè¦æ±‚
1. é€»è¾‘æ¸…æ™°ï¼Œå±‚æ¬¡åˆ†æ˜
2. å†…å®¹å®Œæ•´ï¼Œé‡ç‚¹çªå‡º
3. æ ¼å¼è§„èŒƒï¼Œæ˜“äºç†è§£

## çº¦æŸæ¡ä»¶
- ç¡®ä¿å‡†ç¡®æ€§
- ä¿æŒå®¢è§‚æ€§
- æä¾›å¯æ“ä½œæ€§å»ºè®®
"""
        return structured_prompt.strip()
    
    def _apply_feedback_learning(self, prompt: str, user_profile: UserProfile) -> str:
        """åº”ç”¨åé¦ˆå­¦ä¹ """
        # è·å–ç”¨æˆ·å†å²ä¼˜åŒ–è®°å½•
        user_history = [r for r in self.optimization_history if r.user_id == user_profile.user_id]
        
        if user_history:
            # åˆ†æç”¨æˆ·åå¥½
            accepted_modes = [r.optimization_mode.value for r in user_history if r.user_accepted]
            high_feedback = [r for r in user_history if r.user_feedback and r.user_feedback >= 4]
            
            if accepted_modes:
                # åº”ç”¨ç”¨æˆ·åå¥½çš„æ¨¡å¼
                preferred_mode = max(set(accepted_modes), key=accepted_modes.count)
                if preferred_mode != OptimizationMode.REOPTIMIZE.value:
                    prompt, _ = self._optimize_for_mode(prompt, OptimizationMode(preferred_mode), user_profile)
            
            if high_feedback:
                # å­¦ä¹ é«˜åˆ†åé¦ˆçš„ç‰¹å¾
                for record in high_feedback[-3:]:  # æœ€è¿‘3æ¡é«˜åˆ†è®°å½•
                    prompt = self._apply_successful_patterns(prompt, record.optimized_prompt)
        
        return prompt
    
    def _apply_successful_patterns(self, current_prompt: str, successful_prompt: str) -> str:
        """åº”ç”¨æˆåŠŸæ¨¡å¼"""
        # æå–æˆåŠŸæç¤ºè¯çš„æ¨¡å¼
        patterns = []
        
        # æ£€æŸ¥ç»“æ„æ¨¡å¼
        if "##" in successful_prompt:
            patterns.append("structured_format")
        if "1." in successful_prompt:
            patterns.append("numbered_list")
        if "ï¼š" in successful_prompt and "ï¼Œ" in successful_prompt:
            patterns.append("detailed_explanation")
        
        # åº”ç”¨æ¨¡å¼
        if "structured_format" in patterns and "##" not in current_prompt:
            current_prompt = f"## ä»»åŠ¡\n{current_prompt}"
        
        return current_prompt
    
    def _general_optimization(self, prompt: str) -> str:
        """é€šç”¨ä¼˜åŒ–"""
        # å»é™¤å¤šä½™ç©ºç™½
        prompt = re.sub(r'\s+', ' ', prompt).strip()
        
        # ç¡®ä¿æ ‡ç‚¹ç¬¦å·è§„èŒƒ
        prompt = prompt.replace('ï¼Œï¼Œ', 'ï¼Œ').replace('ã€‚ã€‚', 'ã€‚')
        
        # ç¡®ä¿ç»“å°¾æœ‰æ ‡ç‚¹
        if prompt and prompt[-1] not in 'ã€‚ï¼ï¼Ÿ.!?':
            prompt += 'ã€‚'
        
        return prompt
    
    async def optimize_prompt(self, user_id: str, original_prompt: str, mode: OptimizationMode = OptimizationMode.STANDARD) -> OptimizationResult:
        """ä¼˜åŒ–æç¤ºè¯"""
        start_time = time.time()
        
        try:
            # è·å–ç”¨æˆ·ç”»åƒ
            user_profile = self.get_or_create_user(user_id)
            
            # åˆ†æåŸå§‹æç¤ºè¯
            analysis = self._analyze_prompt(original_prompt)
            
            # æ‰§è¡Œä¼˜åŒ–
            optimized_prompt, reasoning = self._optimize_for_mode(original_prompt, mode, user_profile)
            
            # è®¡ç®—ç½®ä¿¡åº¦
            confidence = self._calculate_confidence(analysis, optimized_prompt)
            
            # ç”Ÿæˆå»ºè®®
            suggestions = self._generate_suggestions(analysis, mode)
            
            # ç”Ÿæˆä¸‹ä¸€æ­¥æ“ä½œ
            next_steps = [
                "è¾“å…¥ 1: ç¡®è®¤ä½¿ç”¨ä¼˜åŒ–åçš„æç¤ºè¯",
                "è¾“å…¥ 2: é‡æ–°ä¼˜åŒ–å½“å‰æç¤ºè¯",
                "è¾“å…¥ 3: åˆ‡æ¢åˆ°ä¸“ä¸šæ–¹å‘ä¼˜åŒ–",
                "è¾“å…¥ 4: åˆ‡æ¢åˆ°å°ç™½å‹å¥½æ¨¡å¼",
                "è¾“å…¥ 5: åˆ‡æ¢åˆ°AIå‹å¥½æ ¼å¼"
            ]
            
            # åˆ›å»ºä¼˜åŒ–è®°å½•
            record = PromptOptimizationRecord(
                record_id=str(uuid.uuid4()),
                user_id=user_id,
                original_prompt=original_prompt,
                optimized_prompt=optimized_prompt,
                optimization_mode=mode,
                optimization_reasoning=reasoning,
                processing_time=time.time() - start_time
            )
            
            # ä¿å­˜è®°å½•
            self.optimization_history.append(record)
            self._save_data()
            
            # æ›´æ–°ç”¨æˆ·äº¤äº’æ¬¡æ•°
            user_profile.total_interactions += 1
            self._save_data()
            
            return OptimizationResult(
                success=True,
                optimized_prompt=optimized_prompt,
                optimization_mode=mode,
                reasoning=reasoning,
                confidence=confidence,
                suggestions=suggestions,
                next_steps=next_steps
            )
            
        except Exception as e:
            logger.error(f"âŒ æç¤ºè¯ä¼˜åŒ–å¤±è´¥: {e}")
            return OptimizationResult(
                success=False,
                optimized_prompt=original_prompt,
                optimization_mode=mode,
                reasoning=f"ä¼˜åŒ–å¤±è´¥: {str(e)}",
                confidence=0.0
            )
    
    def _calculate_confidence(self, analysis: Dict[str, Any], optimized_prompt: str) -> float:
        """è®¡ç®—ä¼˜åŒ–ç½®ä¿¡åº¦"""
        base_confidence = 0.7
        
        # åŸºäºæ”¹è¿›ç¨‹åº¦è°ƒæ•´
        length_improvement = min(0.1, (len(optimized_prompt) - analysis['length']) / 100)
        clarity_bonus = (1 - analysis['clarity_score']) * 0.2
        completeness_bonus = (1 - analysis['completeness_score']) * 0.2
        
        confidence = base_confidence + length_improvement + clarity_bonus + completeness_bonus
        return min(1.0, max(0.0, confidence))
    
    def _generate_suggestions(self, analysis: Dict[str, Any], mode: OptimizationMode) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        if analysis['clarity_score'] < 0.7:
            suggestions.append("å»ºè®®è¿›ä¸€æ­¥æ˜ç¡®è¡¨è¾¾æ„å›¾")
        
        if analysis['completeness_score'] < 0.7:
            suggestions.append("å»ºè®®æ·»åŠ æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯")
        
        if analysis['word_count'] < 10:
            suggestions.append("æç¤ºè¯å¯èƒ½è¿‡äºç®€å•ï¼Œå»ºè®®è¡¥å……ç»†èŠ‚")
        
        if analysis['word_count'] > 200:
            suggestions.append("æç¤ºè¯è¾ƒé•¿ï¼Œè€ƒè™‘ç®€åŒ–è¡¨è¾¾")
        
        # æ¨¡å¼ç‰¹å®šå»ºè®®
        if mode == OptimizationMode.PROFESSIONAL:
            suggestions.append("ä¸“ä¸šæ¨¡å¼å·²åº”ç”¨ï¼Œç¡®ä¿ç¬¦åˆè¡Œä¸šæ ‡å‡†")
        elif mode == OptimizationMode.BEGINNER:
            suggestions.append("å·²ç®€åŒ–è¡¨è¾¾ï¼Œé€‚åˆåˆå­¦è€…ç†è§£")
        
        return suggestions
    
    def record_feedback(self, record_id: str, user_feedback: int, user_accepted: bool):
        """è®°å½•ç”¨æˆ·åé¦ˆ"""
        for record in self.optimization_history:
            if record.record_id == record_id:
                record.user_feedback = user_feedback
                record.user_accepted = user_accepted
                
                # æ›´æ–°ç”¨æˆ·ç”»åƒ
                user_profile = self.user_profiles.get(record.user_id)
                if user_profile:
                    user_profile.satisfaction_scores.append(user_feedback)
                    user_profile.last_updated = datetime.now()
                    
                    # è‡ªåŠ¨è°ƒæ•´ç”¨æˆ·ä¸“ä¸šæ°´å¹³
                    if user_feedback >= 4 and record.optimization_mode == OptimizationMode.PROFESSIONAL:
                        if user_profile.expertise_level == UserExpertiseLevel.BEGINNER:
                            user_profile.expertise_level = UserExpertiseLevel.INTERMEDIATE
                        elif user_profile.expertise_level == UserExpertiseLevel.INTERMEDIATE:
                            user_profile.expertise_level = UserExpertiseLevel.ADVANCED
                
                # æ·»åŠ åˆ°è®­ç»ƒæ•°æ®
                self.training_data.append({
                    "original_prompt": record.original_prompt,
                    "optimized_prompt": record.optimized_prompt,
                    "mode": record.optimization_mode.value,
                    "feedback": user_feedback,
                    "accepted": user_accepted,
                    "timestamp": datetime.now().isoformat()
                })
                
                self._save_data()
                break
    
    def get_user_statistics(self, user_id: str) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·ç»Ÿè®¡ä¿¡æ¯"""
        user_profile = self.get_or_create_user(user_id)
        user_history = [r for r in self.optimization_history if r.user_id == user_id]
        
        if not user_history:
            return {
                "total_interactions": 0,
                "acceptance_rate": 0.0,
                "average_satisfaction": 0.0,
                "preferred_modes": [],
                "expertise_level": user_profile.expertise_level.value
            }
        
        accepted_count = sum(1 for r in user_history if r.user_accepted)
        feedback_scores = [r.user_feedback for r in user_history if r.user_feedback is not None]
        
        mode_counts = {}
        for record in user_history:
            if isinstance(record.optimization_mode, str):
                mode = record.optimization_mode
            else:
                mode = record.optimization_mode.value
            mode_counts[mode] = mode_counts.get(mode, 0) + 1
        
        # å¤„ç†ä¸“ä¸šæ°´å¹³æšä¸¾
        expertise_level = user_profile.expertise_level.value if hasattr(user_profile.expertise_level, 'value') else user_profile.expertise_level
        
        return {
            "total_interactions": len(user_history),
            "acceptance_rate": accepted_count / len(user_history) * 100,
            "average_satisfaction": sum(feedback_scores) / len(feedback_scores) if feedback_scores else 0.0,
            "preferred_modes": sorted(mode_counts.items(), key=lambda x: x[1], reverse=True),
            "expertise_level": expertise_level,
            "satisfaction_trend": user_profile.satisfaction_scores[-10:]  # æœ€è¿‘10æ¬¡
        }
    
    def export_user_data(self, user_id: str, export_path: Optional[Path] = None) -> str:
        """å¯¼å‡ºç”¨æˆ·æ•°æ®"""
        if export_path is None:
            export_path = self.data_dir / f"user_data_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        user_profile = self.get_or_create_user(user_id)
        user_history = [r for r in self.optimization_history if r.user_id == user_id]
        user_stats = self.get_user_statistics(user_id)
        
        export_data = {
            "user_profile": asdict(user_profile),
            "optimization_history": [asdict(r) for r in user_history],
            "statistics": user_stats,
            "export_timestamp": datetime.now().isoformat()
        }
        
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        export_data["user_profile"]["created_at"] = user_profile.created_at.isoformat()
        export_data["user_profile"]["last_updated"] = user_profile.last_updated.isoformat()
        
        for record in export_data["optimization_history"]:
            record["timestamp"] = record["timestamp"].isoformat()
        
        with open(export_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        return str(export_path)
    
    def cleanup_old_data(self, days_to_keep: int = 90):
        """æ¸…ç†æ—§æ•°æ®"""
        cutoff_date = datetime.now() - timedelta(days=days_to_keep)
        
        # æ¸…ç†ä¼˜åŒ–å†å²
        original_count = len(self.optimization_history)
        self.optimization_history = [
            r for r in self.optimization_history 
            if r.timestamp > cutoff_date
        ]
        
        # æ¸…ç†è®­ç»ƒæ•°æ®
        original_training_count = len(self.training_data)
        self.training_data = [
            d for d in self.training_data
            if datetime.fromisoformat(d["timestamp"]) > cutoff_date
        ]
        
        self._save_data()
        
        logger.info(f"ğŸ§¹ æ•°æ®æ¸…ç†å®Œæˆ: åˆ é™¤ {original_count - len(self.optimization_history)} æ¡å†å²è®°å½•, "
                   f"{original_training_count - len(self.training_data)} æ¡è®­ç»ƒæ•°æ®")

# å…¨å±€ä¼˜åŒ–å™¨å®ä¾‹
_global_optimizer: Optional[IntelligentPromptOptimizer] = None

def get_prompt_optimizer() -> IntelligentPromptOptimizer:
    """è·å–å…¨å±€æç¤ºè¯ä¼˜åŒ–å™¨å®ä¾‹"""
    global _global_optimizer
    if _global_optimizer is None:
        _global_optimizer = IntelligentPromptOptimizer()
    return _global_optimizer

# ä¾¿æ·å‡½æ•°
async def optimize_user_prompt(user_id: str, prompt: str, mode: str = "standard") -> OptimizationResult:
    """ä¾¿æ·çš„æç¤ºè¯ä¼˜åŒ–å‡½æ•°"""
    optimizer = get_prompt_optimizer()
    try:
        optimization_mode = OptimizationMode(mode)
    except ValueError:
        optimization_mode = OptimizationMode.STANDARD
    
    return await optimizer.optimize_prompt(user_id, prompt, optimization_mode)

if __name__ == "__main__":
    # æµ‹è¯•æ™ºèƒ½æç¤ºè¯ä¼˜åŒ–å™¨
    async def test_optimizer():
        print("ğŸ§ª æµ‹è¯•æ™ºèƒ½æç¤ºè¯ä¼˜åŒ–å™¨")
        
        optimizer = IntelligentPromptOptimizer()
        
        # æµ‹è¯•ä¼˜åŒ–
        user_id = "test_user_001"
        test_prompt = "å¸®æˆ‘å†™ä¸ªä»£ç "
        
        result = await optimizer.optimize_prompt(user_id, test_prompt, OptimizationMode.STANDARD)
        
        print(f"âœ… ä¼˜åŒ–ç»“æœ:")
        print(f"åŸå§‹æç¤ºè¯: {test_prompt}")
        print(f"ä¼˜åŒ–å: {result.optimized_prompt}")
        print(f"ä¼˜åŒ–æ¨¡å¼: {result.optimization_mode.value}")
        print(f"ç½®ä¿¡åº¦: {result.confidence:.2f}")
        print(f"å»ºè®®: {result.suggestions}")
        print(f"ä¸‹ä¸€æ­¥: {result.next_steps}")
        
        # æµ‹è¯•åé¦ˆ
        optimizer.record_feedback(
            record_id=optimizer.optimization_history[-1].record_id,
            user_feedback=5,
            user_accepted=True
        )
        
        # æŸ¥çœ‹ç»Ÿè®¡
        stats = optimizer.get_user_statistics(user_id)
        print(f"ğŸ“Š ç”¨æˆ·ç»Ÿè®¡: {stats}")
        
        print("ğŸ‰ æµ‹è¯•å®Œæˆ")
    
    asyncio.run(test_optimizer())