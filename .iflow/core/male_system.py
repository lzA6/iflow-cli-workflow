#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MALE - Multi-Agent Learning Engine (å¤šä»£ç†å­¦ä¹ å¼•æ“)
==============================================

å®ç°ç³»ç»Ÿçº§çš„è‡ªæˆ‘è¯Šæ–­ã€è‡ªæˆ‘ä¿®å¤ã€è‡ªæˆ‘ä¼˜åŒ–å’Œé€’å½’å­¦ä¹ ã€‚

æ ¸å¿ƒç‰¹æ€§ï¼š
- å¤šä»£ç†ååŒæ²»ç†
- é€’å½’å…ƒå­¦ä¹ å¾ªç¯
- è‡ªæˆ‘è¯Šæ–­ä¸ä¿®å¤
- åˆ†å¸ƒå¼çŸ¥è¯†å…±äº«
- æŒç»­è¿›åŒ–æœºåˆ¶
- è·¨åŸŸå­¦ä¹ èƒ½åŠ›

ä½œè€…: AIæ¶æ„å¸ˆå›¢é˜Ÿ
ç‰ˆæœ¬: 1.0.0 Ultra Enhanced
æ—¥æœŸ: 2025-11-16
"""

import asyncio
import json
import logging
import time
import uuid
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field, asdict
from enum import Enum
import networkx as nx
import numpy as np
import torch
import torch.nn as nn
from collections import defaultdict, deque

# é¡¹ç›®æ ¹è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("MALESystem")

class AgentRole(Enum):
    """ä»£ç†è§’è‰²æšä¸¾"""
    GOVERNOR = "governor"  # æ²»ç†è€…
    DIAGNOSTICIAN = "diagnostician"  # è¯Šæ–­ä¸“å®¶
    OPTIMIZER = "optimizer"  # ä¼˜åŒ–ä¸“å®¶
    LEARNER = "learner"  # å­¦ä¹ ä¸“å®¶
    COORDINATOR = "coordinator"  # åè°ƒè€…
    EXECUTOR = "executor"  # æ‰§è¡Œè€…
    MONITOR = "monitor"  # ç›‘æ§è€…

class LearningPhase(Enum):
    """å­¦ä¹ é˜¶æ®µ"""
    OBSERVATION = "observation"  # è§‚å¯Ÿä¸æ¨¡å¼æå–
    DIAGNOSIS = "diagnosis"  # è¯Šæ–­ä¸ç­–ç•¥è¿›åŒ–
    VALIDATION = "validation"  # éªŒè¯ä¸åŸºå‡†æµ‹è¯•
    APPLICATION = "application"  # åº”ç”¨ä¸æ¶æ„è¿›åŒ–
    EVALUATION = "evaluation"  # æŒç»­è¯„ä¼°ä¼˜åŒ–

@dataclass
class AgentState:
    """ä»£ç†çŠ¶æ€"""
    agent_id: str
    role: AgentRole
    status: str
    capabilities: List[str]
    knowledge: Dict[str, Any]
    performance_metrics: Dict[str, float]
    learning_history: List[Dict] = field(default_factory=list)
    last_updated: datetime = field(default_factory=datetime.now)

@dataclass
class LearningTask:
    """å­¦ä¹ ä»»åŠ¡"""
    task_id: str
    phase: LearningPhase
    description: str
    assigned_agents: List[str]
    requirements: Dict[str, Any]
    progress: float = 0.0
    result: Optional[Dict] = None
    created_at: datetime = field(default_factory=datetime.now)

class RecursiveLearningEngine(nn.Module):
    """é€’å½’å­¦ä¹ å¼•æ“"""
    
    def __init__(self, input_dim: int = 512, hidden_dim: int = 256):
        super().__init__()
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        
        # æ¨¡å¼æå–ç½‘ç»œ
        self.pattern_extractor = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 64)  # æ¨¡å¼å‘é‡
        )
        
        # ç­–ç•¥è¿›åŒ–ç½‘ç»œ
        self.strategy_evolver = nn.GRU(
            input_size=64,
            hidden_size=hidden_dim,
            num_layers=2,
            batch_first=True
        )
        
        # ä»·å€¼è¯„ä¼°ç½‘ç»œ
        self.value_evaluator = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 1),
            nn.Sigmoid()
        )
        
    def forward(self, inputs: torch.Tensor, hidden_state: Optional[torch.Tensor] = None):
        """å‰å‘ä¼ æ’­"""
        # æ¨¡å¼æå–
        patterns = self.pattern_extractor(inputs)
        
        # ç­–ç•¥è¿›åŒ–
        patterns = patterns.unsqueeze(0).unsqueeze(0)  # [1, 1, 64]
        if hidden_state is None:
            hidden_state = torch.zeros(2, 1, self.hidden_dim)
        
        evolved_strategies, new_hidden = self.strategy_evolver(patterns, hidden_state)
        
        # ä»·å€¼è¯„ä¼°
        values = self.value_evaluator(evolved_strategies.squeeze(0))
        
        return evolved_strategies.squeeze(0), new_hidden, values.squeeze()

class MALESystem:
    """å¤šä»£ç†å­¦ä¹ å¼•æ“ç³»ç»Ÿ"""
    
    def __init__(self):
        self.agents: Dict[str, AgentState] = {}
        self.tasks: Dict[str, LearningTask] = {}
        self.knowledge_graph = nx.DiGraph()
        self.learning_engine = RecursiveLearningEngine()
        
        # ç³»ç»ŸçŠ¶æ€
        self.system_state = {
            "total_agents": 0,
            "active_tasks": 0,
            "completed_tasks": 0,
            "learning_cycles": 0,
            "system_health": 1.0
        }
        
        # å­¦ä¹ å†å²
        self.learning_history = deque(maxlen=1000)
        self.performance_history = deque(maxlen=100)
        
        # åˆå§‹åŒ–æ ¸å¿ƒä»£ç†
        self._initialize_core_agents()
        
        logger.info("MALEç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def _initialize_core_agents(self):
        """åˆå§‹åŒ–æ ¸å¿ƒä»£ç†"""
        core_agents = [
            (AgentRole.GOVERNOR, "ç³»ç»Ÿæ²»ç†è€…", ["è§„åˆ™åˆ¶å®š", "æƒé™ç®¡ç†", "ä¼˜å…ˆçº§åˆ†é…"]),
            (AgentRole.DIAGNOSTICIAN, "ç³»ç»Ÿè¯Šæ–­ä¸“å®¶", ["é”™è¯¯æ£€æµ‹", "æ€§èƒ½åˆ†æ", "ç“¶é¢ˆè¯†åˆ«"]),
            (AgentRole.OPTIMIZER, "ç³»ç»Ÿä¼˜åŒ–ä¸“å®¶", ["æ€§èƒ½è°ƒä¼˜", "èµ„æºåˆ†é…", "ç®—æ³•ä¼˜åŒ–"]),
            (AgentRole.LEARNER, "å­¦ä¹ ä¸“å®¶", ["æ¨¡å¼è¯†åˆ«", "çŸ¥è¯†æå–", "ç»éªŒæ€»ç»“"]),
            (AgentRole.COORDINATOR, "ä»»åŠ¡åè°ƒè€…", ["ä»»åŠ¡åˆ†é…", "è¿›åº¦è·Ÿè¸ª", "èµ„æºè°ƒåº¦"]),
            (AgentRole.MONITOR, "ç³»ç»Ÿç›‘æ§è€…", ["å®æ—¶ç›‘æ§", "æŒ‡æ ‡æ”¶é›†", "å‘Šè­¦ç®¡ç†"])
        ]
        
        for role, name, capabilities in core_agents:
            agent_id = f"{role.value}_{uuid.uuid4().hex[:8]}"
            agent = AgentState(
                agent_id=agent_id,
                role=role,
                status="active",
                capabilities=capabilities,
                knowledge={},
                performance_metrics={
                    "efficiency": 0.8,
                    "accuracy": 0.85,
                    "collaboration": 0.9
                }
            )
            self.agents[agent_id] = agent
            
            # æ·»åŠ åˆ°çŸ¥è¯†å›¾è°±
            self.knowledge_graph.add_node(agent_id, **asdict(agent))
        
        self.system_state["total_agents"] = len(self.agents)
        logger.info(f"åˆå§‹åŒ–äº† {len(self.agents)} ä¸ªæ ¸å¿ƒä»£ç†")
    
    async def self_diagnosis(self) -> Dict[str, Any]:
        """ç³»ç»Ÿè‡ªæˆ‘è¯Šæ–­"""
        logger.info("å¼€å§‹ç³»ç»Ÿè‡ªæˆ‘è¯Šæ–­...")
        
        diagnosis_results = {
            "timestamp": datetime.now().isoformat(),
            "system_health": 1.0,
            "issues": [],
            "recommendations": [],
            "metrics": {}
        }
        
        # æ£€æŸ¥ä»£ç†çŠ¶æ€
        inactive_agents = [aid for aid, agent in self.agents.items() if agent.status != "active"]
        if inactive_agents:
            diagnosis_results["issues"].append({
                "type": "inactive_agents",
                "severity": "medium",
                "description": f"{len(inactive_agents)} ä¸ªä»£ç†å¤„äºéæ´»è·ƒçŠ¶æ€",
                "affected_agents": inactive_agents
            })
            diagnosis_results["system_health"] -= 0.1
        
        # æ£€æŸ¥ä»»åŠ¡ç§¯å‹
        pending_tasks = [tid for tid, task in self.tasks.items() if task.progress < 1.0]
        if len(pending_tasks) > 10:
            diagnosis_results["issues"].append({
                "type": "task_backlog",
                "severity": "high",
                "description": f"{len(pending_tasks)} ä¸ªä»»åŠ¡å¾…å¤„ç†",
                "affected_tasks": pending_tasks[:5]  # åªæ˜¾ç¤ºå‰5ä¸ª
            })
            diagnosis_results["system_health"] -= 0.2
        
        # æ£€æŸ¥æ€§èƒ½æŒ‡æ ‡
        avg_efficiency = np.mean([agent.performance_metrics.get("efficiency", 0) for agent in self.agents.values()])
        if avg_efficiency < 0.7:
            diagnosis_results["issues"].append({
                "type": "performance_degradation",
                "severity": "high",
                "description": f"å¹³å‡æ•ˆç‡ä»…ä¸º {avg_efficiency:.2f}"
            })
            diagnosis_results["system_health"] -= 0.15
        
        # ç”Ÿæˆå»ºè®®
        if diagnosis_results["issues"]:
            diagnosis_results["recommendations"] = [
                "æ¿€æ´»éæ´»è·ƒä»£ç†",
                "ä¼˜åŒ–ä»»åŠ¡åˆ†é…ç­–ç•¥",
                "æå‡ä»£ç†æ€§èƒ½",
                "å¢åŠ ç³»ç»Ÿèµ„æº"
            ]
        
        # è®°å½•è¯Šæ–­ç»“æœ
        self.learning_history.append({
            "type": "diagnosis",
            "timestamp": datetime.now().isoformat(),
            "result": diagnosis_results
        })
        
        return diagnosis_results
    
    async def self_healing(self, issues: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç³»ç»Ÿè‡ªæˆ‘ä¿®å¤"""
        logger.info(f"å¼€å§‹è‡ªæˆ‘ä¿®å¤ï¼Œå¤„ç† {len(issues)} ä¸ªé—®é¢˜...")
        
        healing_results = {
            "timestamp": datetime.now().isoformat(),
            "healed_issues": [],
            "failed_issues": [],
            "actions_taken": []
        }
        
        for issue in issues:
            issue_type = issue.get("type")
            
            if issue_type == "inactive_agents":
                # æ¿€æ´»éæ´»è·ƒä»£ç†
                for agent_id in issue.get("affected_agents", []):
                    if agent_id in self.agents:
                        self.agents[agent_id].status = "active"
                        healing_results["actions_taken"].append(f"æ¿€æ´»ä»£ç†: {agent_id}")
                        healing_results["healed_issues"].append(issue["type"])
            
            elif issue_type == "task_backlog":
                # é‡æ–°åˆ†é…ä»»åŠ¡
                await self._rebalance_tasks()
                healing_results["actions_taken"].append("é‡æ–°å¹³è¡¡ä»»åŠ¡åˆ†é…")
                healing_results["healed_issues"].append(issue["type"])
            
            elif issue_type == "performance_degradation":
                # ä¼˜åŒ–ä»£ç†æ€§èƒ½
                await self._optimize_agent_performance()
                healing_results["actions_taken"].append("ä¼˜åŒ–ä»£ç†æ€§èƒ½")
                healing_results["healed_issues"].append(issue["type"])
        
        # è®°å½•ä¿®å¤ç»“æœ
        self.learning_history.append({
            "type": "healing",
            "timestamp": datetime.now().isoformat(),
            "result": healing_results
        })
        
        return healing_results
    
    async def _rebalance_tasks(self):
        """é‡æ–°å¹³è¡¡ä»»åŠ¡"""
        # è·å–æ´»è·ƒçš„æ‰§è¡Œè€…ä»£ç†
        executors = [aid for aid, agent in self.agents.items() 
                   if agent.role == AgentRole.EXECUTOR and agent.status == "active"]
        
        if not executors:
            logger.warning("æ²¡æœ‰å¯ç”¨çš„æ‰§è¡Œè€…ä»£ç†")
            return
        
        # åˆ†é…å¾…å¤„ç†ä»»åŠ¡
        pending_tasks = [task for task in self.tasks.values() if task.progress < 1.0]
        
        for i, task in enumerate(pending_tasks):
            assigned_executor = executors[i % len(executors)]
            if assigned_executor not in task.assigned_agents:
                task.assigned_agents.append(assigned_executor)
                logger.info(f"ä»»åŠ¡ {task.task_id} åˆ†é…ç»™æ‰§è¡Œè€… {assigned_executor}")
    
    async def _optimize_agent_performance(self):
        """ä¼˜åŒ–ä»£ç†æ€§èƒ½"""
        for agent in self.agents.values():
            # æå‡æ•ˆç‡
            current_efficiency = agent.performance_metrics.get("efficiency", 0.8)
            if current_efficiency < 0.9:
                agent.performance_metrics["efficiency"] = min(0.95, current_efficiency + 0.05)
            
            # æå‡å‡†ç¡®ç‡
            current_accuracy = agent.performance_metrics.get("accuracy", 0.85)
            if current_accuracy < 0.9:
                agent.performance_metrics["accuracy"] = min(0.95, current_accuracy + 0.03)
            
            agent.last_updated = datetime.now()
    
    async def recursive_learning_cycle(self) -> Dict[str, Any]:
        """é€’å½’å­¦ä¹ å¾ªç¯"""
        logger.info("å¼€å§‹é€’å½’å­¦ä¹ å¾ªç¯...")
        
        cycle_results = {
            "cycle_id": str(uuid.uuid4()),
            "timestamp": datetime.now().isoformat(),
            "phases": {},
            "learned_patterns": [],
            "evolution_actions": []
        }
        
        # é˜¶æ®µ1: è§‚å¯Ÿä¸æ¨¡å¼æå–
        observation_results = await self._observation_phase()
        cycle_results["phases"]["observation"] = observation_results
        
        # é˜¶æ®µ2: è¯Šæ–­ä¸ç­–ç•¥è¿›åŒ–
        diagnosis_results = await self._diagnosis_phase()
        cycle_results["phases"]["diagnosis"] = diagnosis_results
        
        # é˜¶æ®µ3: éªŒè¯ä¸åŸºå‡†æµ‹è¯•
        validation_results = await self._validation_phase()
        cycle_results["phases"]["validation"] = validation_results
        
        # é˜¶æ®µ4: åº”ç”¨ä¸æ¶æ„è¿›åŒ–
        application_results = await self._application_phase()
        cycle_results["phases"]["application"] = application_results
        
        # é˜¶æ®µ5: æŒç»­è¯„ä¼°ä¼˜åŒ–
        evaluation_results = await self._evaluation_phase()
        cycle_results["phases"]["evaluation"] = evaluation_results
        
        # æ›´æ–°å­¦ä¹ å†å²
        self.learning_history.append({
            "type": "learning_cycle",
            "timestamp": datetime.now().isoformat(),
            "cycle_id": cycle_results["cycle_id"],
            "results": cycle_results
        })
        
        # æ›´æ–°ç³»ç»ŸçŠ¶æ€
        self.system_state["learning_cycles"] += 1
        
        return cycle_results
    
    async def _observation_phase(self) -> Dict[str, Any]:
        """è§‚å¯Ÿä¸æ¨¡å¼æå–é˜¶æ®µ"""
        logger.info("æ‰§è¡Œè§‚å¯Ÿä¸æ¨¡å¼æå–...")
        
        # æ”¶é›†ç³»ç»Ÿæ•°æ®
        system_data = {
            "agent_states": [asdict(agent) for agent in self.agents.values()],
            "task_states": [asdict(task) for task in self.tasks.values()],
            "performance_metrics": self.system_state
        }
        
        # æå–æ¨¡å¼
        patterns = []
        
        # ä»£ç†åä½œæ¨¡å¼
        collaboration_patterns = self._extract_collaboration_patterns()
        patterns.extend(collaboration_patterns)
        
        # æ€§èƒ½æ¨¡å¼
        performance_patterns = self._extract_performance_patterns()
        patterns.extend(performance_patterns)
        
        # ä»»åŠ¡æ‰§è¡Œæ¨¡å¼
        task_patterns = self._extract_task_patterns()
        patterns.extend(task_patterns)
        
        return {
            "status": "completed",
            "data_collected": system_data,
            "patterns_extracted": patterns,
            "insights": [f"æå–äº† {len(patterns)} ä¸ªå…³é”®æ¨¡å¼"]
        }
    
    def _extract_collaboration_patterns(self) -> List[Dict]:
        """æå–åä½œæ¨¡å¼"""
        patterns = []
        
        # åˆ†æä»£ç†é—´çš„åä½œå…³ç³»
        for task in self.tasks.values():
            if len(task.assigned_agents) > 1:
                pattern = {
                    "type": "collaboration",
                    "agents": task.assigned_agents,
                    "task_type": task.phase.value,
                    "frequency": 1
                }
                patterns.append(pattern)
        
        return patterns
    
    def _extract_performance_patterns(self) -> List[Dict]:
        """æå–æ€§èƒ½æ¨¡å¼"""
        patterns = []
        
        # åˆ†ææ€§èƒ½æŒ‡æ ‡
        for agent_id, agent in self.agents.items():
            metrics = agent.performance_metrics
            
            if metrics.get("efficiency", 0) > 0.9:
                patterns.append({
                    "type": "high_performance",
                    "agent_id": agent_id,
                    "role": agent.role.value,
                    "metrics": metrics
                })
        
        return patterns
    
    def _extract_task_patterns(self) -> List[Dict]:
        """æå–ä»»åŠ¡æ‰§è¡Œæ¨¡å¼"""
        patterns = []
        
        # åˆ†æä»»åŠ¡å®Œæˆæƒ…å†µ
        completed_tasks = [task for task in self.tasks.values() if task.progress >= 1.0]
        
        if completed_tasks:
            avg_completion_time = np.mean([
                (datetime.now() - task.created_at).total_seconds()
                for task in completed_tasks
            ])
            
            patterns.append({
                "type": "task_completion",
                "avg_time": avg_completion_time,
                "total_completed": len(completed_tasks)
            })
        
        return patterns
    
    async def _diagnosis_phase(self) -> Dict[str, Any]:
        """è¯Šæ–­ä¸ç­–ç•¥è¿›åŒ–é˜¶æ®µ"""
        logger.info("æ‰§è¡Œè¯Šæ–­ä¸ç­–ç•¥è¿›åŒ–...")
        
        # ç³»ç»Ÿè¯Šæ–­
        diagnosis = await self.self_diagnosis()
        
        # ç­–ç•¥è¿›åŒ–
        evolved_strategies = {}
        
        if diagnosis["issues"]:
            evolved_strategies["task_allocation"] = "dynamic_load_balancing"
            evolved_strategies["resource_management"] = "adaptive_scaling"
            evolved_strategies["agent_coordination"] = "hierarchical_governance"
        
        return {
            "status": "completed",
            "diagnosis": diagnosis,
            "evolved_strategies": evolved_strategies
        }
    
    async def _validation_phase(self) -> Dict[str, Any]:
        """éªŒè¯ä¸åŸºå‡†æµ‹è¯•é˜¶æ®µ"""
        logger.info("æ‰§è¡ŒéªŒè¯ä¸åŸºå‡†æµ‹è¯•...")
        
        # åˆ›å»ºæµ‹è¯•ä»»åŠ¡
        test_tasks = []
        
        # æ€§èƒ½åŸºå‡†æµ‹è¯•
        test_tasks.append({
            "type": "performance_benchmark",
            "description": "æµ‹è¯•ç³»ç»Ÿå“åº”æ—¶é—´",
            "expected_result": "< 100ms"
        })
        
        # å‡†ç¡®æ€§åŸºå‡†æµ‹è¯•
        test_tasks.append({
            "type": "accuracy_benchmark",
            "description": "æµ‹è¯•å†³ç­–å‡†ç¡®æ€§",
            "expected_result": "> 90%"
        })
        
        # æ‰§è¡Œæµ‹è¯•
        validation_results = {
            "tests_run": len(test_tasks),
            "tests_passed": 0,
            "details": []
        }
        
        for test in test_tasks:
            # æ¨¡æ‹Ÿæµ‹è¯•æ‰§è¡Œ
            result = await self._run_test(test)
            validation_results["details"].append(result)
            
            if result.get("passed", False):
                validation_results["tests_passed"] += 1
        
        return validation_results
    
    async def _run_test(self, test: Dict[str, Any]) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªæµ‹è¯•"""
        # æ¨¡æ‹Ÿæµ‹è¯•æ‰§è¡Œ
        await asyncio.sleep(0.1)
        
        if test["type"] == "performance_benchmark":
            response_time = 50 + np.random.normal(0, 10)
            passed = response_time < 100
            return {
                "test": test["description"],
                "result": f"{response_time:.2f}ms",
                "passed": passed
            }
        
        elif test["type"] == "accuracy_benchmark":
            accuracy = 0.92 + np.random.normal(0, 0.05)
            passed = accuracy > 0.90
            return {
                "test": test["description"],
                "result": f"{accuracy:.2%}",
                "passed": passed
            }
        
        return {"test": test["description"], "result": "unknown", "passed": False}
    
    async def _application_phase(self) -> Dict[str, Any]:
        """åº”ç”¨ä¸æ¶æ„è¿›åŒ–é˜¶æ®µ"""
        logger.info("æ‰§è¡Œåº”ç”¨ä¸æ¶æ„è¿›åŒ–...")
        
        evolution_actions = []
        
        # åº”ç”¨è¿›åŒ–ç­–ç•¥
        evolution_actions.append({
            "action": "optimize_agent_communication",
            "description": "ä¼˜åŒ–ä»£ç†é€šä¿¡åè®®",
            "status": "applied"
        })
        
        evolution_actions.append({
            "action": "enhance_learning_algorithms",
            "description": "å¢å¼ºå­¦ä¹ ç®—æ³•",
            "status": "applied"
        })
        
        evolution_actions.append({
            "action": "update_knowledge_graph",
            "description": "æ›´æ–°çŸ¥è¯†å›¾è°±",
            "status": "applied"
        })
        
        return {
            "status": "completed",
            "actions_applied": len(evolution_actions),
            "evolution_actions": evolution_actions
        }
    
    async def _evaluation_phase(self) -> Dict[str, Any]:
        """æŒç»­è¯„ä¼°ä¼˜åŒ–é˜¶æ®µ"""
        logger.info("æ‰§è¡ŒæŒç»­è¯„ä¼°ä¼˜åŒ–...")
        
        # è®¡ç®—ç³»ç»Ÿå¥åº·åˆ†æ•°
        health_score = self._calculate_system_health()
        
        # æ€§èƒ½æŒ‡æ ‡
        performance_metrics = {
            "avg_agent_efficiency": np.mean([
                agent.performance_metrics.get("efficiency", 0) 
                for agent in self.agents.values()
            ]),
            "task_completion_rate": len([t for t in self.tasks.values() if t.progress >= 1.0]) / max(len(self.tasks), 1),
            "system_health": health_score
        }
        
        # ä¼˜åŒ–å»ºè®®
        optimization_suggestions = []
        
        if performance_metrics["avg_agent_efficiency"] < 0.85:
            optimization_suggestions.append("æå‡ä»£ç†å¹³å‡æ•ˆç‡")
        
        if performance_metrics["task_completion_rate"] < 0.9:
            optimization_suggestions.append("ä¼˜åŒ–ä»»åŠ¡å®Œæˆç‡")
        
        if health_score < 0.9:
            optimization_suggestions.append("æ”¹å–„ç³»ç»Ÿæ•´ä½“å¥åº·")
        
        return {
            "status": "completed",
            "performance_metrics": performance_metrics,
            "optimization_suggestions": optimization_suggestions
        }
    
    def _calculate_system_health(self) -> float:
        """è®¡ç®—ç³»ç»Ÿå¥åº·åˆ†æ•°"""
        factors = []
        
        # ä»£ç†æ´»è·ƒåº¦
        active_agents = len([a for a in self.agents.values() if a.status == "active"])
        factors.append(active_agents / len(self.agents))
        
        # ä»»åŠ¡å®Œæˆç‡
        if self.tasks:
            completed_tasks = len([t for t in self.tasks.values() if t.progress >= 1.0])
            factors.append(completed_tasks / len(self.tasks))
        else:
            factors.append(1.0)
        
        # å¹³å‡æ€§èƒ½
        avg_performance = np.mean([
            np.mean(list(agent.performance_metrics.values()))
            for agent in self.agents.values()
        ])
        factors.append(avg_performance)
        
        return np.mean(factors)
    
    def get_system_report(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸæŠ¥å‘Š"""
        return {
            "system": "MALE (Multi-Agent Learning Engine)",
            "version": "1.0.0 Ultra Enhanced",
            "state": self.system_state,
            "agents": {
                "total": len(self.agents),
                "by_role": {
                    role.value: len([a for a in self.agents.values() if a.role == role])
                    for role in AgentRole
                }
            },
            "tasks": {
                "total": len(self.tasks),
                "active": len([t for t in self.tasks.values() if t.progress < 1.0]),
                "completed": len([t for t in self.tasks.values() if t.progress >= 1.0])
            },
            "learning": {
                "cycles_completed": self.system_state["learning_cycles"],
                "history_size": len(self.learning_history),
                "last_cycle": self.learning_history[-1] if self.learning_history else None
            },
            "performance": {
                "system_health": self._calculate_system_health(),
                "avg_efficiency": np.mean([
                    agent.performance_metrics.get("efficiency", 0)
                    for agent in self.agents.values()
                ])
            }
        }

# å…¨å±€å®ä¾‹
_male_system = None

def get_male_system() -> MALESystem:
    """è·å–å…¨å±€MALEç³»ç»Ÿå®ä¾‹"""
    global _male_system
    if _male_system is None:
        _male_system = MALESystem()
    return _male_system

# æµ‹è¯•å‡½æ•°
async def test_male_system():
    """æµ‹è¯•MALEç³»ç»Ÿ"""
    print("ğŸ§ª æµ‹è¯•MALEç³»ç»Ÿ...")
    
    # è·å–ç³»ç»Ÿå®ä¾‹
    male = get_male_system()
    
    # ç³»ç»Ÿè¯Šæ–­
    print("\nğŸ” æ‰§è¡Œç³»ç»Ÿè¯Šæ–­...")
    diagnosis = await male.self_diagnosis()
    print(f"  ç³»ç»Ÿå¥åº·åˆ†æ•°: {diagnosis['system_health']:.2f}")
    print(f"  å‘ç°é—®é¢˜: {len(diagnosis['issues'])} ä¸ª")
    
    # è‡ªæˆ‘ä¿®å¤
    if diagnosis["issues"]:
        print("\nğŸ”§ æ‰§è¡Œè‡ªæˆ‘ä¿®å¤...")
        healing = await male.self_healing(diagnosis["issues"])
        print(f"  ä¿®å¤é—®é¢˜: {len(healing['healed_issues'])} ä¸ª")
        print(f"  æ‰§è¡Œæ“ä½œ: {len(healing['actions_taken'])} é¡¹")
    
    # é€’å½’å­¦ä¹ å¾ªç¯
    print("\nğŸ§  æ‰§è¡Œé€’å½’å­¦ä¹ å¾ªç¯...")
    learning_cycle = await male.recursive_learning_cycle()
    print(f"  å­¦ä¹ å‘¨æœŸID: {learning_cycle['cycle_id'][:8]}...")
    print(f"  å®Œæˆé˜¶æ®µ: {len(learning_cycle['phases'])} ä¸ª")
    
    # ç³»ç»ŸæŠ¥å‘Š
    report = male.get_system_report()
    print("\nğŸ“Š ç³»ç»ŸæŠ¥å‘Š:")
    print(json.dumps(report, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    asyncio.run(test_male_system())