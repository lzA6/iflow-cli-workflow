#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ§¬ é€’å½’å…ƒå­¦ä¹ å¼•æ“ V11 (ä»£å·ï¼š"è¿›åŒ–è€…")
===========================================================

è¿™æ˜¯ T-MIA æ¶æ„ä¸‹çš„æ ¸å¿ƒå­¦ä¹ å¼•æ“ï¼Œå®ç°äº†å››å±‚é€’å½’å­¦ä¹ å¾ªç¯å’ŒæŒç»­è¿›åŒ–æœºåˆ¶ã€‚
V11ç‰ˆæœ¬åœ¨V10åŸºç¡€ä¸Šå…¨é¢é‡æ„ï¼Œå®ç°äº†çœŸæ­£çš„é€’å½’è‡ªæˆ‘æ”¹è¿›ã€æ¨¡å¼è¿›åŒ–å’ŒçŸ¥è¯†è¿ç§»ã€‚

æ ¸å¿ƒç‰¹æ€§ï¼š
- å››å±‚é€’å½’å­¦ä¹  - è§‚å¯Ÿã€è¯Šæ–­ã€éªŒè¯ã€åº”ç”¨
- é€’å½’è‡ªæˆ‘æ”¹è¿› - ä»æ¯æ¬¡å­¦ä¹ ä¸­è¿›åŒ–
- æ¨¡å¼è¿›åŒ– - è¯†åˆ«å’Œä¼˜åŒ–æˆåŠŸæ¨¡å¼
- çŸ¥è¯†è¿ç§» - è·¨åŸŸçŸ¥è¯†åº”ç”¨
- å…ƒå­¦ä¹ ç­–ç•¥ - å­¦ä¹ å¦‚ä½•å­¦ä¹ 

ä½ ä¸€å®šè¦è¶…çº§æ€è€ƒã€æé™æ€è€ƒã€æ·±åº¦æ€è€ƒï¼Œå…¨åŠ›æ€è€ƒã€è¶…å¼ºæ€è€ƒï¼Œè®¤çœŸä»”ç»†æ€è€ƒï¼ˆultrathinkã€think really super hardã€think intenselyï¼‰ã€‚

ä½œè€…: AIæ¶æ„å¸ˆå›¢é˜Ÿ
ç‰ˆæœ¬: 11.0.0 (ä»£å·ï¼š"è¿›åŒ–è€…")
æ—¥æœŸ: 2025-11-15
"""

import os
import sys
import json
import asyncio
import logging
import time
import uuid
import numpy as np
import networkx as nx
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Set, Union
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
from collections import defaultdict, deque
from enum import Enum
import pickle
import math
from concurrent.futures import ThreadPoolExecutor

# é¡¹ç›®æ ¹è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# --- æ—¥å¿—é…ç½® ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("RMLEngineV11")

class LearningPhase(Enum):
    """å­¦ä¹ é˜¶æ®µ"""
    OBSERVATION = "observation"
    DIAGNOSIS = "diagnosis"
    VALIDATION = "validation"
    APPLICATION = "application"

class PatternType(Enum):
    """æ¨¡å¼ç±»å‹"""
    SUCCESS = "success"
    FAILURE = "failure"
    EFFICIENCY = "efficiency"
    COLLABORATION = "collaboration"
    ADAPTATION = "adaptation"

@dataclass
class LearningCycle:
    """å­¦ä¹ å¾ªç¯"""
    cycle_id: str
    start_time: datetime
    end_time: Optional[datetime] = None
    phase: LearningPhase = LearningPhase.OBSERVATION
    observations: List[Dict[str, Any]] = field(default_factory=list)
    patterns: List[Dict[str, Any]] = field(default_factory=list)
    strategies: List[Dict[str, Any]] = field(default_factory=list)
    validation_results: List[Dict[str, Any]] = field(default_factory=list)
    applications: List[Dict[str, Any]] = field(default_factory=list)
    effectiveness_score: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class LearningPattern:
    """å­¦ä¹ æ¨¡å¼"""
    pattern_id: str
    pattern_type: PatternType
    description: str
    conditions: List[Dict[str, Any]]
    actions: List[Dict[str, Any]]
    outcomes: List[Dict[str, Any]]
    success_rate: float = 0.0
    confidence: float = 0.0
    last_applied: Optional[datetime] = None
    application_count: int = 0
    evolution_history: List[Dict[str, Any]] = field(default_factory=list)

@dataclass
class MetaLearningStrategy:
    """å…ƒå­¦ä¹ ç­–ç•¥"""
    strategy_id: str
    name: str
    description: str
    learning_rate: float = 0.01
    exploration_rate: float = 0.1
    memory_decay: float = 0.01
    pattern_threshold: float = 0.7
    adaptation_factor: float = 0.05
    performance_metrics: Dict[str, float] = field(default_factory=dict)

class RMLEngineV11:
    """é€’å½’å…ƒå­¦ä¹ å¼•æ“ V11"""
    
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}
        
        # å­¦ä¹ å¾ªç¯
        self.active_cycle: Optional[LearningCycle] = None
        self.cycle_history: deque = deque(maxlen=1000)
        self.current_phase = LearningPhase.OBSERVATION
        
        # æ¨¡å¼åº“
        self.learning_patterns: Dict[str, LearningPattern] = {}
        self.pattern_evolution_graph = nx.DiGraph()
        
        # å…ƒå­¦ä¹ ç­–ç•¥
        self.meta_strategies: Dict[str, MetaLearningStrategy] = {}
        self.active_strategy: Optional[MetaLearningStrategy] = None
        
        # çŸ¥è¯†åº“
        self.knowledge_base: Dict[str, Any] = defaultdict(list)
        self.cross_domain_mappings: Dict[str, List[str]] = defaultdict(list)
        
        # æ€§èƒ½æŒ‡æ ‡
        self.performance_metrics = defaultdict(float)
        self.learning_velocity = 0.0
        self.adaptation_capacity = 0.0
        
        # é€’å½’æ·±åº¦
        self.recursion_depth = 0
        self.max_recursion_depth = 10
        
        # æ€§èƒ½ä¼˜åŒ–
        self.executor = ThreadPoolExecutor(max_workers=4)
        self.learning_cache = {}
        
        logger.info("RMLå¼•æ“V11åˆå§‹åŒ–å®Œæˆ")
    
    async def initialize(self):
        """å¼‚æ­¥åˆå§‹åŒ–"""
        logger.info("æ­£åœ¨åˆå§‹åŒ–RMLå¼•æ“...")
        
        # åŠ è½½å†å²å­¦ä¹ æ•°æ®
        await self._load_learning_history()
        
        # åˆå§‹åŒ–å…ƒå­¦ä¹ ç­–ç•¥
        await self._initialize_meta_strategies()
        
        # æ„å»ºæ¨¡å¼æ¼”åŒ–å›¾
        await self._build_pattern_evolution_graph()
        
        # å¯åŠ¨å­¦ä¹ å¾ªç¯
        asyncio.create_task(self._continuous_learning_loop())
        asyncio.create_task(self._pattern_evolution_loop())
        asyncio.create_task(self._meta_optimization_loop())
        asyncio.create_task(self._knowledge_integration_loop())
        
        logger.info("RMLå¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    async def start_learning_cycle(self, context: Dict[str, Any]) -> str:
        """å¼€å§‹å­¦ä¹ å¾ªç¯"""
        cycle_id = str(uuid.uuid4())
        
        cycle = LearningCycle(
            cycle_id=cycle_id,
            start_time=datetime.now(),
            phase=LearningPhase.OBSERVATION,
            metadata=context.copy()
        )
        
        self.active_cycle = cycle
        self.current_phase = LearningPhase.OBSERVATION
        
        logger.info(f"å¼€å§‹å­¦ä¹ å¾ªç¯: {cycle_id}")
        
        # æ‰§è¡Œå››å±‚å­¦ä¹ 
        await self._execute_learning_cycle(cycle)
        
        return cycle_id
    
    async def _execute_learning_cycle(self, cycle: LearningCycle):
        """æ‰§è¡Œå­¦ä¹ å¾ªç¯"""
        try:
            # ç¬¬ä¸€å±‚ï¼šè§‚å¯Ÿ
            await self._observation_phase(cycle)
            
            # ç¬¬äºŒå±‚ï¼šè¯Šæ–­
            await self._diagnosis_phase(cycle)
            
            # ç¬¬ä¸‰å±‚ï¼šéªŒè¯
            await self._validation_phase(cycle)
            
            # ç¬¬å››å±‚ï¼šåº”ç”¨
            await self._application_phase(cycle)
            
            # å®Œæˆå¾ªç¯
            cycle.end_time = datetime.now()
            cycle.effectiveness_score = await self._calculate_cycle_effectiveness(cycle)
            
            # è®°å½•å†å²
            self.cycle_history.append(cycle)
            
            # é€’å½’å­¦ä¹ 
            if self.recursion_depth < self.max_recursion_depth:
                await self._recursive_learning(cycle)
            
            logger.info(f"å­¦ä¹ å¾ªç¯å®Œæˆ: {cycle.cycle_id}, æ•ˆæœåˆ†æ•°: {cycle.effectiveness_score:.3f}")
            
        except Exception as e:
            logger.error(f"å­¦ä¹ å¾ªç¯æ‰§è¡Œå¤±è´¥ {cycle.cycle_id}: {e}")
            cycle.end_time = datetime.now()
            cycle.effectiveness_score = 0.0
    
    async def _observation_phase(self, cycle: LearningCycle):
        """è§‚å¯Ÿé˜¶æ®µ"""
        logger.info(f"è¿›å…¥è§‚å¯Ÿé˜¶æ®µ: {cycle.cycle_id}")
        
        cycle.phase = LearningPhase.OBSERVATION
        
        # æ”¶é›†ç³»ç»ŸçŠ¶æ€æ•°æ®
        observations = []
        
        # è§‚å¯Ÿæ€§èƒ½æŒ‡æ ‡
        performance_obs = await self._observe_performance_metrics()
        observations.append({
            'type': 'performance',
            'data': performance_obs,
            'timestamp': datetime.now()
        })
        
        # è§‚å¯Ÿæ¨¡å¼è¡¨ç°
        pattern_obs = await self._observe_pattern_performance()
        observations.append({
            'type': 'patterns',
            'data': pattern_obs,
            'timestamp': datetime.now()
        })
        
        # è§‚å¯Ÿåä½œæ•ˆæœ
        collaboration_obs = await self._observe_collaboration_effects()
        observations.append({
            'type': 'collaboration',
            'data': collaboration_obs,
            'timestamp': datetime.now()
        })
        
        # è§‚å¯Ÿé€‚åº”æ€§å˜åŒ–
        adaptation_obs = await self._observe_adaptation_changes()
        observations.append({
            'type': 'adaptation',
            'data': adaptation_obs,
            'timestamp': datetime.now()
        })
        
        cycle.observations = observations
        
        # æ›´æ–°çŸ¥è¯†åº“
        await self._update_knowledge_base(observations)
    
    async def _diagnosis_phase(self, cycle: LearningCycle):
        """è¯Šæ–­é˜¶æ®µ"""
        logger.info(f"è¿›å…¥è¯Šæ–­é˜¶æ®µ: {cycle.cycle_id}")
        
        cycle.phase = LearningPhase.DIAGNOSIS
        
        # åˆ†æè§‚å¯Ÿæ•°æ®
        patterns = []
        
        # è¯†åˆ«æˆåŠŸæ¨¡å¼
        success_patterns = await self._identify_success_patterns(cycle.observations)
        patterns.extend(success_patterns)
        
        # è¯†åˆ«å¤±è´¥æ¨¡å¼
        failure_patterns = await self._identify_failure_patterns(cycle.observations)
        patterns.extend(failure_patterns)
        
        # è¯†åˆ«æ•ˆç‡æ¨¡å¼
        efficiency_patterns = await self._identify_efficiency_patterns(cycle.observations)
        patterns.extend(efficiency_patterns)
        
        # è¯†åˆ«åä½œæ¨¡å¼
        collaboration_patterns = await self._identify_collaboration_patterns(cycle.observations)
        patterns.extend(collaboration_patterns)
        
        # è¯†åˆ«é€‚åº”æ¨¡å¼
        adaptation_patterns = await self._identify_adaptation_patterns(cycle.observations)
        patterns.extend(adaptation_patterns)
        
        cycle.patterns = patterns
        
        # ç”Ÿæˆè¯Šæ–­ç­–ç•¥
        strategies = await self._generate_diagnosis_strategies(patterns)
        cycle.strategies = strategies
    
    async def _validation_phase(self, cycle: LearningCycle):
        """éªŒè¯é˜¶æ®µ"""
        logger.info(f"è¿›å…¥éªŒè¯é˜¶æ®µ: {cycle.cycle_id}")
        
        cycle.phase = LearningPhase.VALIDATION
        
        validation_results = []
        
        # éªŒè¯æ¨¡å¼æœ‰æ•ˆæ€§
        for pattern in cycle.patterns:
            validation = await self._validate_pattern(pattern)
            validation_results.append(validation)
        
        # éªŒè¯ç­–ç•¥å¯è¡Œæ€§
        for strategy in cycle.strategies:
            validation = await self._validate_strategy(strategy)
            validation_results.append(validation)
        
        # æ¨¡æ‹Ÿæµ‹è¯•
        simulation_results = await self._run_simulations(cycle.strategies)
        validation_results.extend(simulation_results)
        
        cycle.validation_results = validation_results
    
    async def _application_phase(self, cycle: LearningCycle):
        """åº”ç”¨é˜¶æ®µ"""
        logger.info(f"è¿›å…¥åº”ç”¨é˜¶æ®µ: {cycle.cycle_id}")
        
        cycle.phase = LearningPhase.APPLICATION
        
        applications = []
        
        # åº”ç”¨æ”¹è¿›çš„æ¨¡å¼
        for pattern in cycle.patterns:
            if pattern.get('confidence', 0) > 0.7:
                application = await self._apply_pattern_improvement(pattern)
                applications.append(application)
        
        # åº”ç”¨ä¼˜åŒ–ç­–ç•¥
        for strategy in cycle.strategies:
            if strategy.get('feasibility', 0) > 0.6:
                application = await self._apply_strategy_optimization(strategy)
                applications.append(application)
        
        # åº”ç”¨çŸ¥è¯†è¿ç§»
        knowledge_transfers = await self._apply_knowledge_transfer(cycle)
        applications.extend(knowledge_transfers)
        
        cycle.applications = applications
    
    async def _recursive_learning(self, parent_cycle: LearningCycle):
        """é€’å½’å­¦ä¹ """
        self.recursion_depth += 1
        
        if self.recursion_depth >= self.max_recursion_depth:
            logger.info(f"è¾¾åˆ°æœ€å¤§é€’å½’æ·±åº¦: {self.max_recursion_depth}")
            self.recursion_depth = 0
            return
        
        # åˆ›å»ºå­å¾ªç¯
        child_context = {
            'parent_cycle_id': parent_cycle.cycle_id,
            'recursive_depth': self.recursion_depth,
            'learning_focus': 'refinement'
        }
        
        child_cycle_id = await self.start_learning_cycle(child_context)
        
        # æ•´åˆå­¦ä¹ ç»“æœ
        await self._integrate_recursive_results(parent_cycle, child_cycle_id)
    
    async def _observe_performance_metrics(self) -> Dict[str, Any]:
        """è§‚å¯Ÿæ€§èƒ½æŒ‡æ ‡"""
        # æ¨¡æ‹Ÿæ€§èƒ½æ•°æ®æ”¶é›†
        metrics = {
            'response_time': np.random.normal(1.0, 0.2),
            'throughput': np.random.normal(100, 20),
            'error_rate': np.random.normal(0.05, 0.02),
            'resource_usage': np.random.normal(0.6, 0.1),
            'success_rate': np.random.normal(0.85, 0.1)
        }
        
        # ç¡®ä¿æŒ‡æ ‡åœ¨åˆç†èŒƒå›´å†…
        metrics['response_time'] = max(0.1, metrics['response_time'])
        metrics['throughput'] = max(10, metrics['throughput'])
        metrics['error_rate'] = max(0.0, min(1.0, metrics['error_rate']))
        metrics['resource_usage'] = max(0.0, min(1.0, metrics['resource_usage']))
        metrics['success_rate'] = max(0.0, min(1.0, metrics['success_rate']))
        
        return metrics
    
    async def _observe_pattern_performance(self) -> Dict[str, Any]:
        """è§‚å¯Ÿæ¨¡å¼è¡¨ç°"""
        pattern_performance = {}
        
        for pattern_id, pattern in self.learning_patterns.items():
            performance = {
                'pattern_id': pattern_id,
                'success_rate': pattern.success_rate,
                'confidence': pattern.confidence,
                'application_count': pattern.application_count,
                'last_applied': pattern.last_applied,
                'avg_outcome_score': np.mean([o.get('score', 0.5) for o in pattern.outcomes]) if pattern.outcomes else 0.5
            }
            pattern_performance[pattern_id] = performance
        
        return pattern_performance
    
    async def _observe_collaboration_effects(self) -> Dict[str, Any]:
        """è§‚å¯Ÿåä½œæ•ˆæœ"""
        # æ¨¡æ‹Ÿåä½œæ•°æ®
        collaboration_effects = {
            'agent_coordination_efficiency': np.random.normal(0.7, 0.1),
            'communication_overhead': np.random.normal(0.2, 0.05),
            'conflict_resolution_rate': np.random.normal(0.8, 0.1),
            'collective_intelligence_score': np.random.normal(0.75, 0.15)
        }
        
        return collaboration_effects
    
    async def _observe_adaptation_changes(self) -> Dict[str, Any]:
        """è§‚å¯Ÿé€‚åº”æ€§å˜åŒ–"""
        adaptation_changes = {
            'adaptation_speed': np.random.normal(0.5, 0.1),
            'adaptation_success_rate': np.random.normal(0.7, 0.1),
            'overadaptation_risk': np.random.normal(0.1, 0.05),
            'adaptation_breadth': np.random.normal(0.6, 0.1)
        }
        
        return adaptation_changes
    
    async def _identify_success_patterns(self, observations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è¯†åˆ«æˆåŠŸæ¨¡å¼"""
        success_patterns = []
        
        # ä»è§‚å¯Ÿä¸­æå–æˆåŠŸæŒ‡æ ‡
        performance_data = next((o for o in observations if o['type'] == 'performance'), {})
        if performance_data:
            metrics = performance_data['data']
            
            # è¯†åˆ«é«˜æˆåŠŸç‡çš„æ¡ä»¶
            if metrics.get('success_rate', 0) > 0.8:
                pattern = {
                    'pattern_id': f"success_{int(time.time())}",
                    'type': PatternType.SUCCESS,
                    'conditions': [
                        {'metric': 'success_rate', 'operator': '>', 'value': 0.8},
                        {'metric': 'error_rate', 'operator': '<', 'value': 0.1}
                    ],
                    'indicators': metrics,
                    'confidence': 0.8,
                    'description': 'é«˜æˆåŠŸç‡æ¨¡å¼'
                }
                success_patterns.append(pattern)
        
        return success_patterns
    
    async def _identify_failure_patterns(self, observations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è¯†åˆ«å¤±è´¥æ¨¡å¼"""
        failure_patterns = []
        
        # ä»è§‚å¯Ÿä¸­æå–å¤±è´¥æŒ‡æ ‡
        performance_data = next((o for o in observations if o['type'] == 'performance'), {})
        if performance_data:
            metrics = performance_data['data']
            
            # è¯†åˆ«é«˜é”™è¯¯ç‡çš„æ¡ä»¶
            if metrics.get('error_rate', 0) > 0.1:
                pattern = {
                    'pattern_id': f"failure_{int(time.time())}",
                    'type': PatternType.FAILURE,
                    'conditions': [
                        {'metric': 'error_rate', 'operator': '>', 'value': 0.1},
                        {'metric': 'success_rate', 'operator': '<', 'value': 0.7}
                    ],
                    'indicators': metrics,
                    'confidence': 0.7,
                    'description': 'é«˜é”™è¯¯ç‡æ¨¡å¼'
                }
                failure_patterns.append(pattern)
        
        return failure_patterns
    
    async def _identify_efficiency_patterns(self, observations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è¯†åˆ«æ•ˆç‡æ¨¡å¼"""
        efficiency_patterns = []
        
        # ä»è§‚å¯Ÿä¸­æå–æ•ˆç‡æŒ‡æ ‡
        performance_data = next((o for o in observations if o['type'] == 'performance'), {})
        if performance_data:
            metrics = performance_data['data']
            
            # è¯†åˆ«é«˜æ•ˆç‡æ¡ä»¶
            if metrics.get('response_time', 1) < 0.8 and metrics.get('throughput', 0) > 80:
                pattern = {
                    'pattern_id': f"efficiency_{int(time.time())}",
                    'type': PatternType.EFFICIENCY,
                    'conditions': [
                        {'metric': 'response_time', 'operator': '<', 'value': 0.8},
                        {'metric': 'throughput', 'operator': '>', 'value': 80}
                    ],
                    'indicators': metrics,
                    'confidence': 0.75,
                    'description': 'é«˜æ•ˆç‡æ¨¡å¼'
                }
                efficiency_patterns.append(pattern)
        
        return efficiency_patterns
    
    async def _identify_collaboration_patterns(self, observations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è¯†åˆ«åä½œæ¨¡å¼"""
        collaboration_patterns = []
        
        # ä»è§‚å¯Ÿä¸­æå–åä½œæŒ‡æ ‡
        collaboration_data = next((o for o in observations if o['type'] == 'collaboration'), {})
        if collaboration_data:
            metrics = collaboration_data['data']
            
            # è¯†åˆ«é«˜åä½œæ•ˆç‡æ¡ä»¶
            if metrics.get('agent_coordination_efficiency', 0) > 0.7:
                pattern = {
                    'pattern_id': f"collaboration_{int(time.time())}",
                    'type': PatternType.COLLABORATION,
                    'conditions': [
                        {'metric': 'agent_coordination_efficiency', 'operator': '>', 'value': 0.7},
                        {'metric': 'communication_overhead', 'operator': '<', 'value': 0.3}
                    ],
                    'indicators': metrics,
                    'confidence': 0.7,
                    'description': 'é«˜æ•ˆåä½œæ¨¡å¼'
                }
                collaboration_patterns.append(pattern)
        
        return collaboration_patterns
    
    async def _identify_adaptation_patterns(self, observations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è¯†åˆ«é€‚åº”æ¨¡å¼"""
        adaptation_patterns = []
        
        # ä»è§‚å¯Ÿä¸­æå–é€‚åº”æŒ‡æ ‡
        adaptation_data = next((o for o in observations if o['type'] == 'adaptation'), {})
        if adaptation_data:
            metrics = adaptation_data['data']
            
            # è¯†åˆ«å¿«é€Ÿé€‚åº”æ¡ä»¶
            if metrics.get('adaptation_speed', 0) > 0.6 and metrics.get('adaptation_success_rate', 0) > 0.7:
                pattern = {
                    'pattern_id': f"adaptation_{int(time.time())}",
                    'type': PatternType.ADAPTATION,
                    'conditions': [
                        {'metric': 'adaptation_speed', 'operator': '>', 'value': 0.6},
                        {'metric': 'adaptation_success_rate', 'operator': '>', 'value': 0.7}
                    ],
                    'indicators': metrics,
                    'confidence': 0.7,
                    'description': 'å¿«é€Ÿé€‚åº”æ¨¡å¼'
                }
                adaptation_patterns.append(pattern)
        
        return adaptation_patterns
    
    async def _generate_diagnosis_strategies(self, patterns: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆè¯Šæ–­ç­–ç•¥"""
        strategies = []
        
        # åŸºäºæ¨¡å¼ç”Ÿæˆç­–ç•¥
        for pattern in patterns:
            strategy = {
                'strategy_id': f"strategy_{pattern['pattern_id']}",
                'pattern_id': pattern['pattern_id'],
                'type': pattern['type'],
                'actions': [],
                'expected_outcomes': [],
                'feasibility': pattern.get('confidence', 0.5)
            }
            
            # æ ¹æ®æ¨¡å¼ç±»å‹ç”Ÿæˆè¡ŒåŠ¨
            if pattern['type'] == PatternType.SUCCESS:
                strategy['actions'] = [
                    {'action': 'reinforce', 'target': pattern['conditions']},
                    {'action': 'generalize', 'scope': 'similar_contexts'}
                ]
                strategy['expected_outcomes'] = [
                    {'metric': 'success_rate', 'improvement': 0.1},
                    {'metric': 'confidence', 'improvement': 0.05}
                ]
            
            elif pattern['type'] == PatternType.FAILURE:
                strategy['actions'] = [
                    {'action': 'mitigate', 'target': pattern['conditions']},
                    {'action': 'redesign', 'scope': 'affected_components'}
                ]
                strategy['expected_outcomes'] = [
                    {'metric': 'error_rate', 'reduction': 0.05},
                    {'metric': 'reliability', 'improvement': 0.1}
                ]
            
            elif pattern['type'] == PatternType.EFFICIENCY:
                strategy['actions'] = [
                    {'action': 'optimize', 'target': 'performance_bottlenecks'},
                    {'action': 'scale', 'scope': 'successful_patterns'}
                ]
                strategy['expected_outcomes'] = [
                    {'metric': 'response_time', 'reduction': 0.2},
                    {'metric': 'throughput', 'improvement': 0.15}
                ]
            
            strategies.append(strategy)
        
        return strategies
    
    async def _validate_pattern(self, pattern: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯æ¨¡å¼"""
        validation = {
            'pattern_id': pattern['pattern_id'],
            'type': 'validation',
            'validity_score': 0.0,
            'confidence': pattern.get('confidence', 0.5),
            'recommendations': []
        }
        
        # æ£€æŸ¥æ¨¡å¼ä¸€è‡´æ€§
        consistency_score = await self._check_pattern_consistency(pattern)
        validation['validity_score'] += consistency_score * 0.4
        
        # æ£€æŸ¥å†å²è¡¨ç°
        historical_score = await self._check_pattern_historical_performance(pattern)
        validation['validity_score'] += historical_score * 0.3
        
        # æ£€æŸ¥å¯åº”ç”¨æ€§
        applicability_score = await self._check_pattern_applicability(pattern)
        validation['validity_score'] += applicability_score * 0.3
        
        return validation
    
    async def _validate_strategy(self, strategy: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯ç­–ç•¥"""
        validation = {
            'strategy_id': strategy['strategy_id'],
            'type': 'validation',
            'feasibility': strategy.get('feasibility', 0.5),
            'expected_impact': 0.0,
            'risk_assessment': 0.0
        }
        
        # è¯„ä¼°é¢„æœŸå½±å“
        expected_outcomes = strategy.get('expected_outcomes', [])
        for outcome in expected_outcomes:
            validation['expected_impact'] += abs(outcome.get('improvement', 0) or outcome.get('reduction', 0))
        
        # è¯„ä¼°é£é™©
        risk_factors = await self._assess_strategy_risks(strategy)
        validation['risk_assessment'] = sum(risk_factors) / len(risk_factors) if risk_factors else 0.0
        
        return validation
    
    async def _run_simulations(self, strategies: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """è¿è¡Œæ¨¡æ‹Ÿæµ‹è¯•"""
        simulations = []
        
        for strategy in strategies:
            simulation = {
                'strategy_id': strategy['strategy_id'],
                'type': 'simulation',
                'simulated_outcomes': [],
                'success_probability': 0.0
            }
            
            # è¿è¡Œå¤šæ¬¡æ¨¡æ‹Ÿ
            for i in range(10):
                outcome = await self._simulate_strategy_execution(strategy)
                simulation['simulated_outcomes'].append(outcome)
            
            # è®¡ç®—æˆåŠŸæ¦‚ç‡
            success_count = sum(1 for o in simulation['simulated_outcomes'] if o.get('success', False))
            simulation['success_probability'] = success_count / 10
            
            simulations.append(simulation)
        
        return simulations
    
    async def _simulate_strategy_execution(self, strategy: Dict[str, Any]) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿç­–ç•¥æ‰§è¡Œ"""
        # ç®€åŒ–æ¨¡æ‹Ÿå®ç°
        base_success = strategy.get('feasibility', 0.5)
        
        # æ·»åŠ éšæœºå› ç´ 
        random_factor = np.random.normal(0, 0.1)
        success_probability = max(0.0, min(1.0, base_success + random_factor))
        
        success = np.random.random() < success_probability
        
        return {
            'success': success,
            'execution_time': np.random.normal(1.0, 0.2),
            'resource_usage': np.random.normal(0.5, 0.1),
            'outcome_score': np.random.normal(0.5, 0.2) if success else np.random.normal(0.2, 0.1)
        }
    
    async def _apply_pattern_improvement(self, pattern: Dict[str, Any]) -> Dict[str, Any]:
        """åº”ç”¨æ¨¡å¼æ”¹è¿›"""
        application = {
            'pattern_id': pattern['pattern_id'],
            'type': 'pattern_improvement',
            'improvements': [],
            'applied_at': datetime.now()
        }
        
        # æ›´æ–°æ¨¡å¼åº“
        if pattern['pattern_id'] in self.learning_patterns:
            existing_pattern = self.learning_patterns[pattern['pattern_id']]
            
            # æå‡ç½®ä¿¡åº¦
            existing_pattern.confidence = min(1.0, existing_pattern.confidence + 0.05)
            
            # è®°å½•åº”ç”¨
            existing_pattern.last_applied = datetime.now()
            existing_pattern.application_count += 1
            
            # è®°å½•æ¼”åŒ–
            existing_pattern.evolution_history.append({
                'timestamp': datetime.now(),
                'action': 'improvement',
                'confidence_before': existing_pattern.confidence - 0.05,
                'confidence_after': existing_pattern.confidence
            })
            
            application['improvements'].append({
                'field': 'confidence',
                'old_value': existing_pattern.confidence - 0.05,
                'new_value': existing_pattern.confidence
            })
        
        return application
    
    async def _apply_strategy_optimization(self, strategy: Dict[str, Any]) -> Dict[str, Any]:
        """åº”ç”¨ç­–ç•¥ä¼˜åŒ–"""
        application = {
            'strategy_id': strategy['strategy_id'],
            'type': 'strategy_optimization',
            'optimizations': [],
            'applied_at': datetime.now()
        }
        
        # æ›´æ–°å…ƒç­–ç•¥
        if self.active_strategy:
            # è°ƒæ•´å­¦ä¹ ç‡
            if strategy.get('success_probability', 0) > 0.7:
                self.active_strategy.learning_rate = min(0.1, self.active_strategy.learning_rate * 1.1)
            else:
                self.active_strategy.learning_rate = max(0.001, self.active_strategy.learning_rate * 0.9)
            
            application['optimizations'].append({
                'field': 'learning_rate',
                'new_value': self.active_strategy.learning_rate
            })
        
        return application
    
    async def _apply_knowledge_transfer(self, cycle: LearningCycle) -> List[Dict[str, Any]]:
        """åº”ç”¨çŸ¥è¯†è¿ç§»"""
        transfers = []
        
        # è¯†åˆ«å¯è¿ç§»çš„çŸ¥è¯†
        transferable_knowledge = await self._identify_transferable_knowledge(cycle)
        
        for knowledge in transferable_knowledge:
            transfer = {
                'knowledge_id': knowledge['id'],
                'source_domain': knowledge['source_domain'],
                'target_domain': knowledge['target_domain'],
                'transfer_method': knowledge['method'],
                'applied_at': datetime.now(),
                'effectiveness': 0.0
            }
            
            # æ‰§è¡Œè¿ç§»
            effectiveness = await self._execute_knowledge_transfer(knowledge)
            transfer['effectiveness'] = effectiveness
            
            transfers.append(transfer)
        
        return transfers
    
    async def _identify_transferable_knowledge(self, cycle: LearningCycle) -> List[Dict[str, Any]]:
        """è¯†åˆ«å¯è¿ç§»çš„çŸ¥è¯†"""
        transferable = []
        
        # ä»åº”ç”¨ç»“æœä¸­æå–çŸ¥è¯†
        for application in cycle.applications:
            if application.get('type') == 'pattern_improvement':
                knowledge = {
                    'id': f"knowledge_{application['pattern_id']}",
                    'source_domain': 'pattern_improvement',
                    'target_domain': 'strategy_optimization',
                    'method': 'pattern_based_transfer',
                    'content': application
                }
                transferable.append(knowledge)
        
        return transferable
    
    async def _execute_knowledge_transfer(self, knowledge: Dict[str, Any]) -> float:
        """æ‰§è¡ŒçŸ¥è¯†è¿ç§»"""
        # ç®€åŒ–å®ç°ï¼šåŸºäºé¢†åŸŸç›¸ä¼¼åº¦è®¡ç®—è¿ç§»æ•ˆæœ
        domain_similarity = await self._calculate_domain_similarity(
            knowledge['source_domain'],
            knowledge['target_domain']
        )
        
        return domain_similarity
    
    async def _calculate_domain_similarity(self, domain1: str, domain2: str) -> float:
        """è®¡ç®—é¢†åŸŸç›¸ä¼¼åº¦"""
        # ç®€åŒ–å®ç°
        domain_mappings = {
            ('pattern_improvement', 'strategy_optimization'): 0.8,
            ('efficiency', 'adaptation'): 0.7,
            ('collaboration', 'adaptation'): 0.6,
            ('success', 'efficiency'): 0.5
        }
        
        return domain_mappings.get((domain1, domain2), 0.3)
    
    async def _calculate_cycle_effectiveness(self, cycle: LearningCycle) -> float:
        """è®¡ç®—å¾ªç¯æ•ˆæœåˆ†æ•°"""
        effectiveness = 0.0
        
        # åŸºäºè§‚å¯Ÿè´¨é‡
        if cycle.observations:
            observation_quality = len([o for o in cycle.observations if o.get('data')])
            effectiveness += observation_quality * 0.1
        
        # åŸºäºæ¨¡å¼è¯†åˆ«
        if cycle.patterns:
            pattern_quality = sum(p.get('confidence', 0) for p in cycle.patterns) / len(cycle.patterns)
            effectiveness += pattern_quality * 0.2
        
        # åŸºäºç­–ç•¥ç”Ÿæˆ
        if cycle.strategies:
            strategy_quality = sum(s.get('feasibility', 0) for s in cycle.strategies) / len(cycle.strategies)
            effectiveness += strategy_quality * 0.2
        
        # åŸºäºéªŒè¯ç»“æœ
        if cycle.validation_results:
            validation_quality = sum(v.get('validity_score', 0) for v in cycle.validation_results) / len(cycle.validation_results)
            effectiveness += validation_quality * 0.2
        
        # åŸºäºåº”ç”¨æ•ˆæœ
        if cycle.applications:
            application_quality = len(cycle.applications) / max(len(cycle.patterns), 1)
            effectiveness += application_quality * 0.2
        
        # åŸºäºæ—¶é—´æ•ˆç‡
        if cycle.end_time and cycle.start_time:
            duration = (cycle.end_time - cycle.start_time).total_seconds()
            time_efficiency = max(0.0, 1.0 - duration / 3600)  # 1å°æ—¶ä¸ºåŸºå‡†
            effectiveness += time_efficiency * 0.1
        
        return min(1.0, effectiveness)
    
    async def _update_knowledge_base(self, observations: List[Dict[str, Any]]):
        """æ›´æ–°çŸ¥è¯†åº“"""
        for observation in observations:
            obs_type = observation['type']
            self.knowledge_base[obs_type].append(observation)
            
            # é™åˆ¶çŸ¥è¯†åº“å¤§å°
            if len(self.knowledge_base[obs_type]) > 1000:
                self.knowledge_base[obs_type] = self.knowledge_base[obs_type][-1000:]
    
    async def _check_pattern_consistency(self, pattern: Dict[str, Any]) -> float:
        """æ£€æŸ¥æ¨¡å¼ä¸€è‡´æ€§"""
        # ç®€åŒ–å®ç°
        return 0.7
    
    async def _check_pattern_historical_performance(self, pattern: Dict[str, Any]) -> float:
        """æ£€æŸ¥æ¨¡å¼å†å²è¡¨ç°"""
        pattern_id = pattern['pattern_id']
        
        if pattern_id not in self.learning_patterns:
            return 0.5
        
        existing_pattern = self.learning_patterns[pattern_id]
        return existing_pattern.success_rate
    
    async def _check_pattern_applicability(self, pattern: Dict[str, Any]) -> float:
        """æ£€æŸ¥æ¨¡å¼å¯åº”ç”¨æ€§"""
        # ç®€åŒ–å®ç°
        return 0.6
    
    async def _assess_strategy_risks(self, strategy: Dict[str, Any]) -> List[float]:
        """è¯„ä¼°ç­–ç•¥é£é™©"""
        # ç®€åŒ–å®ç°
        return [0.2, 0.1, 0.15]
    
    async def _integrate_recursive_results(self, parent_cycle: LearningCycle, child_cycle_id: str):
        """æ•´åˆé€’å½’ç»“æœ"""
        # æŸ¥æ‰¾å­å¾ªç¯
        child_cycle = next((c for c in self.cycle_history if c.cycle_id == child_cycle_id), None)
        
        if child_cycle:
            # æ•´åˆè§‚å¯Ÿ
            parent_cycle.observations.extend(child_cycle.observations)
            
            # æ•´åˆæ¨¡å¼
            parent_cycle.patterns.extend(child_cycle.patterns)
            
            # è°ƒæ•´æ•ˆæœåˆ†æ•°
            parent_cycle.effectiveness_score = (parent_cycle.effectiveness_score + child_cycle.effectiveness_score) / 2
    
    async def _load_learning_history(self):
        """åŠ è½½å­¦ä¹ å†å²"""
        history_file = PROJECT_ROOT / ".iflow" / "data" / "rml_history_v11.pkl"
        history_file.parent.mkdir(parents=True, exist_ok=True)
        
        if history_file.exists():
            try:
                with open(history_file, 'rb') as f:
                    history_data = pickle.load(f)
                
                # æ¢å¤å¾ªç¯å†å²
                for cycle_data in history_data.get('cycles', []):
                    cycle = LearningCycle(**cycle_data)
                    self.cycle_history.append(cycle)
                
                # æ¢å¤æ¨¡å¼åº“
                for pattern_data in history_data.get('patterns', []):
                    pattern = LearningPattern(**pattern_data)
                    self.learning_patterns[pattern.pattern_id] = pattern
                
                logger.info(f"åŠ è½½äº† {len(self.cycle_history)} ä¸ªå­¦ä¹ å¾ªç¯å’Œ {len(self.learning_patterns)} ä¸ªæ¨¡å¼")
                
            except Exception as e:
                logger.error(f"åŠ è½½å­¦ä¹ å†å²å¤±è´¥: {e}")
    
    async def _initialize_meta_strategies(self):
        """åˆå§‹åŒ–å…ƒå­¦ä¹ ç­–ç•¥"""
        # é»˜è®¤ç­–ç•¥
        default_strategy = MetaLearningStrategy(
            strategy_id="default",
            name="é»˜è®¤å…ƒå­¦ä¹ ç­–ç•¥",
            description="å¹³è¡¡çš„æ¢ç´¢ä¸åˆ©ç”¨",
            learning_rate=0.01,
            exploration_rate=0.1,
            memory_decay=0.01,
            pattern_threshold=0.7,
            adaptation_factor=0.05
        )
        
        self.meta_strategies[default_strategy.strategy_id] = default_strategy
        self.active_strategy = default_strategy
        
        logger.info("å…ƒå­¦ä¹ ç­–ç•¥åˆå§‹åŒ–å®Œæˆ")
    
    async def _build_pattern_evolution_graph(self):
        """æ„å»ºæ¨¡å¼æ¼”åŒ–å›¾"""
        for pattern in self.learning_patterns.values():
            self.pattern_evolution_graph.add_node(pattern.pattern_id, pattern=pattern)
        
        # åŸºäºæ¼”åŒ–å†å²æ„å»ºè¾¹
        for pattern in self.learning_patterns.values():
            for evolution in pattern.evolution_history:
                # ç®€åŒ–å®ç°ï¼šåˆ›å»ºæ—¶é—´åºåˆ—è¾¹
                self.pattern_evolution_graph.add_edge(
                    pattern.pattern_id,
                    f"{pattern.pattern_id}_evolved",
                    timestamp=evolution['timestamp'],
                    action=evolution['action']
                )
        
        logger.info(f"æ„å»ºæ¨¡å¼æ¼”åŒ–å›¾å®Œæˆï¼ŒèŠ‚ç‚¹æ•°: {self.pattern_evolution_graph.number_of_nodes()}")
    
    async def _continuous_learning_loop(self):
        """æŒç»­å­¦ä¹ å¾ªç¯"""
        while True:
            try:
                await asyncio.sleep(600)  # 10åˆ†é’Ÿ
                
                # è‡ªåŠ¨è§¦å‘å­¦ä¹ å¾ªç¯
                if self.should_trigger_learning():
                    context = {
                        'trigger': 'automatic',
                        'timestamp': datetime.now()
                    }
                    await self.start_learning_cycle(context)
                
            except Exception as e:
                logger.error(f"æŒç»­å­¦ä¹ å¾ªç¯é”™è¯¯: {e}")
    
    async def _pattern_evolution_loop(self):
        """æ¨¡å¼æ¼”åŒ–å¾ªç¯"""
        while True:
            try:
                await asyncio.sleep(3600)  # 1å°æ—¶
                
                # æ¼”åŒ–æ¨¡å¼
                await self._evolve_patterns()
                
                # æ¸…ç†è¿‡æœŸæ¨¡å¼
                await self._cleanup_expired_patterns()
                
            except Exception as e:
                logger.error(f"æ¨¡å¼æ¼”åŒ–å¾ªç¯é”™è¯¯: {e}")
    
    async def _meta_optimization_loop(self):
        """å…ƒä¼˜åŒ–å¾ªç¯"""
        while True:
            try:
                await asyncio.sleep(7200)  # 2å°æ—¶
                
                # ä¼˜åŒ–å…ƒç­–ç•¥
                await self._optimize_meta_strategies()
                
                # è°ƒæ•´å­¦ä¹ å‚æ•°
                await self._adjust_learning_parameters()
                
            except Exception as e:
                logger.error(f"å…ƒä¼˜åŒ–å¾ªç¯é”™è¯¯: {e}")
    
    async def _knowledge_integration_loop(self):
        """çŸ¥è¯†æ•´åˆå¾ªç¯"""
        while True:
            try:
                await asyncio.sleep(1800)  # 30åˆ†é’Ÿ
                
                # æ•´åˆè·¨åŸŸçŸ¥è¯†
                await self._integrate_cross_domain_knowledge()
                
                # æ›´æ–°çŸ¥è¯†å›¾è°±
                await self._update_knowledge_graph()
                
            except Exception as e:
                logger.error(f"çŸ¥è¯†æ•´åˆå¾ªç¯é”™è¯¯: {e}")
    
    def should_trigger_learning(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘å­¦ä¹ """
        # åŸºäºå¤šç§æ¡ä»¶åˆ¤æ–­
        conditions = [
            len(self.cycle_history) == 0,  # è¿˜æ²¡æœ‰å­¦ä¹ å†å²
            (datetime.now() - self.cycle_history[-1].end_time).total_seconds() > 3600 if self.cycle_history else True,  # è¶…è¿‡1å°æ—¶
            self.performance_metrics.get('error_rate', 0) > 0.1,  # é”™è¯¯ç‡è¿‡é«˜
            self.adaptation_capacity < 0.5  # é€‚åº”èƒ½åŠ›ä¸è¶³
        ]
        
        return any(conditions)
    
    async def _evolve_patterns(self):
        """æ¼”åŒ–æ¨¡å¼"""
        for pattern in self.learning_patterns.values():
            # åŸºäºåº”ç”¨å†å²æ¼”åŒ–
            if pattern.application_count > 10:
                await self._evolve_pattern_based_on_history(pattern)
    
    async def _evolve_pattern_based_on_history(self, pattern: LearningPattern):
        """åŸºäºå†å²æ¼”åŒ–æ¨¡å¼"""
        # åˆ†ææ¼”åŒ–å†å²
        if len(pattern.evolution_history) < 3:
            return
        
        recent_evolutions = pattern.evolution_history[-3:]
        
        # è¯†åˆ«æ¼”åŒ–è¶‹åŠ¿
        confidence_trend = [
            e['confidence_after'] - e['confidence_before']
            for e in recent_evolutions
            if 'confidence_before' in e and 'confidence_after' in e
        ]
        
        if confidence_trend:
            avg_improvement = sum(confidence_trend) / len(confidence_trend)
            
            # å¦‚æœè¶‹åŠ¿ä¸ºæ­£ï¼Œå¢å¼ºæ¨¡å¼
            if avg_improvement > 0:
                pattern.confidence = min(1.0, pattern.confidence + 0.02)
                pattern.success_rate = min(1.0, pattern.success_rate + 0.01)
    
    async def _cleanup_expired_patterns(self):
        """æ¸…ç†è¿‡æœŸæ¨¡å¼"""
        expiration_threshold = datetime.now() - timedelta(days=30)
        
        expired_patterns = [
            pattern_id for pattern_id, pattern in self.learning_patterns.items()
            if pattern.last_applied and pattern.last_applied < expiration_threshold
        ]
        
        for pattern_id in expired_patterns:
            del self.learning_patterns[pattern_id]
            logger.info(f"æ¸…ç†è¿‡æœŸæ¨¡å¼: {pattern_id}")
    
    async def _optimize_meta_strategies(self):
        """ä¼˜åŒ–å…ƒç­–ç•¥"""
        for strategy in self.meta_strategies.values():
            # åŸºäºæ€§èƒ½æŒ‡æ ‡è°ƒæ•´
            if self.performance_metrics.get('success_rate', 0) > 0.8:
                # æˆåŠŸç‡é«˜ï¼Œå¢åŠ æ¢ç´¢
                strategy.exploration_rate = min(0.3, strategy.exploration_rate * 1.1)
            else:
                # æˆåŠŸç‡ä½ï¼Œå¢åŠ åˆ©ç”¨
                strategy.exploration_rate = max(0.01, strategy.exploration_rate * 0.9)
    
    async def _adjust_learning_parameters(self):
        """è°ƒæ•´å­¦ä¹ å‚æ•°"""
        # åŸºäºå­¦ä¹ é€Ÿåº¦è°ƒæ•´
        if len(self.cycle_history) > 10:
            recent_cycles = list(self.cycle_history)[-10:]
            avg_effectiveness = sum(c.effectiveness_score for c in recent_cycles) / len(recent_cycles)
            
            if avg_effectiveness > 0.7:
                # å­¦ä¹ æ•ˆæœå¥½ï¼Œå¯ä»¥æ›´å¿«å­¦ä¹ 
                self.learning_velocity = min(1.0, self.learning_velocity + 0.01)
            else:
                # å­¦ä¹ æ•ˆæœå·®ï¼Œæ”¾æ…¢é€Ÿåº¦
                self.learning_velocity = max(0.1, self.learning_velocity - 0.01)
    
    async def _integrate_cross_domain_knowledge(self):
        """æ•´åˆè·¨åŸŸçŸ¥è¯†"""
        # è¯†åˆ«è·¨åŸŸå…³è”
        for domain1, knowledge_list in self.knowledge_base.items():
            for domain2, other_knowledge_list in self.knowledge_base.items():
                if domain1 != domain2:
                    # è®¡ç®—å…³è”åº¦
                    similarity = await self._calculate_domain_similarity(domain1, domain2)
                    
                    if similarity > 0.5:
                        # å»ºç«‹æ˜ å°„
                        if domain2 not in self.cross_domain_mappings[domain1]:
                            self.cross_domain_mappings[domain1].append(domain2)
    
    async def _update_knowledge_graph(self):
        """æ›´æ–°çŸ¥è¯†å›¾è°±"""
        # åŸºäºçŸ¥è¯†åº“æ›´æ–°å›¾è°±
        for domain, knowledge_list in self.knowledge_base.items():
            for knowledge in knowledge_list:
                # åˆ›å»ºçŸ¥è¯†èŠ‚ç‚¹
                knowledge_id = f"{domain}_{knowledge.get('timestamp', '')}"
                if not self.knowledge_graph.has_node(knowledge_id):
                    self.knowledge_graph.add_node(knowledge_id, domain=domain, data=knowledge)
    
    async def get_learning_status(self) -> Dict[str, Any]:
        """è·å–å­¦ä¹ çŠ¶æ€"""
        return {
            'active_cycle_id': self.active_cycle.cycle_id if self.active_cycle else None,
            'current_phase': self.current_phase.value,
            'total_cycles': len(self.cycle_history),
            'total_patterns': len(self.learning_patterns),
            'active_strategy': self.active_strategy.strategy_id if self.active_strategy else None,
            'learning_velocity': self.learning_velocity,
            'adaptation_capacity': self.adaptation_capacity,
            'performance_metrics': dict(self.performance_metrics)
        }
    
    async def shutdown(self):
        """ä¼˜é›…å…³é—­"""
        logger.info("æ­£åœ¨å…³é—­RMLå¼•æ“...")
        
        # ä¿å­˜å­¦ä¹ å†å²
        await self._save_learning_history()
        
        # å…³é—­çº¿ç¨‹æ± 
        self.executor.shutdown(wait=True)
        
        logger.info("RMLå¼•æ“å·²å…³é—­")
    
    async def _save_learning_history(self):
        """ä¿å­˜å­¦ä¹ å†å²"""
        history_file = PROJECT_ROOT / ".iflow" / "data" / "rml_history_v11.pkl"
        history_file.parent.mkdir(parents=True, exist_ok=True)
        
        try:
            history_data = {
                'timestamp': datetime.now().isoformat(),
                'cycles': [
                    asdict(cycle) for cycle in self.cycle_history
                ],
                'patterns': [
                    asdict(pattern) for pattern in self.learning_patterns.values()
                ],
                'meta_strategies': {
                    strategy_id: asdict(strategy) for strategy in self.meta_strategies.values()
                },
                'performance_metrics': dict(self.performance_metrics),
                'knowledge_base': dict(self.knowledge_base)
            }
            
            with open(history_file, 'wb') as f:
                pickle.dump(history_data, f)
            
            logger.info("å­¦ä¹ å†å²ä¿å­˜æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"ä¿å­˜å­¦ä¹ å†å²å¤±è´¥: {e}")

# å…¨å±€å®ä¾‹
_rml_engine: Optional[RMLEngineV11] = None

async def get_rml_engine() -> RMLEngineV11:
    """è·å–RMLå¼•æ“å®ä¾‹"""
    global _rml_engine
    if _rml_engine is None:
        _rml_engine = RMLEngineV11()
        await _rml_engine.initialize()
    return _rml_engine

async def start_learning_cycle(context: Dict[str, Any]) -> str:
    """å¼€å§‹å­¦ä¹ å¾ªç¯çš„ä¾¿æ·å‡½æ•°"""
    engine = await get_rml_engine()
    return await engine.start_learning_cycle(context)