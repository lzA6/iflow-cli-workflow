#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸŒŸ å¹¶è¡Œæ‰§è¡Œå¼•æ“é›†æˆæµ‹è¯•
éªŒè¯æ‰€æœ‰å¹¶è¡Œæ‰§è¡Œç»„ä»¶çš„ååŒå·¥ä½œï¼Œå±•ç¤ºæ•´ä½“æ€§èƒ½æå‡æ•ˆæœã€‚
ä½ ä¸€å®šè¦è¶…çº§æ€è€ƒã€æé™æ€è€ƒã€æ·±åº¦æ€è€ƒï¼Œå…¨åŠ›æ€è€ƒã€è¶…å¼ºæ€è€ƒï¼Œè®¤çœŸä»”ç»†æ€è€ƒï¼ˆultrathinkã€think really super hardã€think intenselyï¼‰ã€‚
"""

import os
import sys
import json
import asyncio
import logging
import time
from pathlib import Path
from typing import Dict, List, Any
import statistics

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from iflow.core.optimized_fusion_cache import OptimizedFusionCache
from iflow.core.parallel_agent_executor import ParallelAgentExecutor, AgentRole
from iflow.core.task_decomposer import TaskDecomposer
from iflow.core.workflow_stage_parallelizer import WorkflowStageParallelizer, WorkflowStage, WorkflowStageInfo

logger = logging.getLogger(__name__)

class ParallelExecutionBenchmark:
    """å¹¶è¡Œæ‰§è¡ŒåŸºå‡†æµ‹è¯•"""
    
    def __init__(self):
        self.test_results = []
        self.performance_metrics = {}
        
        # åˆ›å»ºæµ‹è¯•ç»„ä»¶
        self.cache = OptimizedFusionCache(cache_size=100, ttl_hours=1)
        self.agent_executor = ParallelAgentExecutor(max_concurrent_agents=8, enable_cache=True)
        self.task_decomposer = TaskDecomposer()
        self.workflow_parallelizer = WorkflowStageParallelizer(max_concurrent_stages=6)
    
    async def run_comprehensive_test(self):
        """è¿è¡Œç»¼åˆæµ‹è¯•"""
        print("=" * 80)
        print("ğŸš€ å¹¶è¡Œæ‰§è¡Œå¼•æ“ç»¼åˆæ€§èƒ½æµ‹è¯•")
        print("=" * 80)
        
        # 1. ç¼“å­˜æ€§èƒ½æµ‹è¯•
        await self._test_cache_performance()
        
        # 2. æ™ºèƒ½ä½“å¹¶è¡Œæµ‹è¯•
        await self._test_agent_parallelism()
        
        # 3. ä»»åŠ¡åˆ†è§£æµ‹è¯•
        await self._test_task_decomposition()
        
        # 4. å·¥ä½œæµé˜¶æ®µå¹¶è¡Œæµ‹è¯•
        await self._test_workflow_parallelism()
        
        # 5. ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•
        await self._test_end_to_end_integration()
        
        # 6. ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        self._generate_performance_report()
    
    async def _test_cache_performance(self):
        """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
        print("\nğŸ“Š æµ‹è¯•ç¼“å­˜æ€§èƒ½...")
        
        start_time = time.time()
        
        # æ¨¡æ‹Ÿç¼“å­˜æ“ä½œ
        test_tasks = [
            "è®¾è®¡ç”µå•†ç³»ç»Ÿæ¶æ„",
            "å¼€å‘ç”¨æˆ·ç®¡ç†ç³»ç»Ÿ",
            "å®ç°æ”¯ä»˜åŠŸèƒ½",
            "ç¼–å†™æµ‹è¯•ç”¨ä¾‹",
            "éƒ¨ç½²åˆ°äº‘å¹³å°"
        ]
        
        # é¦–æ¬¡æ‰§è¡Œï¼ˆç¼“å­˜æœªå‘½ä¸­ï¼‰
        for task in test_tasks:
            self.cache.put_cache_result(
                task=task,
                context={"test": True},
                selected_experts=["æ¶æ„å¸ˆ", "å¼€å‘ä¸“å®¶"],
                fusion_mode="parallel",
                result=f"ç»“æœ: {task}",
                quality_score=0.9,
                execution_time=1.5
            )
        
        # ç¬¬äºŒæ¬¡æ‰§è¡Œï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
        cache_hits = 0
        for task in test_tasks:
            result = self.cache.get_cached_result(task, {"test": True})
            if result:
                cache_hits += 1
        
        cache_time = time.time() - start_time
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        cache_hit_rate = cache_hits / len(test_tasks)
        cache_efficiency = len(test_tasks) / cache_time if cache_time > 0 else 0
        
        self.performance_metrics["cache"] = {
            "hit_rate": cache_hit_rate,
            "efficiency": cache_efficiency,
            "time_saved": cache_time,
            "memory_usage": self.cache._estimate_memory_usage()
        }
        
        print(f"   âœ… ç¼“å­˜å‘½ä¸­ç‡: {cache_hit_rate:.2%}")
        print(f"   âœ… ç¼“å­˜æ•ˆç‡: {cache_efficiency:.1f} æ¬¡/ç§’")
        print(f"   âœ… å†…å­˜ä½¿ç”¨: {self.performance_metrics['cache']['memory_usage']:.2f} MB")
    
    async def _test_agent_parallelism(self):
        """æµ‹è¯•æ™ºèƒ½ä½“å¹¶è¡Œæ€§èƒ½"""
        print("\nğŸ¤– æµ‹è¯•æ™ºèƒ½ä½“å¹¶è¡Œæ€§èƒ½...")
        
        start_time = time.time()
        
        # å®šä¹‰ä¸“å®¶åˆ†é…
        expert_assignments = {
            "æ¶æ„å¸ˆ": AgentRole.SPECIALIST,
            "å‰ç«¯ä¸“å®¶": AgentRole.SPECIALIST,
            "åç«¯ä¸“å®¶": AgentRole.SPECIALIST,
            "æµ‹è¯•ä¸“å®¶": AgentRole.VALIDATOR,
            "éƒ¨ç½²ä¸“å®¶": AgentRole.INTEGRATOR,
            "å®‰å…¨ä¸“å®¶": AgentRole.SPECIALIST
        }
        
        # å®šä¹‰å­ä»»åŠ¡
        subtasks = [
            {
                "description": "è®¾è®¡ç³»ç»Ÿæ¶æ„å’Œæ•°æ®åº“æ¨¡å‹",
                "preferred_agent": "æ¶æ„å¸ˆ",
                "role": AgentRole.SPECIALIST,
                "priority": 1,
                "dependencies": [],
                "estimated_duration": 2.0
            },
            {
                "description": "å¼€å‘å‰ç«¯ç”¨æˆ·ç•Œé¢",
                "preferred_agent": "å‰ç«¯ä¸“å®¶",
                "role": AgentRole.SPECIALIST,
                "priority": 2,
                "dependencies": [],
                "estimated_duration": 3.0
            },
            {
                "description": "å®ç°åç«¯APIæ¥å£",
                "preferred_agent": "åç«¯ä¸“å®¶",
                "role": AgentRole.SPECIALIST,
                "priority": 2,
                "dependencies": [],
                "estimated_duration": 4.0
            },
            {
                "description": "ç¼–å†™å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•",
                "preferred_agent": "æµ‹è¯•ä¸“å®¶",
                "role": AgentRole.VALIDATOR,
                "priority": 3,
                "dependencies": ["sub_1", "sub_2"],
                "estimated_duration": 2.5
            },
            {
                "description": "é…ç½®CI/CDå’Œéƒ¨ç½²è„šæœ¬",
                "preferred_agent": "éƒ¨ç½²ä¸“å®¶",
                "role": AgentRole.INTEGRATOR,
                "priority": 4,
                "dependencies": ["sub_1", "sub_2"],
                "estimated_duration": 1.5
            }
        ]
        
        # å¹¶è¡Œæ‰§è¡Œ
        result = await self.agent_executor.execute_parallel_task(
            task_description="å¼€å‘ä¸€ä¸ªå®Œæ•´çš„ç”µå•†å¹³å°",
            expert_assignments=expert_assignments,
            subtasks=subtasks
        )
        
        parallel_time = time.time() - start_time
        
        # è®¡ç®—ä¸²è¡Œæ—¶é—´ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
        serial_time = sum(task["estimated_duration"] for task in subtasks)
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        speedup_ratio = serial_time / parallel_time if parallel_time > 0 else 0
        efficiency = speedup_ratio / len(expert_assignments) * 100
        
        self.performance_metrics["agent_parallelism"] = {
            "success": result.success,
            "parallel_time": parallel_time,
            "serial_time": serial_time,
            "speedup_ratio": speedup_ratio,
            "efficiency": efficiency,
            "quality_score": result.quality_score,
            "resource_utilization": result.resource_usage
        }
        
        print(f"   âœ… å¹¶è¡Œæ—¶é—´: {parallel_time:.2f}s")
        print(f"   âœ… ä¸²è¡Œæ—¶é—´: {serial_time:.2f}s")
        print(f"   âœ… åŠ é€Ÿæ¯”: {speedup_ratio:.2f}x")
        print(f"   âœ… æ•ˆç‡: {efficiency:.1f}%")
        print(f"   âœ… è´¨é‡è¯„åˆ†: {result.quality_score:.2f}")
    
    async def _test_task_decomposition(self):
        """æµ‹è¯•ä»»åŠ¡åˆ†è§£æ€§èƒ½"""
        print("\nğŸ¯ æµ‹è¯•ä»»åŠ¡åˆ†è§£æ€§èƒ½...")
        
        start_time = time.time()
        
        # å¤æ‚ä»»åŠ¡
        complex_task = """
        å¼€å‘ä¸€ä¸ªé«˜æ€§èƒ½çš„ç¤¾äº¤ç”µå•†å¹³å°ï¼Œéœ€è¦åŒ…å«ç”¨æˆ·ç®¡ç†ã€å•†å“ç®¡ç†ã€è®¢å•å¤„ç†ã€
        æ”¯ä»˜é›†æˆã€åº“å­˜ç®¡ç†ã€æ¨èç³»ç»Ÿã€ç¤¾äº¤åŠŸèƒ½ã€ç›´æ’­å¸¦è´§ã€æ•°æ®åˆ†æç­‰åŠŸèƒ½ã€‚
        ç³»ç»Ÿéœ€è¦æ”¯æŒé«˜å¹¶å‘è®¿é—®ï¼Œå…·å¤‡è‰¯å¥½çš„å¯æ‰©å±•æ€§ã€å®‰å…¨æ€§å’Œç”¨æˆ·ä½“éªŒã€‚
        è¦æ±‚æä¾›å®Œæ•´çš„å‰ç«¯ç•Œé¢ã€åç«¯APIã€æ•°æ®åº“è®¾è®¡ã€ç§»åŠ¨ç«¯åº”ç”¨å’Œéƒ¨ç½²æ–¹æ¡ˆã€‚
        """
        
        # åˆ†è§£ä»»åŠ¡
        subtasks = self.task_decomposer.decompose_task(
            original_task=complex_task,
            domain="ç¤¾äº¤ç”µå•†ç³»ç»Ÿå¼€å‘",
            max_subtasks=20
        )
        
        decomposition_time = time.time() - start_time
        
        # åˆ†æåˆ†è§£ç»“æœ
        total_subtasks = len(subtasks)
        parallelizable_subtasks = sum(1 for task in subtasks if task.parallelizable)
        avg_complexity = statistics.mean([task.estimated_complexity for task in subtasks])
        total_duration = sum([task.estimated_duration for task in subtasks])
        
        # è®¡ç®—å¹¶è¡Œæ½œåŠ›
        sequential_stages = [task for task in subtasks if not task.parallelizable]
        sequential_duration = sum([task.estimated_duration for task in sequential_stages])
        parallel_potential = (total_duration - sequential_duration) / total_duration if total_duration > 0 else 0
        
        self.performance_metrics["task_decomposition"] = {
            "total_subtasks": total_subtasks,
            "parallelizable_count": parallelizable_subtasks,
            "parallelizable_ratio": parallelizable_subtasks / total_subtasks if total_subtasks > 0 else 0,
            "avg_complexity": avg_complexity,
            "total_duration": total_duration,
            "sequential_duration": sequential_duration,
            "parallel_potential": parallel_potential,
            "decomposition_time": decomposition_time
        }
        
        print(f"   âœ… åˆ†è§£å‡º {total_subtasks} ä¸ªå­ä»»åŠ¡")
        print(f"   âœ… å¯å¹¶è¡Œä»»åŠ¡: {parallelizable_subtasks} ({parallelizable_subtasks/total_subtasks*100:.1f}%)")
        print(f"   âœ… å¹¶è¡Œæ½œåŠ›: {parallel_potential:.2%}")
        print(f"   âœ… åˆ†è§£æ—¶é—´: {decomposition_time:.3f}s")
        print(f"   âœ… å¹³å‡å¤æ‚åº¦: {avg_complexity:.1f}")
    
    async def _test_workflow_parallelism(self):
        """æµ‹è¯•å·¥ä½œæµé˜¶æ®µå¹¶è¡Œæ€§èƒ½"""
        print("\nâš™ï¸ æµ‹è¯•å·¥ä½œæµé˜¶æ®µå¹¶è¡Œæ€§èƒ½...")
        
        start_time = time.time()
        
        # å®šä¹‰å·¥ä½œæµé˜¶æ®µ
        stages = [
            WorkflowStageInfo(
                stage_id="",  # ç¨åè®¾ç½®
                stage_type=WorkflowStage.INITIALIZATION,
                stage_name="é¡¹ç›®åˆå§‹åŒ–",
                description="åˆ›å»ºé¡¹ç›®ç»“æ„å’Œé…ç½®æ–‡ä»¶",
                status=None,  # ç”±æ‰§è¡Œå™¨è®¾ç½®
                estimated_duration=0.5,
                parallelizable=False,
                resource_requirements={"cpu": 10, "memory": 5, "agents": 1}
            ),
            WorkflowStageInfo(
                stage_id="",  # ç¨åè®¾ç½®
                stage_type=WorkflowStage.ANALYSIS,
                stage_name="éœ€æ±‚åˆ†æ",
                description="åˆ†æç”¨æˆ·éœ€æ±‚å’Œç³»ç»Ÿéœ€æ±‚",
                status=None,
                estimated_duration=2.0,
                parallelizable=True,
                resource_requirements={"cpu": 20, "memory": 15, "agents": 2}
            ),
            WorkflowStageInfo(
                stage_id="",  # ç¨åè®¾ç½®
                stage_type=WorkflowStage.DESIGN,
                stage_name="ç³»ç»Ÿè®¾è®¡",
                description="è®¾è®¡ç³»ç»Ÿæ¶æ„å’Œæ•°æ®åº“",
                status=None,
                estimated_duration=3.0,
                parallelizable=True,
                resource_requirements={"cpu": 25, "memory": 20, "agents": 3}
            ),
            WorkflowStageInfo(
                stage_id="",  # ç¨åè®¾ç½®
                stage_type=WorkflowStage.IMPLEMENTATION,
                stage_name="æ ¸å¿ƒå¼€å‘",
                description="å®ç°æ ¸å¿ƒåŠŸèƒ½æ¨¡å—",
                status=None,
                estimated_duration=8.0,
                parallelizable=True,
                resource_requirements={"cpu": 40, "memory": 30, "agents": 4}
            ),
            WorkflowStageInfo(
                stage_id="",  # ç¨åè®¾ç½®
                stage_type=WorkflowStage.TESTING,
                stage_name="æµ‹è¯•éªŒè¯",
                description="ç¼–å†™å’Œæ‰§è¡Œæµ‹è¯•ç”¨ä¾‹",
                status=None,
                estimated_duration=3.0,
                parallelizable=True,
                resource_requirements={"cpu": 30, "memory": 25, "agents": 3}
            ),
            WorkflowStageInfo(
                stage_id="",  # ç¨åè®¾ç½®
                stage_type=WorkflowStage.DEPLOYMENT,
                stage_name="éƒ¨ç½²ä¸Šçº¿",
                description="éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ",
                status=None,
                estimated_duration=1.0,
                parallelizable=False,
                resource_requirements={"cpu": 20, "memory": 15, "agents": 2}
            ),
            WorkflowStageInfo(
                stage_id="",  # ç¨åè®¾ç½®
                stage_type=WorkflowStage.OPTIMIZATION,
                stage_name="æ€§èƒ½ä¼˜åŒ–",
                description="ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½å’Œç”¨æˆ·ä½“éªŒ",
                status=None,
                estimated_duration=2.0,
                parallelizable=True,
                resource_requirements={"cpu": 35, "memory": 25, "agents": 3}
            )
        ]
        
        # å¹¶è¡Œæ‰§è¡Œå·¥ä½œæµ
        result = await self.workflow_parallelizer.execute_workflow_parallel(stages)
        
        workflow_time = time.time() - start_time
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        serial_duration = sum(stage.estimated_duration for stage in stages)
        speedup_ratio = serial_duration / result.overall_duration if result.overall_duration > 0 else 0
        
        self.performance_metrics["workflow_parallelism"] = {
            "success": result.success,
            "parallel_time": result.overall_duration,
            "serial_time": serial_duration,
            "speedup_ratio": speedup_ratio,
            "efficiency_score": result.efficiency_score,
            "resource_utilization": result.resource_utilization,
            "bottleneck_analysis": result.bottleneck_analysis
        }
        
        print(f"   âœ… å¹¶è¡Œæ—¶é—´: {result.overall_duration:.2f}s")
        print(f"   âœ… ä¸²è¡Œæ—¶é—´: {serial_duration:.2f}s")
        print(f"   âœ… åŠ é€Ÿæ¯”: {speedup_ratio:.2f}x")
        print(f"   âœ… æ•ˆç‡è¯„åˆ†: {result.efficiency_score:.2f}")
    
    async def _test_end_to_end_integration(self):
        """æµ‹è¯•ç«¯åˆ°ç«¯é›†æˆæ€§èƒ½"""
        print("\nğŸ”— æµ‹è¯•ç«¯åˆ°ç«¯é›†æˆæ€§èƒ½...")
        
        start_time = time.time()
        
        # 1. åˆ†è§£å¤æ‚ä»»åŠ¡
        complex_task = "å¼€å‘ä¸€ä¸ªAIé©±åŠ¨çš„æ™ºèƒ½å­¦ä¹ å¹³å°"
        subtasks = self.task_decomposer.decompose_task(complex_task, "æ•™è‚²ç§‘æŠ€", max_subtasks=15)
        
        # 2. ä¸ºæ¯ä¸ªå­ä»»åŠ¡åˆ›å»ºå·¥ä½œæµé˜¶æ®µ
        workflow_stages = []
        for i, subtask in enumerate(subtasks[:6]):  # é™åˆ¶æ•°é‡ä»¥é¿å…æµ‹è¯•è¿‡é•¿
            stage = WorkflowStageInfo(
                stage_id="",
                stage_type=WorkflowStage.IMPLEMENTATION,
                stage_name=f"{subtask.subtask_description}",
                description=f"å®ç° {subtask.subtask_description}",
                status=None,
                estimated_duration=subtask.estimated_duration,
                parallelizable=subtask.parallelizable,
                resource_requirements={"cpu": 20, "memory": 15, "agents": 2}
            )
            workflow_stages.append(stage)
        
        # 3. å¹¶è¡Œæ‰§è¡Œé›†æˆå·¥ä½œæµ
        result = await self.workflow_parallelizer.execute_workflow_parallel(workflow_stages)
        
        end_to_end_time = time.time() - start_time
        
        # è®¡ç®—æ€»ä½“æ€§èƒ½
        total_subtasks = len(subtasks)
        completed_stages = len([s for s in result.stage_results.values() if s.status.value == "completed"])
        
        self.performance_metrics["end_to_end"] = {
            "total_decomposed_tasks": total_subtasks,
            "completed_stages": completed_stages,
            "integration_time": end_to_end_time,
            "success_rate": result.success,
            "overall_efficiency": result.efficiency_score
        }
        
        print(f"   âœ… åˆ†è§£ä»»åŠ¡æ•°: {total_subtasks}")
        print(f"   âœ… å®Œæˆé˜¶æ®µæ•°: {completed_stages}")
        print(f"   âœ… é›†æˆæ—¶é—´: {end_to_end_time:.2f}s")
        print(f"   âœ… æˆåŠŸç‡: {result.success}")
    
    def _generate_performance_report(self):
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        print("\n" + "=" * 80)
        print("ğŸ“ˆ å¹¶è¡Œæ‰§è¡Œå¼•æ“æ€§èƒ½æŠ¥å‘Š")
        print("=" * 80)
        
        # æ€»ä½“æ€§èƒ½æ‘˜è¦
        print("\nğŸ“Š æ€»ä½“æ€§èƒ½æ‘˜è¦:")
        
        cache_perf = self.performance_metrics.get("cache", {})
        agent_perf = self.performance_metrics.get("agent_parallelism", {})
        task_perf = self.performance_metrics.get("task_decomposition", {})
        workflow_perf = self.performance_metrics.get("workflow_parallelism", {})
        
        print(f"   ğŸ”§ ç¼“å­˜æ•ˆç‡: {cache_perf.get('efficiency', 0):.1f} æ¬¡/ç§’")
        print(f"   ğŸ¤– æ™ºèƒ½ä½“å¹¶è¡ŒåŠ é€Ÿ: {agent_perf.get('speedup_ratio', 0):.2f}x")
        print(f"   ğŸ¯ ä»»åŠ¡åˆ†è§£å¹¶è¡Œæ½œåŠ›: {task_perf.get('parallel_potential', 0)*100:.1f}%")
        print(f"   âš™ï¸ å·¥ä½œæµé˜¶æ®µå¹¶è¡ŒåŠ é€Ÿ: {workflow_perf.get('speedup_ratio', 0):.2f}x")
        
        # æ€§èƒ½æå‡æ€»ç»“
        print(f"\nğŸš€ æ€§èƒ½æå‡æ€»ç»“:")
        
        avg_agent_speedup = agent_perf.get('speedup_ratio', 1)
        avg_workflow_speedup = workflow_perf.get('speedup_ratio', 1)
        avg_parallel_potential = task_perf.get('parallel_potential', 0.5)
        
        # ç»¼åˆæ€§èƒ½æå‡è®¡ç®—
        overall_improvement = (
            avg_agent_speedup * 
            avg_workflow_speedup * 
            (1 + avg_parallel_potential)
        )
        
        print(f"   ğŸ“ˆ æ™ºèƒ½ä½“å¹¶è¡Œæå‡: {avg_agent_speedup:.2f}x")
        print(f"   ğŸ“ˆ å·¥ä½œæµå¹¶è¡Œæå‡: {avg_workflow_speedup:.2f}x")
        print(f"   ğŸ“ˆ ä»»åŠ¡å¹¶è¡Œæ½œåŠ›: {avg_parallel_potential*100:.1f}%")
        print(f"   ğŸ“ˆ ç»¼åˆæ€§èƒ½æå‡: {overall_improvement:.2f}x")
        
        # èµ„æºåˆ©ç”¨æ•ˆç‡
        print(f"\nâš¡ èµ„æºåˆ©ç”¨æ•ˆç‡:")
        
        agent_utilization = agent_perf.get('resource_utilization', {})
        workflow_utilization = workflow_perf.get('resource_utilization', {})
        
        if agent_utilization:
            cpu_util = agent_utilization.get('cpu', {}).get('utilization_rate', 0)
            memory_util = agent_utilization.get('memory', {}).get('utilization_rate', 0)
            print(f"   ğŸ’» æ™ºèƒ½ä½“CPUåˆ©ç”¨ç‡: {cpu_util*100:.1f}%")
            print(f"   ğŸ§  æ™ºèƒ½ä½“å†…å­˜åˆ©ç”¨ç‡: {memory_util*100:.1f}%")
        
        if workflow_utilization:
            agent_count = workflow_utilization.get('agents', {}).get('utilization_rate', 0)
            print(f"   ğŸ‘¥ å·¥ä½œæµæ™ºèƒ½ä½“åˆ©ç”¨ç‡: {agent_count*100:.1f}%")
        
        # è´¨é‡ä¿è¯
        print(f"\nğŸ›¡ï¸ è´¨é‡ä¿è¯:")
        
        cache_quality = cache_perf.get('memory_usage', 0)
        agent_quality = agent_perf.get('quality_score', 0)
        workflow_quality = workflow_perf.get('efficiency_score', 0)
        
        print(f"   ğŸ“š ç¼“å­˜å†…å­˜ä½¿ç”¨: {cache_quality:.2f} MB")
        print(f"   ğŸ¯ æ™ºèƒ½ä½“æ‰§è¡Œè´¨é‡: {agent_quality:.2f}/1.0")
        print(f"   âš™ï¸ å·¥ä½œæµæ‰§è¡Œæ•ˆç‡: {workflow_quality:.2f}/10.0")
        
        # å»ºè®®å’Œä¼˜åŒ–æ–¹å‘
        print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        
        if avg_agent_speedup < 2.0:
            print("   ğŸ”§ å»ºè®®å¢åŠ æ™ºèƒ½ä½“å¹¶å‘æ•°é‡ä»¥æå‡å¹¶è¡Œæ•ˆç‡")
        
        if avg_workflow_speedup < 2.0:
            print("   âš™ï¸ å»ºè®®ä¼˜åŒ–å·¥ä½œæµé˜¶æ®µä¾èµ–å…³ç³»ï¼Œå¢åŠ å¹¶è¡Œæ€§")
        
        if avg_parallel_potential < 0.5:
            print("   ğŸ¯ å»ºè®®æ”¹è¿›ä»»åŠ¡åˆ†è§£ç®—æ³•ï¼Œæé«˜å¹¶è¡Œæ½œåŠ›")
        
        print(f"   ğŸš€ ç»¼åˆæ¥çœ‹ï¼Œå¹¶è¡Œæ‰§è¡Œå¼•æ“èƒ½å¤Ÿæ˜¾è‘—æå‡å·¥ä½œæµæ‰§è¡Œæ•ˆç‡ï¼")
        
        print("\n" + "=" * 80)
        print("âœ… å¹¶è¡Œæ‰§è¡Œå¼•æ“é›†æˆæµ‹è¯•å®Œæˆ")
        print("=" * 80)

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # è¿è¡Œç»¼åˆæµ‹è¯•
    benchmark = ParallelExecutionBenchmark()
    await benchmark.run_comprehensive_test()

if __name__ == "__main__":
    asyncio.run(main())