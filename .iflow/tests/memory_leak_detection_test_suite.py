#!/usr/bin/env python3
"""
ç¼“å­˜ç³»ç»Ÿå†…å­˜æ³„æ¼æ£€æµ‹å¥—ä»¶
ä¸“é—¨æ£€æµ‹é•¿æ—¶é—´è¿è¡Œä¸‹çš„å†…å­˜æ³„æ¼é—®é¢˜

æµ‹è¯•ç›®æ ‡ï¼š
1. éªŒè¯é•¿æ—¶é—´è¿è¡Œä¸‹çš„å†…å­˜ç¨³å®šæ€§
2. æ£€æµ‹ç¼“å­˜ç³»ç»Ÿçš„å†…å­˜æ³„æ¼æƒ…å†µ
3. æµ‹è¯•åƒåœ¾å›æ”¶æœºåˆ¶çš„æœ‰æ•ˆæ€§
4. è¯„ä¼°å†…å­˜ä½¿ç”¨è¶‹åŠ¿å’Œå¢é•¿æ¨¡å¼
5. éªŒè¯å†…å­˜ä¼˜åŒ–ç­–ç•¥çš„æ•ˆæœ

ä½œè€…ï¼šAé¡¹ç›®V7å‡çº§ç‰ˆ
åˆ›å»ºæ—¶é—´ï¼š2025-11-13
"""

import time
import threading
import gc
import weakref
import tracemalloc
import psutil
import os
import sys
import json
import logging
import asyncio
import statistics
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass, field
from collections import defaultdict, deque
from datetime import datetime, timedelta

# å¯¼å…¥Aé¡¹ç›®çš„æ ¸å¿ƒç»„ä»¶
try:
    from ..core.optimized_fusion_cache import OptimizedFusionCache
    from ..core.intelligent_context_manager import IntelligentContextManager
    from ..core.unified_model_adapter import UnifiedModelAdapter
    from ..core.parallel_agent_executor import ParallelAgentExecutor
    from ..core.task_decomposer import TaskDecomposer
    from ..core.workflow_stage_parallelizer import WorkflowStageParallelizer
except ImportError:
    # å¤‡ç”¨å¯¼å…¥è·¯å¾„
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    
    from core.optimized_fusion_cache import OptimizedFusionCache
    from core.intelligent_context_manager import IntelligentContextManager
    from core.unified_model_adapter import UnifiedModelAdapter
    from core.parallel_agent_executor import ParallelAgentExecutor
    from core.task_decomposer import TaskDecomposer
    from core.workflow_stage_parallelizer import WorkflowStageParallelizer

@dataclass
class MemoryLeakMetric:
    """å†…å­˜æ³„æ¼æŒ‡æ ‡æ•°æ®ç±»"""
    test_name: str
    initial_memory_mb: float  # åˆå§‹å†…å­˜(MB)
    final_memory_mb: float    # æœ€ç»ˆå†…å­˜(MB)
    memory_growth_mb: float   # å†…å­˜å¢é•¿(MB)
    memory_growth_rate: float # å†…å­˜å¢é•¿ç‡(%/å°æ—¶)
    garbage_collection_efficiency: float  # åƒåœ¾å›æ”¶æ•ˆç‡(%)
    object_count_growth: int  # å¯¹è±¡æ•°é‡å¢é•¿
    leak_detected: bool       # æ˜¯å¦æ£€æµ‹åˆ°æ³„æ¼
    leak_severity: str        # æ³„æ¼ä¸¥é‡ç¨‹åº¦
    stability_score: float    # ç¨³å®šæ€§è¯„åˆ†(0-100)

class MemoryLeakDetectionTester:
    """å†…å­˜æ³„æ¼æ£€æµ‹æµ‹è¯•å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.cache_system = OptimizedFusionCache()
        self.context_manager = IntelligentContextManager()
        self.model_adapter = UnifiedModelAdapter()
        self.parallel_executor = ParallelAgentExecutor()
        self.task_decomposer = TaskDecomposer()
        self.workflow_parallelizer = WorkflowStageParallelizer()
        
        # æµ‹è¯•é…ç½®
        self.monitoring_duration = 3600  # ç›‘æ§æ—¶é•¿(ç§’)ï¼Œ1å°æ—¶
        self.monitoring_interval = 30    # ç›‘æ§é—´éš”(ç§’)
        self.stress_test_duration = 600  # å‹åŠ›æµ‹è¯•æ—¶é•¿(ç§’)ï¼Œ10åˆ†é’Ÿ
        self.long_running_duration = 7200  # é•¿æ—¶é—´è¿è¡Œæµ‹è¯•(ç§’)ï¼Œ2å°æ—¶
        
        # å†…å­˜ç›‘æ§é…ç½®
        self.memory_snapshots = []
        self.object_snapshots = []
        self.process = psutil.Process(os.getpid())
        
        # åƒåœ¾å›æ”¶ç›‘æ§
        self.gc_before_counts = []
        self.gc_after_counts = []
        
        # æµ‹è¯•ç»“æœå­˜å‚¨
        self.metrics: List[MemoryLeakMetric] = []
        
        # å¼±å¼•ç”¨è·Ÿè¸ªå™¨
        self.weak_refs = weakref.WeakSet()
        
        # é…ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('memory_leak_detection_test.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # å¯åŠ¨å†…å­˜è·Ÿè¸ª
        tracemalloc.start()
        
    def get_memory_usage(self) -> float:
        """
        è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡(MB)
        
        Returns:
            float: å†…å­˜ä½¿ç”¨é‡(MB)
        """
        try:
            memory_info = self.process.memory_info()
            return memory_info.rss / 1024 / 1024  # è½¬æ¢ä¸ºMB
        except Exception as e:
            self.logger.error(f"è·å–å†…å­˜ä½¿ç”¨é‡å¤±è´¥: {e}")
            return 0.0
    
    def get_object_count(self) -> Dict[str, int]:
        """
        è·å–å½“å‰å¯¹è±¡æ•°é‡ç»Ÿè®¡
        
        Returns:
            Dict[str, int]: å¯¹è±¡ç±»å‹è®¡æ•°å­—å…¸
        """
        try:
            # è·å–ä¸»è¦å¯¹è±¡ç±»å‹çš„æ•°é‡
            object_counts = {}
            
            # ç»Ÿè®¡ç¼“å­˜ç›¸å…³å¯¹è±¡
            if hasattr(self.cache_system, '_cache'):
                object_counts['cache_entries'] = len(self.cache_system._cache) if self.cache_system._cache else 0
            
            if hasattr(self.cache_system, '_ttl_heap'):
                object_counts['ttl_entries'] = len(self.cache_system._ttl_heap) if self.cache_system._ttl_heap else 0
            
            # ç»Ÿè®¡Pythonå¯¹è±¡æ€»æ•°
            object_counts['total_objects'] = len(gc.get_objects())
            
            # ç»Ÿè®¡å„ä»£åƒåœ¾å›æ”¶å™¨ä¸­çš„å¯¹è±¡æ•°é‡
            for i, count in enumerate(gc.get_count()):
                object_counts[f'gc_generation_{i}'] = count
            
            return object_counts
        except Exception as e:
            self.logger.error(f"è·å–å¯¹è±¡æ•°é‡å¤±è´¥: {e}")
            return {}
    
    def force_garbage_collection(self) -> Tuple[List[int], List[int]]:
        """
        å¼ºåˆ¶æ‰§è¡Œåƒåœ¾å›æ”¶å¹¶è®°å½•å‰åçŠ¶æ€
        
        Returns:
            Tuple[List[int], List[int]]: åƒåœ¾å›æ”¶å‰åçš„å¯¹è±¡æ•°é‡
        """
        # è®°å½•åƒåœ¾å›æ”¶å‰çš„çŠ¶æ€
        before_counts = list(gc.get_count())
        before_objects = len(gc.get_objects())
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        
        # è®°å½•åƒåœ¾å›æ”¶åçš„çŠ¶æ€
        after_counts = list(gc.get_count())
        after_objects = len(gc.get_objects())
        
        return before_counts, after_counts
    
    def record_memory_snapshot(self, label: str = ""):
        """
        è®°å½•å†…å­˜å¿«ç…§
        
        Args:
            label: å¿«ç…§æ ‡ç­¾
        """
        timestamp = time.time()
        memory_mb = self.get_memory_usage()
        object_counts = self.get_object_count()
        
        snapshot = {
            'timestamp': timestamp,
            'label': label,
            'memory_mb': memory_mb,
            'object_counts': object_counts,
            'gc_counts': list(gc.get_count())
        }
        
        self.memory_snapshots.append(snapshot)
        
        # ä¿æŒå¿«ç…§æ•°é‡åœ¨åˆç†èŒƒå›´å†…
        if len(self.memory_snapshots) > 1000:
            self.memory_snapshots.pop(0)
    
    def simulate_cache_operations(self, duration: int, operation_type: str = "mixed"):
        """
        æ¨¡æ‹Ÿç¼“å­˜æ“ä½œä»¥äº§ç”Ÿå†…å­˜å‹åŠ›
        
        Args:
            duration: æ“ä½œæ—¶é•¿(ç§’)
            operation_type: æ“ä½œç±»å‹
        """
        self.logger.info(f"å¼€å§‹æ¨¡æ‹Ÿç¼“å­˜æ“ä½œ: {operation_type}, æ—¶é•¿: {duration}ç§’")
        
        start_time = time.time()
        operation_count = 0
        
        while time.time() - start_time < duration:
            current_time = time.time()
            
            # æ¯30ç§’è®°å½•ä¸€æ¬¡å¿«ç…§
            if operation_count % 100 == 0:
                self.record_memory_snapshot(f"operation_{operation_count}")
            
            try:
                if operation_type == "write_heavy":
                    # å†™å¯†é›†æ“ä½œ
                    key = f"test_key_{operation_count}"
                    value = {
                        'data': 'x' * 1000,  # 1KBæ•°æ®
                        'metadata': {'created_at': current_time, 'operation_count': operation_count},
                        'large_data': ['item_' + str(i) for i in range(100)]
                    }
                    self.cache_system.set(key, value, ttl=3600)
                    
                elif operation_type == "read_heavy":
                    # è¯»å¯†é›†æ“ä½œ
                    key = f"test_key_{operation_count % 1000}"  # å¾ªç¯è®¿é—®
                    result = self.cache_system.get(key)
                    if result is None:
                        # å¦‚æœä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ª
                        self.cache_system.set(key, f"fallback_data_{operation_count}", ttl=3600)
                
                elif operation_type == "mixed":
                    # æ··åˆæ“ä½œ
                    if operation_count % 3 == 0:
                        # å†™æ“ä½œ
                        key = f"write_key_{operation_count}"
                        value = {'data': f'write_data_{operation_count}', 'timestamp': current_time}
                        self.cache_system.set(key, value, ttl=3600)
                    elif operation_count % 3 == 1:
                        # è¯»æ“ä½œ
                        key = f"read_key_{operation_count % 500}"
                        result = self.cache_system.get(key)
                    else:
                        # åˆ é™¤æ“ä½œ
                        key = f"delete_key_{operation_count % 300}"
                        self.cache_system.delete(key)
                
                elif operation_type == "burst":
                    # çªå‘æ“ä½œ
                    if operation_count % 50 == 0:
                        # çªå‘å†™å…¥
                        for i in range(50):
                            key = f"burst_key_{operation_count}_{i}"
                            value = {'burst_data': i, 'timestamp': current_time}
                            self.cache_system.set(key, value, ttl=3600)
                    else:
                        # æ­£å¸¸æ“ä½œ
                        key = f"normal_key_{operation_count}"
                        self.cache_system.get(key)
                
                operation_count += 1
                
                # æ¯1000æ¬¡æ“ä½œå¼ºåˆ¶åƒåœ¾å›æ”¶
                if operation_count % 1000 == 0:
                    before_gc, after_gc = self.force_garbage_collection()
                    gc_efficiency = self.calculate_gc_efficiency(before_gc, after_gc)
                    self.logger.info(f"æ“ä½œ{operation_count}: GCæ•ˆç‡={gc_efficiency:.2f}%")
                
                # æ¯100æ¬¡æ“ä½œè®°å½•å†…å­˜çŠ¶æ€
                if operation_count % 100 == 0:
                    memory_mb = self.get_memory_usage()
                    self.logger.info(f"æ“ä½œ{operation_count}: å†…å­˜ä½¿ç”¨={memory_mb:.2f}MB")
                
            except Exception as e:
                self.logger.error(f"æ“ä½œ{operation_count}å‘ç”Ÿé”™è¯¯: {e}")
                continue
        
        self.logger.info(f"ç¼“å­˜æ“ä½œæ¨¡æ‹Ÿå®Œæˆ: æ€»æ“ä½œæ•°={operation_count}, å¹³å‡æ“ä½œé¢‘ç‡={operation_count/duration:.2f}æ¬¡/ç§’")
    
    def calculate_gc_efficiency(self, before_counts: List[int], after_counts: List[int]) -> float:
        """
        è®¡ç®—åƒåœ¾å›æ”¶æ•ˆç‡
        
        Args:
            before_counts: åƒåœ¾å›æ”¶å‰çš„å¯¹è±¡æ•°é‡
            after_counts: åƒåœ¾å›æ”¶åçš„å¯¹è±¡æ•°é‡
            
        Returns:
            float: åƒåœ¾å›æ”¶æ•ˆç‡(%)
        """
        try:
            total_before = sum(before_counts)
            total_after = sum(after_counts)
            if total_before > 0:
                return (total_before - total_after) / total_before * 100
            return 0.0
        except Exception:
            return 0.0
    
    def analyze_memory_trend(self) -> Dict[str, Any]:
        """
        åˆ†æå†…å­˜ä½¿ç”¨è¶‹åŠ¿
        
        Returns:
            Dict[str, Any]: å†…å­˜è¶‹åŠ¿åˆ†æç»“æœ
        """
        if len(self.memory_snapshots) < 10:
            return {"error": "å¿«ç…§æ•°é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œè¶‹åŠ¿åˆ†æ"}
        
        # æå–å†…å­˜æ•°æ®
        memory_values = [snapshot['memory_mb'] for snapshot in self.memory_snapshots]
        timestamps = [snapshot['timestamp'] for snapshot in self.memory_snapshots]
        
        # è®¡ç®—åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        initial_memory = memory_values[0]
        final_memory = memory_values[-1]
        memory_growth = final_memory - initial_memory
        total_duration_hours = (timestamps[-1] - timestamps[0]) / 3600
        
        # è®¡ç®—å†…å­˜å¢é•¿ç‡
        memory_growth_rate = (memory_growth / total_duration_hours) if total_duration_hours > 0 else 0
        
        # è®¡ç®—å†…å­˜æ³¢åŠ¨
        memory_std = statistics.stdev(memory_values) if len(memory_values) > 1 else 0
        memory_variance = statistics.variance(memory_values) if len(memory_values) > 1 else 0
        
        # æ£€æµ‹å†…å­˜æ³„æ¼è¶‹åŠ¿
        # ä½¿ç”¨çº¿æ€§å›å½’åˆ†æå†…å­˜å¢é•¿è¶‹åŠ¿
        n = len(memory_values)
        if n > 1:
            # è®¡ç®—çº¿æ€§å›å½’æ–œç‡
            x_mean = statistics.mean(range(n))
            y_mean = statistics.mean(memory_values)
            
            numerator = sum((i - x_mean) * (memory_values[i] - y_mean) for i in range(n))
            denominator = sum((i - x_mean) ** 2 for i in range(n))
            
            slope = numerator / denominator if denominator != 0 else 0
            trend_direction = "increasing" if slope > 0.1 else "decreasing" if slope < -0.1 else "stable"
        else:
            slope = 0
            trend_direction = "unknown"
        
        return {
            'initial_memory_mb': initial_memory,
            'final_memory_mb': final_memory,
            'memory_growth_mb': memory_growth,
            'memory_growth_rate_per_hour': memory_growth_rate,
            'memory_std_deviation': memory_std,
            'memory_variance': memory_variance,
            'trend_slope': slope,
            'trend_direction': trend_direction,
            'total_duration_hours': total_duration_hours
        }
    
    def detect_memory_leak(self, memory_trend: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ£€æµ‹å†…å­˜æ³„æ¼
        
        Args:
            memory_trend: å†…å­˜è¶‹åŠ¿åˆ†æç»“æœ
            
        Returns:
            Dict[str, Any]: æ³„æ¼æ£€æµ‹ç»“æœ
        """
        memory_growth = memory_trend.get('memory_growth_mb', 0)
        memory_growth_rate = memory_trend.get('memory_growth_rate_per_hour', 0)
        trend_slope = memory_trend.get('trend_slope', 0)
        total_duration = memory_trend.get('total_duration_hours', 0)
        
        # å†…å­˜æ³„æ¼æ£€æµ‹æ ‡å‡†
        leak_threshold_mb = 50  # 50MBå†…å­˜å¢é•¿é˜ˆå€¼
        leak_rate_threshold = 10  # 10MB/å°æ—¶å¢é•¿ç‡é˜ˆå€¼
        slope_threshold = 0.5  # è¶‹åŠ¿æ–œç‡é˜ˆå€¼
        
        # åŸºäºå¤šä¸ªæŒ‡æ ‡ç»¼åˆåˆ¤æ–­
        growth_leak = memory_growth > leak_threshold_mb
        rate_leak = memory_growth_rate > leak_rate_threshold
        slope_leak = trend_slope > slope_threshold
        
        leak_detected = growth_leak or rate_leak or slope_leak
        
        # ç¡®å®šæ³„æ¼ä¸¥é‡ç¨‹åº¦
        if not leak_detected:
            leak_severity = "none"
            stability_score = 100
        elif memory_growth > 200 or memory_growth_rate > 50 or trend_slope > 2:
            leak_severity = "critical"
            stability_score = 20
        elif memory_growth > 100 or memory_growth_rate > 25 or trend_slope > 1:
            leak_severity = "high"
            stability_score = 40
        elif memory_growth > 50 or memory_growth_rate > 10 or trend_slope > 0.5:
            leak_severity = "medium"
            stability_score = 70
        else:
            leak_severity = "low"
            stability_score = 85
        
        return {
            'leak_detected': leak_detected,
            'leak_severity': leak_severity,
            'stability_score': stability_score,
            'growth_leak': growth_leak,
            'rate_leak': rate_leak,
            'slope_leak': slope_leak,
            'evidence': {
                'memory_growth_mb': memory_growth,
                'growth_rate_threshold_mb': leak_threshold_mb,
                'memory_growth_rate': memory_growth_rate,
                'rate_threshold': leak_rate_threshold,
                'trend_slope': trend_slope,
                'slope_threshold': slope_threshold
            }
        }
    
    def test_short_term_memory_stability(self) -> MemoryLeakMetric:
        """
        æµ‹è¯•çŸ­æœŸå†…å­˜ç¨³å®šæ€§(1å°æ—¶)
        
        Returns:
            MemoryLeakMetric: çŸ­æœŸå†…å­˜ç¨³å®šæ€§æŒ‡æ ‡
        """
        self.logger.info("å¼€å§‹çŸ­æœŸå†…å­˜ç¨³å®šæ€§æµ‹è¯•...")
        
        # è®°å½•åˆå§‹çŠ¶æ€
        self.record_memory_snapshot("initial")
        initial_memory = self.get_memory_usage()
        initial_objects = self.get_object_count()
        
        # è¿è¡Œæ··åˆè´Ÿè½½æµ‹è¯•
        self.simulate_cache_operations(self.monitoring_duration // 6, "mixed")
        
        # è®°å½•æœ€ç»ˆçŠ¶æ€
        self.record_memory_snapshot("final")
        final_memory = self.get_memory_usage()
        final_objects = self.get_object_count()
        
        # åˆ†æå†…å­˜è¶‹åŠ¿
        memory_trend = self.analyze_memory_trend()
        leak_detection = self.detect_memory_leak(memory_trend)
        
        # è®¡ç®—åƒåœ¾å›æ”¶æ•ˆç‡
        gc_before_total = sum(self.gc_before_counts) if self.gc_before_counts else 0
        gc_after_total = sum(self.gc_after_counts) if self.gc_after_counts else 0
        gc_efficiency = ((gc_before_total - gc_after_total) / gc_before_total * 100) if gc_before_total > 0 else 0
        
        # è®¡ç®—å¯¹è±¡æ•°é‡å¢é•¿
        object_growth = final_objects.get('total_objects', 0) - initial_objects.get('total_objects', 0)
        
        metric = MemoryLeakMetric(
            test_name="short_term_memory_stability",
            initial_memory_mb=initial_memory,
            final_memory_mb=final_memory,
            memory_growth_mb=memory_trend.get('memory_growth_mb', 0),
            memory_growth_rate=memory_trend.get('memory_growth_rate_per_hour', 0),
            garbage_collection_efficiency=gc_efficiency,
            object_count_growth=object_growth,
            leak_detected=leak_detection['leak_detected'],
            leak_severity=leak_detection['leak_severity'],
            stability_score=leak_detection['stability_score']
        )
        
        self.metrics.append(metric)
        self.logger.info(f"çŸ­æœŸå†…å­˜ç¨³å®šæ€§æµ‹è¯•å®Œæˆ: åˆå§‹={initial_memory:.2f}MB, æœ€ç»ˆ={final_memory:.2f}MB, å¢é•¿={memory_trend.get('memory_growth_mb', 0):.2f}MB, æ³„æ¼={leak_detection['leak_detected']}")
        
        return metric
    
    def test_stress_memory_behavior(self) -> MemoryLeakMetric:
        """
        æµ‹è¯•å‹åŠ›ä¸‹çš„å†…å­˜è¡Œä¸º(10åˆ†é’Ÿé«˜å¼ºåº¦æ“ä½œ)
        
        Returns:
            MemoryLeakMetric: å‹åŠ›æµ‹è¯•å†…å­˜æŒ‡æ ‡
        """
        self.logger.info("å¼€å§‹å‹åŠ›æµ‹è¯•å†…å­˜è¡Œä¸º...")
        
        # è®°å½•åˆå§‹çŠ¶æ€
        self.record_memory_snapshot("stress_initial")
        initial_memory = self.get_memory_usage()
        
        # é«˜å¼ºåº¦å†™å…¥æ“ä½œ
        self.simulate_cache_operations(self.stress_test_duration // 2, "write_heavy")
        
        # é«˜å¼ºåº¦è¯»å–æ“ä½œ
        self.simulate_cache_operations(self.stress_test_duration // 2, "read_heavy")
        
        # è®°å½•æœ€ç»ˆçŠ¶æ€
        self.record_memory_snapshot("stress_final")
        final_memory = self.get_memory_usage()
        
        # åˆ†æå†…å­˜è¶‹åŠ¿
        memory_trend = self.analyze_memory_trend()
        leak_detection = self.detect_memory_leak(memory_trend)
        
        metric = MemoryLeakMetric(
            test_name="stress_memory_behavior",
            initial_memory_mb=initial_memory,
            final_memory_mb=final_memory,
            memory_growth_mb=memory_trend.get('memory_growth_mb', 0),
            memory_growth_rate=memory_trend.get('memory_growth_rate_per_hour', 0),
            garbage_collection_efficiency=0,  # å‹åŠ›æµ‹è¯•ä¸è®¡ç®—GCæ•ˆç‡
            object_count_growth=0,
            leak_detected=leak_detection['leak_detected'],
            leak_severity=leak_detection['leak_severity'],
            stability_score=leak_detection['stability_score']
        )
        
        self.metrics.append(metric)
        self.logger.info(f"å‹åŠ›æµ‹è¯•å®Œæˆ: å†…å­˜å¢é•¿={memory_trend.get('memory_growth_mb', 0):.2f}MB, æ³„æ¼={leak_detection['leak_detected']}, ä¸¥é‡ç¨‹åº¦={leak_detection['leak_severity']}")
        
        return metric
    
    def test_long_term_memory_stability(self) -> MemoryLeakMetric:
        """
        æµ‹è¯•é•¿æœŸå†…å­˜ç¨³å®šæ€§(2å°æ—¶)
        
        Returns:
            MemoryLeakMetric: é•¿æœŸå†…å­˜ç¨³å®šæ€§æŒ‡æ ‡
        """
        self.logger.info("å¼€å§‹é•¿æœŸå†…å­˜ç¨³å®šæ€§æµ‹è¯•...")
        
        # è®°å½•åˆå§‹çŠ¶æ€
        self.record_memory_snapshot("long_term_initial")
        initial_memory = self.get_memory_usage()
        
        # æ¨¡æ‹Ÿé•¿æ—¶é—´è¿è¡Œçš„æ··åˆè´Ÿè½½
        self.simulate_cache_operations(self.long_running_duration, "mixed")
        
        # è®°å½•æœ€ç»ˆçŠ¶æ€
        self.record_memory_snapshot("long_term_final")
        final_memory = self.get_memory_usage()
        
        # åˆ†æå†…å­˜è¶‹åŠ¿
        memory_trend = self.analyze_memory_trend()
        leak_detection = self.detect_memory_leak(memory_trend)
        
        metric = MemoryLeakMetric(
            test_name="long_term_memory_stability",
            initial_memory_mb=initial_memory,
            final_memory_mb=final_memory,
            memory_growth_mb=memory_trend.get('memory_growth_mb', 0),
            memory_growth_rate=memory_trend.get('memory_growth_rate_per_hour', 0),
            garbage_collection_efficiency=0,
            object_count_growth=0,
            leak_detected=leak_detection['leak_detected'],
            leak_severity=leak_detection['leak_severity'],
            stability_score=leak_detection['stability_score']
        )
        
        self.metrics.append(metric)
        self.logger.info(f"é•¿æœŸå†…å­˜ç¨³å®šæ€§æµ‹è¯•å®Œæˆ: åˆå§‹={initial_memory:.2f}MB, æœ€ç»ˆ={final_memory:.2f}MB, å¢é•¿={memory_trend.get('memory_growth_mb', 0):.2f}MB, æ³„æ¼={leak_detection['leak_detected']}")
        
        return metric
    
    def test_memory_recovery_after_gc(self) -> MemoryLeakMetric:
        """
        æµ‹è¯•åƒåœ¾å›æ”¶åçš„å†…å­˜æ¢å¤æƒ…å†µ
        
        Returns:
            MemoryLeakMetric: å†…å­˜æ¢å¤æŒ‡æ ‡
        """
        self.logger.info("å¼€å§‹å†…å­˜æ¢å¤æµ‹è¯•...")
        
        # è®°å½•åƒåœ¾å›æ”¶å‰çš„å†…å­˜çŠ¶æ€
        self.record_memory_snapshot("before_gc")
        memory_before_gc = self.get_memory_usage()
        
        # æ‰§è¡Œå¼ºåˆ¶åƒåœ¾å›æ”¶
        before_counts, after_counts = self.force_garbage_collection()
        
        # è®°å½•åƒåœ¾å›æ”¶åçš„å†…å­˜çŠ¶æ€
        self.record_memory_snapshot("after_gc")
        memory_after_gc = self.get_memory_usage()
        
        # è®¡ç®—å†…å­˜å›æ”¶æ•ˆæœ
        memory_recovered = memory_before_gc - memory_after_gc
        gc_efficiency = self.calculate_gc_efficiency(before_counts, after_counts)
        
        self.logger.info(f"å†…å­˜æ¢å¤æµ‹è¯•: å›æ”¶å‰={memory_before_gc:.2f}MB, å›æ”¶å={memory_after_gc:.2f}MB, å›æ”¶é‡={memory_recovered:.2f}MB, GCæ•ˆç‡={gc_efficiency:.2f}%")
        
        metric = MemoryLeakMetric(
            test_name="memory_recovery_after_gc",
            initial_memory_mb=memory_before_gc,
            final_memory_mb=memory_after_gc,
            memory_growth_mb=-memory_recovered,  # è´Ÿå€¼è¡¨ç¤ºå†…å­˜å‡å°‘
            memory_growth_rate=0,
            garbage_collection_efficiency=gc_efficiency,
            object_count_growth=0,
            leak_detected=False,  # è¿™ä¸ªæµ‹è¯•ä¸æ£€æµ‹æ³„æ¼
            leak_severity="none",
            stability_score=gc_efficiency  # ç”¨GCæ•ˆç‡ä½œä¸ºç¨³å®šæ€§è¯„åˆ†
        )
        
        self.metrics.append(metric)
        return metric
    
    def test_cache_memory_optimization(self) -> MemoryLeakMetric:
        """
        æµ‹è¯•ç¼“å­˜å†…å­˜ä¼˜åŒ–æ•ˆæœ
        
        Returns:
            MemoryLeakMetric: ç¼“å­˜ä¼˜åŒ–æŒ‡æ ‡
        """
        self.logger.info("å¼€å§‹ç¼“å­˜å†…å­˜ä¼˜åŒ–æµ‹è¯•...")
        
        # æµ‹è¯•ä¸åŒç¼“å­˜å¤§å°ä¸‹çš„å†…å­˜ä½¿ç”¨
        cache_scenarios = [100, 500, 1000, 2000]
        total_memory_used = 0
        total_items_cached = 0
        
        for scenario_size in cache_scenarios:
            # æ¸…ç©ºç¼“å­˜
            self.cache_system.clear()
            
            # è®°å½•æ¸…ç©ºåçš„å†…å­˜
            memory_before = self.get_memory_usage()
            
            # ç¼“å­˜æŒ‡å®šæ•°é‡çš„é¡¹ç›®
            for i in range(scenario_size):
                key = f"optimization_test_{scenario_size}_{i}"
                value = {
                    'data': 'x' * 500,  # 500å­—èŠ‚æ•°æ®
                    'metadata': {'created_at': time.time()},
                    'dependencies': [f'dep_{j}' for j in range(5)]
                }
                self.cache_system.set(key, value, ttl=3600)
            
            # è®°å½•ç¼“å­˜åçš„å†…å­˜
            memory_after = self.get_memory_usage()
            memory_used = memory_after - memory_before
            
            total_memory_used += memory_used
            total_items_cached += scenario_size
            
            self.logger.info(f"ç¼“å­˜{scenario_size}ä¸ªé¡¹ç›®: å†…å­˜ä½¿ç”¨={memory_used:.2f}MB, å¹³å‡æ¯é¡¹ç›®={memory_used/scenario_size:.4f}MB")
        
        # è®¡ç®—ç¼“å­˜å†…å­˜æ•ˆç‡
        avg_memory_per_item = total_memory_used / total_items_cached if total_items_cached > 0 else 0
        memory_efficiency = 100 / max(avg_memory_per_item, 0.001)  # é¿å…é™¤é›¶ï¼Œæ•ˆç‡ä¸å¹³å‡å†…å­˜ä½¿ç”¨æˆåæ¯”
        
        metric = MemoryLeakMetric(
            test_name="cache_memory_optimization",
            initial_memory_mb=0,
            final_memory_mb=0,
            memory_growth_mb=0,
            memory_growth_rate=0,
            garbage_collection_efficiency=0,
            object_count_growth=0,
            leak_detected=False,
            leak_severity="none",
            stability_score=memory_efficiency
        )
        
        self.metrics.append(metric)
        self.logger.info(f"ç¼“å­˜å†…å­˜ä¼˜åŒ–æµ‹è¯•å®Œæˆ: å¹³å‡æ¯é¡¹ç›®å†…å­˜={avg_memory_per_item:.4f}MB, å†…å­˜æ•ˆç‡={memory_efficiency:.2f}")
        
        return metric
    
    def generate_memory_leak_report(self) -> Dict[str, Any]:
        """
        ç”Ÿæˆå†…å­˜æ³„æ¼æ£€æµ‹æŠ¥å‘Š
        
        Returns:
            Dict[str, Any]: å†…å­˜æ³„æ¼æ£€æµ‹æŠ¥å‘Šæ•°æ®
        """
        self.logger.info("ç”Ÿæˆå†…å­˜æ³„æ¼æ£€æµ‹æŠ¥å‘Š...")
        
        if not self.metrics:
            self.logger.warning("æ²¡æœ‰æµ‹è¯•æ•°æ®ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
            return {}
        
        # è®¡ç®—æ€»ä½“æŒ‡æ ‡
        total_leaks = sum(1 for m in self.metrics if m.leak_detected)
        avg_stability_score = statistics.mean([m.stability_score for m in self.metrics])
        avg_memory_growth = statistics.mean([m.memory_growth_mb for m in self.metrics])
        avg_growth_rate = statistics.mean([m.memory_growth_rate for m in self.metrics if m.memory_growth_rate > 0])
        
        # åˆ†ææ³„æ¼ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ
        severity_counts = defaultdict(int)
        for metric in self.metrics:
            severity_counts[metric.leak_severity] += 1
        
        # æ‰¾å‡ºæœ€ä¸¥é‡çš„æ³„æ¼æƒ…å†µ
        leak_metrics = [m for m in self.metrics if m.leak_detected]
        worst_leak = max(leak_metrics, key=lambda x: x.memory_growth_mb) if leak_metrics else None
        
        report = {
            'memory_leak_detection_analysis': {
                'overall_assessment': {
                    'total_tests': len(self.metrics),
                    'leaks_detected': total_leaks,
                    'leak_rate_percent': (total_leaks / len(self.metrics)) * 100 if self.metrics else 0,
                    'avg_stability_score': round(avg_stability_score, 2),
                    'avg_memory_growth_mb': round(avg_memory_growth, 2),
                    'avg_growth_rate_per_hour': round(avg_growth_rate, 2)
                },
                'leak_severity_distribution': dict(severity_counts),
                'worst_leak_case': {
                    'test_name': worst_leak.test_name if worst_leak else "none",
                    'memory_growth_mb': worst_leak.memory_growth_mb if worst_leak else 0,
                    'severity': worst_leak.leak_severity if worst_leak else "none"
                } if worst_leak else {},
                'detailed_metrics': [
                    {
                        'test_name': m.test_name,
                        'initial_memory_mb': round(m.initial_memory_mb, 2),
                        'final_memory_mb': round(m.final_memory_mb, 2),
                        'memory_growth_mb': round(m.memory_growth_mb, 2),
                        'memory_growth_rate_per_hour': round(m.memory_growth_rate, 2),
                        'gc_efficiency_percent': round(m.garbage_collection_efficiency, 2),
                        'object_growth': m.object_count_growth,
                        'leak_detected': m.leak_detected,
                        'leak_severity': m.leak_severity,
                        'stability_score': round(m.stability_score, 2)
                    }
                    for m in self.metrics
                ],
                'memory_health_summary': {
                    'memory_stability': 'EXCELLENT' if avg_stability_score > 80 else 'GOOD' if avg_stability_score > 60 else 'FAIR' if avg_stability_score > 40 else 'POOR',
                    'leak_risk_level': 'LOW' if total_leaks == 0 else 'MEDIUM' if total_leaks <= len(self.metrics) // 3 else 'HIGH',
                    'gc_effectiveness': 'EXCELLENT' if any(m.garbage_collection_efficiency > 80 for m in self.metrics if m.garbage_collection_efficiency > 0) else 'GOOD' if any(m.garbage_collection_efficiency > 60 for m in self.metrics) else 'POOR',
                    'recommendations': self.generate_recommendations(avg_stability_score, total_leaks, avg_memory_growth)
                }
            }
        }
        
        return report
    
    def generate_recommendations(self, avg_stability: float, leak_count: int, avg_growth: float) -> List[str]:
        """
        åŸºäºæµ‹è¯•ç»“æœç”Ÿæˆä¼˜åŒ–å»ºè®®
        
        Args:
            avg_stability: å¹³å‡ç¨³å®šæ€§è¯„åˆ†
            leak_count: æ³„æ¼æ£€æµ‹æ•°é‡
            avg_growth: å¹³å‡å†…å­˜å¢é•¿
            
        Returns:
            List[str]: ä¼˜åŒ–å»ºè®®åˆ—è¡¨
        """
        recommendations = []
        
        if avg_stability < 40:
            recommendations.append("ğŸš¨ å†…å­˜ç¨³å®šæ€§æå·®ï¼Œå»ºè®®ç«‹å³æ£€æŸ¥å†…å­˜æ³„æ¼é—®é¢˜")
        elif avg_stability < 60:
            recommendations.append("âš ï¸ å†…å­˜ç¨³å®šæ€§è¾ƒå·®ï¼Œéœ€è¦ä¼˜åŒ–å†…å­˜ç®¡ç†ç­–ç•¥")
        elif avg_stability < 80:
            recommendations.append("ğŸ“ˆ å†…å­˜ç¨³å®šæ€§è‰¯å¥½ï¼Œå¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–")
        else:
            recommendations.append("âœ… å†…å­˜ç¨³å®šæ€§ä¼˜ç§€ï¼Œå½“å‰å†…å­˜ç®¡ç†ç­–ç•¥æœ‰æ•ˆ")
        
        if leak_count > 0:
            recommendations.append("ğŸ” æ£€æµ‹åˆ°å†…å­˜æ³„æ¼ï¼Œå»ºè®®æ£€æŸ¥ç¼“å­˜å¯¹è±¡ç”Ÿå‘½å‘¨æœŸç®¡ç†")
            recommendations.append("ğŸ§¹ ä¼˜åŒ–åƒåœ¾å›æ”¶ç­–ç•¥ï¼Œå¢åŠ å®šæœŸå¼ºåˆ¶GC")
            recommendations.append("ğŸ“Š å®ç°å†…å­˜ä½¿ç”¨ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶")
        
        if avg_growth > 50:
            recommendations.append("ğŸ’¾ å†…å­˜å¢é•¿è¾ƒå¿«ï¼Œå»ºè®®ä¼˜åŒ–ç¼“å­˜å¤§å°å’Œæ·˜æ±°ç­–ç•¥")
            recommendations.append("ğŸ”„ å®ç°æ™ºèƒ½å†…å­˜ç®¡ç†ï¼Œå®šæœŸæ¸…ç†æ— ç”¨ç¼“å­˜")
        
        recommendations.extend([
            "ğŸ”§ è€ƒè™‘ä½¿ç”¨å†…å­˜æ± æŠ€æœ¯å‡å°‘å†…å­˜ç¢ç‰‡",
            "ğŸ“Š å»ºç«‹æŒç»­çš„å†…å­˜ç›‘æ§ä½“ç³»",
            "âš¡ ä¼˜åŒ–å¯¹è±¡åˆ›å»ºå’Œé”€æ¯ç­–ç•¥",
            "ğŸ›¡ï¸ å®ç°å†…å­˜ä½¿ç”¨ä¸Šé™å’Œè‡ªåŠ¨æ¸…ç†æœºåˆ¶"
        ])
        
        return recommendations
    
    def save_memory_leak_report(self, report: Dict[str, Any]):
        """
        ä¿å­˜å†…å­˜æ³„æ¼æ£€æµ‹æŠ¥å‘Šåˆ°æ–‡ä»¶
        
        Args:
            report: å†…å­˜æ³„æ¼æ£€æµ‹æŠ¥å‘Šæ•°æ®
        """
        # ä¿å­˜JSONæ ¼å¼æŠ¥å‘Š
        with open('memory_leak_detection_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # ç”ŸæˆHTMLæ ¼å¼æŠ¥å‘Š
        html_report = self.generate_html_report(report)
        with open('memory_leak_detection_report.html', 'w', encoding='utf-8') as f:
            f.write(html_report)
        
        self.logger.info("å†…å­˜æ³„æ¼æ£€æµ‹æŠ¥å‘Šå·²ä¿å­˜")
    
    def generate_html_report(self, report: Dict[str, Any]) -> str:
        """
        ç”ŸæˆHTMLæ ¼å¼çš„å†…å­˜æ³„æ¼æ£€æµ‹æŠ¥å‘Š
        
        Args:
            report: å†…å­˜æ³„æ¼æ£€æµ‹æŠ¥å‘Šæ•°æ®
            
        Returns:
            str: HTMLæ ¼å¼æŠ¥å‘Š
        """
        html_template = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Aé¡¹ç›®V7 - å†…å­˜æ³„æ¼æ£€æµ‹æŠ¥å‘Š</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        .container {{
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 0 20px rgba(0,0,0,0.1);
        }}
        h1 {{
            color: #2c3e50;
            text-align: center;
            margin-bottom: 30px;
            font-size: 2.5em;
        }}
        h2 {{
            color: #34495e;
            border-bottom: 3px solid #e74c3c;
            padding-bottom: 10px;
            margin-top: 30px;
        }}
        .summary-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }}
        .metric-card {{
            background: linear-gradient(135deg, #e74c3c 0%, #c0392b 100%);
            color: white;
            padding: 20px;
            border-radius: 10px;
            text-align: center;
        }}
        .metric-value {{
            font-size: 2em;
            font-weight: bold;
            margin-bottom: 5px;
        }}
        .metric-label {{
            font-size: 0.9em;
            opacity: 0.9;
        }}
        .healthy {{
            background: linear-gradient(135deg, #27ae60 0%, #2ecc71 100%);
        }}
        .warning {{
            background: linear-gradient(135deg, #f39c12 0%, #e67e22 100%);
        }}
        .critical {{
            background: linear-gradient(135deg, #e74c3c 0%, #c0392b 100%);
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }}
        th, td {{
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }}
        th {{
            background-color: #3498db;
            color: white;
            font-weight: bold;
        }}
        tr:nth-child(even) {{
            background-color: #f2f2f2;
        }}
        .leak-detected {{
            color: #e74c3c;
            font-weight: bold;
        }}
        .no-leak {{
            color: #27ae60;
            font-weight: bold;
        }}
        .recommendation {{
            background: #e8f5e8;
            border-left: 4px solid #27ae60;
            padding: 15px;
            margin: 10px 0;
            border-radius: 5px;
        }}
        .warning-recommendation {{
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 15px;
            margin: 10px 0;
            border-radius: 5px;
        }}
        .critical-recommendation {{
            background: #f8d7da;
            border-left: 4px solid #dc3545;
            padding: 15px;
            margin: 10px 0;
            border-radius: 5px;
        }}
        .footer {{
            text-align: center;
            margin-top: 30px;
            padding-top: 20px;
            border-top: 1px solid #ddd;
            color: #7f8c8d;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ§¹ Aé¡¹ç›®V7 - å†…å­˜æ³„æ¼æ£€æµ‹æŠ¥å‘Š</h1>
        
        <h2>ğŸ“Š æ€»ä½“è¯„ä¼°</h2>
        <div class="summary-grid">
            <div class="metric-card {'healthy' if report['memory_leak_detection_analysis']['overall_assessment']['leak_rate_percent'] == 0 else 'warning' if report['memory_leak_detection_analysis']['overall_assessment']['leak_rate_percent'] < 30 else 'critical'}">
                <div class="metric-value">{report['memory_leak_detection_analysis']['overall_assessment']['leak_rate_percent']:.1f}%</div>
                <div class="metric-label">å†…å­˜æ³„æ¼ç‡</div>
            </div>
            <div class="metric-card {'healthy' if report['memory_leak_detection_analysis']['overall_assessment']['avg_stability_score'] > 80 else 'warning' if report['memory_leak_detection_analysis']['overall_assessment']['avg_stability_score'] > 60 else 'critical'}">
                <div class="metric-value">{report['memory_leak_detection_analysis']['overall_assessment']['avg_stability_score']:.1f}</div>
                <div class="metric-label">ç¨³å®šæ€§è¯„åˆ†</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{report['memory_leak_detection_analysis']['overall_assessment']['avg_memory_growth_mb']:.2f}MB</div>
                <div class="metric-label">å¹³å‡å†…å­˜å¢é•¿</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{report['memory_leak_detection_analysis']['overall_assessment']['avg_growth_rate_per_hour']:.2f}MB/h</div>
                <div class="metric-label">å¹³å‡å¢é•¿ç‡</div>
            </div>
        </div>
        
        <h2>ğŸ¯ æ³„æ¼æ£€æµ‹ç»“æœ</h2>
        <div class="summary-grid">
            <div style="background: #e8f5e8; padding: 20px; border-radius: 10px; text-align: center;">
                <h3>å†…å­˜ç¨³å®šæ€§</h3>
                <p class="{'no-leak' if report['memory_leak_detection_analysis']['memory_health_summary']['memory_stability'] == 'EXCELLENT' else 'warning-recommendation'}">
                    {report['memory_leak_detection_analysis']['memory_health_summary']['memory_stability']}
                </p>
            </div>
            <div style="background: #fff3cd; padding: 20px; border-radius: 10px; text-align: center;">
                <h3>æ³„æ¼é£é™©ç­‰çº§</h3>
                <p class="{'no-leak' if report['memory_leak_detection_analysis']['memory_health_summary']['leak_risk_level'] == 'LOW' else 'leak-detected'}">
                    {report['memory_leak_detection_analysis']['memory_health_summary']['leak_risk_level']}
                </p>
            </div>
        </div>
        
        <h2>ğŸ“‹ è¯¦ç»†æµ‹è¯•ç»“æœ</h2>
        <table>
            <thead>
                <tr>
                    <th>æµ‹è¯•åœºæ™¯</th>
                    <th>åˆå§‹å†…å­˜(MB)</th>
                    <th>æœ€ç»ˆå†…å­˜(MB)</th>
                    <th>å†…å­˜å¢é•¿(MB)</th>
                    <th>å¢é•¿ç‡(MB/h)</th>
                    <th>GCæ•ˆç‡(%)</th>
                    <th>æ³„æ¼æ£€æµ‹</th>
                    <th>ä¸¥é‡ç¨‹åº¦</th>
                    <th>ç¨³å®šæ€§è¯„åˆ†</th>
                </tr>
            </thead>
            <tbody>
                {''.join([f'''
                <tr>
                    <td>{metric['test_name']}</td>
                    <td>{metric['initial_memory_mb']}</td>
                    <td>{metric['final_memory_mb']}</td>
                    <td>{metric['memory_growth_mb']}</td>
                    <td>{metric['memory_growth_rate_per_hour']}</td>
                    <td>{metric['gc_efficiency_percent']}%</td>
                    <td class="{'no-leak' if not metric['leak_detected'] else 'leak-detected'}">
                        {'âœ… æ— æ³„æ¼' if not metric['leak_detected'] else 'ğŸš¨ æ£€æµ‹åˆ°æ³„æ¼'}
                    </td>
                    <td>{metric['leak_severity']}</td>
                    <td>{metric['stability_score']}</td>
                </tr>
                ''' for metric in report['memory_leak_detection_analysis']['detailed_metrics']])}
            </tbody>
        </table>
        
        <h2>ğŸ’¡ ä¼˜åŒ–å»ºè®®</h2>
        {''.join([f'<div class="{"critical-recommendation" if "ğŸš¨" in recommendation else "warning-recommendation" if "âš ï¸" in recommendation else "recommendation"}">{recommendation}</div>' for recommendation in report['memory_leak_detection_analysis']['memory_health_summary']['recommendations']])}
        
        <div class="footer">
            <p>ğŸ“Š æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p>ğŸ§¹ Aé¡¹ç›®V7 - å†…å­˜æ³„æ¼æ£€æµ‹æµ‹è¯•å¥—ä»¶</p>
        </div>
    </div>
</body>
</html>
        """
        
        return html_template
    
    def run_comprehensive_memory_leak_test(self):
        """
        è¿è¡Œå…¨é¢çš„å†…å­˜æ³„æ¼æ£€æµ‹æµ‹è¯•
        """
        self.logger.info("ğŸ§¹ å¼€å§‹è¿è¡Œå…¨é¢çš„å†…å­˜æ³„æ¼æ£€æµ‹æµ‹è¯•...")
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        self.test_short_term_memory_stability()
        self.test_stress_memory_behavior()
        self.test_long_term_memory_stability()
        self.test_memory_recovery_after_gc()
        self.test_cache_memory_optimization()
        
        # ç”Ÿæˆæ£€æµ‹æŠ¥å‘Š
        report = self.generate_memory_leak_report()
        
        # ä¿å­˜æŠ¥å‘Š
        self.save_memory_leak_report(report)
        
        # æ‰“å°æµ‹è¯•æ€»ç»“
        self.logger.info("=" * 80)
        self.logger.info("ğŸ§¹ å†…å­˜æ³„æ¼æ£€æµ‹å®Œæˆï¼")
        self.logger.info(f"ğŸ“Š æ€»ä½“è¯„ä¼°ç»“æœ:")
        self.logger.info(f"   ğŸš¨ æ³„æ¼æ£€æµ‹ç‡: {report['memory_leak_detection_analysis']['overall_assessment']['leak_rate_percent']:.1f}%")
        self.logger.info(f"   ğŸ“ˆ å¹³å‡ç¨³å®šæ€§è¯„åˆ†: {report['memory_leak_detection_analysis']['overall_assessment']['avg_stability_score']:.1f}/100")
        self.logger.info(f"   ğŸ“Š å¹³å‡å†…å­˜å¢é•¿: {report['memory_leak_detection_analysis']['overall_assessment']['avg_memory_growth_mb']:.2f}MB")
        self.logger.info(f"   âš¡ å¹³å‡å¢é•¿ç‡: {report['memory_leak_detection_analysis']['overall_assessment']['avg_growth_rate_per_hour']:.2f}MB/h")
        self.logger.info(f"   ğŸ§ª æµ‹è¯•æ€»æ•°: {report['memory_leak_detection_analysis']['overall_assessment']['total_tests']}")
        self.logger.info("=" * 80)
        
        return report

if __name__ == "__main__":
    # è¿è¡Œå†…å­˜æ³„æ¼æ£€æµ‹æµ‹è¯•
    tester = MemoryLeakDetectionTester()
    report = tester.run_comprehensive_memory_leak_test()
    
    # æ‰“å°å…³é”®å‘ç°
    print("\nğŸ§¹ å…³é”®å†…å­˜æ³„æ¼å‘ç°:")
    print(f"ğŸš¨ æ³„æ¼æ£€æµ‹ç‡: {report['memory_leak_detection_analysis']['overall_assessment']['leak_rate_percent']:.1f}%")
    print(f"ğŸ“ˆ ç¨³å®šæ€§è¯„åˆ†: {report['memory_leak_detection_analysis']['overall_assessment']['avg_stability_score']:.1f}/100")
    print(f"ğŸ“Š å¹³å‡å†…å­˜å¢é•¿: {report['memory_leak_detection_analysis']['overall_assessment']['avg_memory_growth_mb']:.2f}MB")
    print(f"âœ… åœ¨ {report['memory_leak_detection_analysis']['overall_assessment']['total_tests']} ä¸ªæµ‹è¯•åœºæ™¯ä¸­éªŒè¯äº†å†…å­˜ç¨³å®šæ€§")