#!/usr/bin/env python3
"""
åŠŸèƒ½ç‰¹ç‚¹åˆ†ææ¨¡å—
æ·±å…¥åˆ†ææ¯ä¸ªæ–‡ä»¶çš„åŠŸèƒ½ç‰¹ç‚¹ã€ä¼˜ç¼ºç‚¹ã€ä»·å€¼è¯„ä¼°å’Œæ›¿ä»£æ–¹æ¡ˆ
"""

import os
import re
import ast
import json
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, asdict
from datetime import datetime
import asyncio
from enum import Enum

class FeatureCategory(Enum):
    """åŠŸèƒ½ç±»åˆ«"""
    CORE_ENGINE = "core_engine"
    WORKFLOW_SYSTEM = "workflow_system"
    KNOWLEDGE_BASE = "knowledge_base"
    UTILITY_MODULE = "utility_module"
    TEST_MODULE = "test_module"
    CONFIG_MODULE = "config_module"
    API_MODULE = "api_module"
    SECURITY_MODULE = "security_module"
    PERFORMANCE_MODULE = "performance_module"
    UI_MODULE = "ui_module"

class ValueLevel(Enum):
    """ä»·å€¼ç­‰çº§"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    NEGLIGIBLE = "negligible"

@dataclass
class FeatureCharacteristic:
    """åŠŸèƒ½ç‰¹å¾"""
    name: str
    description: str
    category: FeatureCategory
    value_level: ValueLevel
    uniqueness: float  # ç‹¬ç‰¹æ€§ 0-1
    complexity: float  # å¤æ‚åº¦ 0-1
    maturity: float    # æˆç†Ÿåº¦ 0-1
    usage_frequency: str  # ä½¿ç”¨é¢‘ç‡
    user_impact: str     # ç”¨æˆ·å½±å“
    business_value: str  # ä¸šåŠ¡ä»·å€¼
    technical_debt: float  # æŠ€æœ¯å€ºåŠ¡ 0-1

@dataclass
class Advantage:
    """ä¼˜åŠ¿"""
    category: str
    description: str
    impact_level: str
    evidence: List[str]
    quantification: Optional[str]

@dataclass
class Disadvantage:
    """åŠ£åŠ¿"""
    category: str
    description: str
    impact_level: str
    evidence: List[str]
    mitigation: Optional[str]

@dataclass
class Alternative:
    """æ›¿ä»£æ–¹æ¡ˆ"""
    name: str
    description: str
    feasibility: float  # å¯è¡Œæ€§ 0-1
    cost_estimate: str
    pros: List[str]
    cons: List[str]
    implementation_effort: str

@dataclass
class FunctionalityAnalysis:
    """åŠŸèƒ½åˆ†æç»“æœ"""
    file_path: str
    feature_characteristics: List[FeatureCharacteristic]
    advantages: List[Advantage]
    disadvantages: List[Disadvantage]
    alternatives: List[Alternative]
    retention_justification: str
    removal_justification: Optional[str]
    replacement_options: List[str]
    integration_points: List[str]
    dependencies: List[str]
    dependents: List[str]
    overall_assessment: str
    recommendation: str

class FeatureAnalysisModule:
    """åŠŸèƒ½ç‰¹ç‚¹åˆ†ææ¨¡å—"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.analysis_cache = {}
        self.feature_patterns = self._load_feature_patterns()
        self.value_assessment_criteria = self._load_value_criteria()
        
    async def analyze_comprehensive_features(self, file_path: str) -> FunctionalityAnalysis:
        """ç»¼åˆåŠŸèƒ½åˆ†æ"""
        print(f"ğŸ” å¼€å§‹ç»¼åˆåŠŸèƒ½åˆ†æ: {file_path}")
        
        # 1. åŸºç¡€æ–‡ä»¶åˆ†æ
        print("ğŸ“ åˆ†æåŸºç¡€æ–‡ä»¶ä¿¡æ¯...")
        basic_info = await self._analyze_basic_file_info(file_path)
        
        # 2. åŠŸèƒ½ç‰¹å¾è¯†åˆ«
        print("ğŸ¯ è¯†åˆ«åŠŸèƒ½ç‰¹å¾...")
        feature_characteristics = await self._identify_feature_characteristics(file_path, basic_info)
        
        # 3. ä¼˜åŠ¿åˆ†æ
        print("ğŸ’ª åˆ†æä¼˜åŠ¿...")
        advantages = await self._analyze_advantages(file_path, feature_characteristics)
        
        # 4. åŠ£åŠ¿åˆ†æ
        print("âš ï¸ åˆ†æåŠ£åŠ¿...")
        disadvantages = await self._analyze_disadvantages(file_path, feature_characteristics)
        
        # 5. æ›¿ä»£æ–¹æ¡ˆåˆ†æ
        print("ğŸ”„ åˆ†ææ›¿ä»£æ–¹æ¡ˆ...")
        alternatives = await self._analyze_alternatives(file_path, feature_characteristics)
        
        # 6. ä¾èµ–å…³ç³»åˆ†æ
        print("ğŸ”— åˆ†æä¾èµ–å…³ç³»...")
        dependencies, dependents = await self._analyze_dependencies(file_path)
        
        # 7. é›†æˆç‚¹åˆ†æ
        print("ğŸ”Œ åˆ†æé›†æˆç‚¹...")
        integration_points = await self._analyze_integration_points(file_path)
        
        # 8. ä¿ç•™/åˆ é™¤ç†ç”±ç”Ÿæˆ
        print("âš–ï¸ ç”Ÿæˆå†³ç­–ç†ç”±...")
        retention_justification = await self._generate_retention_justification(
            file_path, feature_characteristics, advantages, disadvantages
        )
        removal_justification = await self._generate_removal_justification(
            file_path, feature_characteristics, disadvantages
        )
        
        # 9. æ›¿æ¢é€‰é¡¹åˆ†æ
        print("ğŸ”„ åˆ†ææ›¿æ¢é€‰é¡¹...")
        replacement_options = await self._analyze_replacement_options(file_path, alternatives)
        
        # 10. æ•´ä½“è¯„ä¼°
        print("ğŸ“Š è¿›è¡Œæ•´ä½“è¯„ä¼°...")
        overall_assessment = await self._perform_overall_assessment(
            feature_characteristics, advantages, disadvantages
        )
        
        # 11. æ¨èå»ºè®®
        print("ğŸ’¡ ç”Ÿæˆæ¨èå»ºè®®...")
        recommendation = await self._generate_recommendation(
            file_path, overall_assessment, alternatives
        )
        
        # 12. æ„å»ºåˆ†æç»“æœ
        analysis_result = FunctionalityAnalysis(
            file_path=file_path,
            feature_characteristics=feature_characteristics,
            advantages=advantages,
            disadvantages=disadvantages,
            alternatives=alternatives,
            retention_justification=retention_justification,
            removal_justification=removal_justification,
            replacement_options=replacement_options,
            integration_points=integration_points,
            dependencies=dependencies,
            dependents=dependents,
            overall_assessment=overall_assessment,
            recommendation=recommendation
        )
        
        print(f"âœ… åŠŸèƒ½åˆ†æå®Œæˆ: {file_path}")
        return analysis_result
    
    async def _analyze_basic_file_info(self, file_path: str) -> Dict[str, Any]:
        """åˆ†æåŸºç¡€æ–‡ä»¶ä¿¡æ¯"""
        full_path = self.project_root / file_path
        
        if not full_path.exists():
            return {"error": "æ–‡ä»¶ä¸å­˜åœ¨"}
        
        try:
            with open(full_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # åŸºæœ¬ç»Ÿè®¡
            lines = content.split('\n')
            code_lines = len([line for line in lines if line.strip() and not line.strip().startswith('#')])
            
            # ASTåˆ†æ
            try:
                tree = ast.parse(content)
                functions = [node.name for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
                classes = [node.name for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]
                imports = []
                for node in ast.walk(tree):
                    if isinstance(node, ast.Import):
                        imports.extend([alias.name for alias in node.names])
                    elif isinstance(node, ast.ImportFrom):
                        module = node.module or ""
                        imports.extend([f"{module}.{alias.name}" for alias in node.names])
            except:
                functions = []
                classes = []
                imports = []
            
            return {
                "file_size": full_path.stat().st_size,
                "total_lines": len(lines),
                "code_lines": code_lines,
                "functions": functions,
                "classes": classes,
                "imports": imports,
                "file_name": full_path.name,
                "file_extension": full_path.suffix,
                "last_modified": full_path.stat().st_mtime
            }
            
        except Exception as e:
            return {"error": f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}"}
    
    async def _identify_feature_characteristics(self, file_path: str, basic_info: Dict[str, Any]) -> List[FeatureCharacteristic]:
        """è¯†åˆ«åŠŸèƒ½ç‰¹å¾"""
        characteristics = []
        
        if "error" in basic_info:
            return characteristics
        
        file_name = basic_info["file_name"].lower()
        content = await self._read_file_content(file_path)
        
        # åŸºäºæ–‡ä»¶åå’Œå†…å®¹è¯†åˆ«ç‰¹å¾
        for pattern_name, pattern_config in self.feature_patterns.items():
            if await self._matches_pattern(file_name, content, pattern_config):
                characteristic = await self._create_characteristic_from_pattern(
                    pattern_name, pattern_config, basic_info
                )
                characteristics.append(characteristic)
        
        # åŸºäºä»£ç ç»“æ„è¯†åˆ«ç‰¹å¾
        structure_characteristics = await self._analyze_structure_characteristics(basic_info, content)
        characteristics.extend(structure_characteristics)
        
        return characteristics
    
    async def _matches_pattern(self, file_name: str, content: str, pattern_config: Dict[str, Any]) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ¹é…æ¨¡å¼"""
        # æ£€æŸ¥æ–‡ä»¶åæ¨¡å¼
        if "filename_patterns" in pattern_config:
            for pattern in pattern_config["filename_patterns"]:
                if re.search(pattern, file_name):
                    return True
        
        # æ£€æŸ¥å†…å®¹æ¨¡å¼
        if "content_patterns" in pattern_config:
            for pattern in pattern_config["content_patterns"]:
                if re.search(pattern, content, re.IGNORECASE):
                    return True
        
        # æ£€æŸ¥å…³é”®è¯
        if "keywords" in pattern_config:
            for keyword in pattern_config["keywords"]:
                if keyword.lower() in content.lower():
                    return True
        
        return False
    
    async def _create_characteristic_from_pattern(self, pattern_name: str, 
                                                pattern_config: Dict[str, Any], 
                                                basic_info: Dict[str, Any]) -> FeatureCharacteristic:
        """ä»æ¨¡å¼åˆ›å»ºç‰¹å¾"""
        category = FeatureCategory(pattern_config.get("category", "utility_module"))
        value_level = ValueLevel(pattern_config.get("value_level", "medium"))
        
        # è®¡ç®—ç‹¬ç‰¹æ€§
        uniqueness = await self._calculate_uniqueness(pattern_name, basic_info)
        
        # è®¡ç®—å¤æ‚åº¦
        complexity = await self._calculate_complexity(basic_info)
        
        # è¯„ä¼°æˆç†Ÿåº¦
        maturity = await self._assess_maturity(pattern_name, basic_info)
        
        return FeatureCharacteristic(
            name=pattern_config["name"],
            description=pattern_config["description"],
            category=category,
            value_level=value_level,
            uniqueness=uniqueness,
            complexity=complexity,
            maturity=maturity,
            usage_frequency=pattern_config.get("usage_frequency", "unknown"),
            user_impact=pattern_config.get("user_impact", "medium"),
            business_value=pattern_config.get("business_value", "medium"),
            technical_debt=pattern_config.get("technical_debt", 0.3)
        )
    
    async def _analyze_structure_characteristics(self, basic_info: Dict[str, Any], content: str) -> List[FeatureCharacteristic]:
        """åˆ†æç»“æ„ç‰¹å¾"""
        characteristics = []
        
        # åŸºäºå‡½æ•°æ•°é‡
        function_count = len(basic_info.get("functions", []))
        if function_count > 10:
            characteristics.append(FeatureCharacteristic(
                name="å¤šåŠŸèƒ½æ¨¡å—",
                description=f"åŒ…å«{function_count}ä¸ªå‡½æ•°çš„å¤æ‚æ¨¡å—",
                category=FeatureCategory.UTILITY_MODULE,
                value_level=ValueLevel.MEDIUM,
                uniqueness=0.6,
                complexity=0.8,
                maturity=0.7,
                usage_frequency="medium",
                user_impact="medium",
                business_value="medium",
                technical_debt=0.4
            ))
        
        # åŸºäºç±»æ•°é‡
        class_count = len(basic_info.get("classes", []))
        if class_count > 0:
            characteristics.append(FeatureCharacteristic(
                name="é¢å‘å¯¹è±¡è®¾è®¡",
                description=f"åŒ…å«{class_count}ä¸ªç±»çš„é¢å‘å¯¹è±¡æ¨¡å—",
                category=FeatureCategory.CORE_ENGINE,
                value_level=ValueLevel.HIGH,
                uniqueness=0.7,
                complexity=0.6,
                maturity=0.8,
                usage_frequency="high",
                user_impact="high",
                business_value="high",
                technical_debt=0.2
            ))
        
        # åŸºäºå¼‚æ­¥ç‰¹æ€§
        if "async def" in content:
            characteristics.append(FeatureCharacteristic(
                name="å¼‚æ­¥å¤„ç†èƒ½åŠ›",
                description="æ”¯æŒå¼‚æ­¥ç¼–ç¨‹çš„æ¨¡å—",
                category=FeatureCategory.PERFORMANCE_MODULE,
                value_level=ValueLevel.HIGH,
                uniqueness=0.8,
                complexity=0.7,
                maturity=0.8,
                usage_frequency="high",
                user_impact="high",
                business_value="high",
                technical_debt=0.3
            ))
        
        return characteristics
    
    async def _calculate_uniqueness(self, pattern_name: str, basic_info: Dict[str, Any]) -> float:
        """è®¡ç®—ç‹¬ç‰¹æ€§"""
        # ç®€åŒ–çš„ç‹¬ç‰¹æ€§è®¡ç®—
        file_name = basic_info["file_name"].lower()
        
        # åŸºäºæ–‡ä»¶åçš„ç‹¬ç‰¹æ€§
        unique_indicators = ["engine", "kernel", "core", "quantum", "evolution"]
        uniqueness_score = 0.5  # åŸºç¡€åˆ†æ•°
        
        for indicator in unique_indicators:
            if indicator in file_name:
                uniqueness_score += 0.1
        
        # åŸºäºå‡½æ•°åçš„ç‹¬ç‰¹æ€§
        functions = basic_info.get("functions", [])
        unique_functions = [f for f in functions if any(keyword in f.lower() for keyword in ["quantum", "evolution", "intelligent", "smart"])]
        if unique_functions:
            uniqueness_score += 0.2
        
        return min(1.0, uniqueness_score)
    
    async def _calculate_complexity(self, basic_info: Dict[str, Any]) -> float:
        """è®¡ç®—å¤æ‚åº¦"""
        code_lines = basic_info.get("code_lines", 0)
        function_count = len(basic_info.get("functions", []))
        class_count = len(basic_info.get("classes", []))
        import_count = len(basic_info.get("imports", []))
        
        # ç®€åŒ–çš„å¤æ‚åº¦è®¡ç®—
        complexity_score = 0.0
        
        # åŸºäºä»£ç è¡Œæ•°
        if code_lines > 500:
            complexity_score += 0.3
        elif code_lines > 200:
            complexity_score += 0.2
        elif code_lines > 100:
            complexity_score += 0.1
        
        # åŸºäºå‡½æ•°æ•°é‡
        if function_count > 20:
            complexity_score += 0.3
        elif function_count > 10:
            complexity_score += 0.2
        elif function_count > 5:
            complexity_score += 0.1
        
        # åŸºäºç±»æ•°é‡
        if class_count > 5:
            complexity_score += 0.2
        elif class_count > 2:
            complexity_score += 0.1
        
        # åŸºäºå¯¼å…¥æ•°é‡
        if import_count > 10:
            complexity_score += 0.2
        elif import_count > 5:
            complexity_score += 0.1
        
        return min(1.0, complexity_score)
    
    async def _assess_maturity(self, pattern_name: str, basic_info: Dict[str, Any]) -> float:
        """è¯„ä¼°æˆç†Ÿåº¦"""
        # ç®€åŒ–çš„æˆç†Ÿåº¦è¯„ä¼°
        maturity_score = 0.5  # åŸºç¡€åˆ†æ•°
        
        file_name = basic_info["file_name"].lower()
        
        # åŸºäºç‰ˆæœ¬å·
        if re.search(r'v\d+_\d+', file_name):
            maturity_score += 0.2
        
        # åŸºäºæ–‡æ¡£æ³¨é‡Š
        try:
            content = await self._read_file_content(basic_info["file_path"])
            docstring_count = content.count('"""') + content.count("'''")
            if docstring_count > 0:
                maturity_score += 0.1
        except:
            pass
        
        # åŸºäºé”™è¯¯å¤„ç†
        try:
            content = await self._read_file_content(basic_info["file_path"])
            if "try:" in content and "except" in content:
                maturity_score += 0.2
        except:
            pass
        
        return min(1.0, maturity_score)
    
    async def _analyze_advantages(self, file_path: str, 
                                feature_characteristics: List[FeatureCharacteristic]) -> List[Advantage]:
        """åˆ†æä¼˜åŠ¿"""
        advantages = []
        
        # åŸºäºç‰¹å¾åˆ†æä¼˜åŠ¿
        for characteristic in feature_characteristics:
            category_advantages = await self._generate_advantages_from_characteristic(characteristic)
            advantages.extend(category_advantages)
        
        # åŸºäºä»£ç è´¨é‡åˆ†æä¼˜åŠ¿
        quality_advantages = await self._analyze_quality_advantages(file_path)
        advantages.extend(quality_advantages)
        
        # åŸºäºæ¶æ„åˆ†æä¼˜åŠ¿
        architecture_advantages = await self._analyze_architecture_advantages(file_path)
        advantages.extend(architecture_advantages)
        
        return advantages
    
    async def _generate_advantages_from_characteristic(self, characteristic: FeatureCharacteristic) -> List[Advantage]:
        """ä»ç‰¹å¾ç”Ÿæˆä¼˜åŠ¿"""
        advantages = []
        
        if characteristic.category == FeatureCategory.CORE_ENGINE:
            advantages.append(Advantage(
                category="æ ¸å¿ƒåŠŸèƒ½",
                description=f"æä¾›{characteristic.name}çš„æ ¸å¿ƒåŠŸèƒ½",
                impact_level="high",
                evidence=[f"ç‰¹å¾ç±»åˆ«: {characteristic.category.value}"],
                quantification=f"ä»·å€¼ç­‰çº§: {characteristic.value_level.value}"
            ))
        
        if characteristic.uniqueness > 0.7:
            advantages.append(Advantage(
                category="ç‹¬ç‰¹æ€§",
                description=f"å…·æœ‰{characteristic.uniqueness:.1%}çš„ç‹¬ç‰¹æ€§",
                impact_level="high",
                evidence=["ç‹¬ç‰¹æ€§è¯„åˆ†é«˜"],
                quantification=f"ç‹¬ç‰¹æ€§: {characteristic.uniqueness:.1%}"
            ))
        
        if characteristic.maturity > 0.7:
            advantages.append(Advantage(
                category="æˆç†Ÿåº¦",
                description=f"ä»£ç æˆç†Ÿåº¦é«˜({characteristic.maturity:.1%})",
                impact_level="medium",
                evidence=["æˆç†Ÿåº¦è¯„åˆ†é«˜"],
                quantification=f"æˆç†Ÿåº¦: {characteristic.maturity:.1%}"
            ))
        
        return advantages
    
    async def _analyze_quality_advantages(self, file_path: str) -> List[Advantage]:
        """åˆ†æè´¨é‡ä¼˜åŠ¿"""
        advantages = []
        
        try:
            content = await self._read_file_content(file_path)
            
            # æ£€æŸ¥æ–‡æ¡£å®Œæ•´æ€§
            docstring_count = content.count('"""') + content.count("'''")
            if docstring_count > 0:
                advantages.append(Advantage(
                    category="æ–‡æ¡£å®Œæ•´æ€§",
                    description=f"åŒ…å«{docstring_count}ä¸ªæ–‡æ¡£å­—ç¬¦ä¸²",
                    impact_level="medium",
                    evidence=["å‘ç°æ–‡æ¡£å­—ç¬¦ä¸²"],
                    quantification=f"æ–‡æ¡£å­—ç¬¦ä¸²æ•°é‡: {docstring_count}"
                ))
            
            # æ£€æŸ¥é”™è¯¯å¤„ç†
            if "try:" in content and "except" in content:
                advantages.append(Advantage(
                    category="é”™è¯¯å¤„ç†",
                    description="åŒ…å«å¼‚å¸¸å¤„ç†æœºåˆ¶",
                    impact_level="high",
                    evidence=["å‘ç°try-exceptå—"],
                    quantification="å…·å¤‡é”™è¯¯å¤„ç†èƒ½åŠ›"
                ))
            
            # æ£€æŸ¥æ¨¡å—åŒ–è®¾è®¡
            if "def " in content:
                function_count = content.count("def ")
                if function_count > 1:
                    advantages.append(Advantage(
                        category="æ¨¡å—åŒ–è®¾è®¡",
                        description=f"åŒ…å«{function_count}ä¸ªå‡½æ•°ï¼Œæ¨¡å—åŒ–ç¨‹åº¦é«˜",
                        impact_level="medium",
                        evidence=[f"å‡½æ•°æ•°é‡: {function_count}"],
                        quantification=f"æ¨¡å—åŒ–ç¨‹åº¦: {function_count}ä¸ªå‡½æ•°"
                    ))
        
        except Exception as e:
            advantages.append(Advantage(
                category="åˆ†æé™åˆ¶",
                description=f"è´¨é‡åˆ†æå—é™: {e}",
                impact_level="low",
                evidence=["åˆ†æé”™è¯¯"],
                quantification=None
            ))
        
        return advantages
    
    async def _analyze_architecture_advantages(self, file_path: str) -> List[Advantage]:
        """åˆ†ææ¶æ„ä¼˜åŠ¿"""
        advantages = []
        
        try:
            content = await self._read_file_content(file_path)
            
            # æ£€æŸ¥é¢å‘å¯¹è±¡è®¾è®¡
            if "class " in content:
                class_count = content.count("class ")
                advantages.append(Advantage(
                    category="é¢å‘å¯¹è±¡è®¾è®¡",
                    description=f"é‡‡ç”¨é¢å‘å¯¹è±¡è®¾è®¡ï¼ŒåŒ…å«{class_count}ä¸ªç±»",
                    impact_level="high",
                    evidence=[f"ç±»æ•°é‡: {class_count}"],
                    quantification=f"é¢å‘å¯¹è±¡ç¨‹åº¦: {class_count}ä¸ªç±»"
                ))
            
            # æ£€æŸ¥å¼‚æ­¥è®¾è®¡
            if "async def" in content:
                async_function_count = content.count("async def")
                advantages.append(Advantage(
                    category="å¼‚æ­¥è®¾è®¡",
                    description=f"æ”¯æŒå¼‚æ­¥ç¼–ç¨‹ï¼ŒåŒ…å«{async_function_count}ä¸ªå¼‚æ­¥å‡½æ•°",
                    impact_level="high",
                    evidence=[f"å¼‚æ­¥å‡½æ•°æ•°é‡: {async_function_count}"],
                    quantification=f"å¼‚æ­¥ç¨‹åº¦: {async_function_count}ä¸ªå¼‚æ­¥å‡½æ•°"
                ))
            
            # æ£€æŸ¥æ¥å£è®¾è®¡
            if "import" in content:
                import_count = content.count("import")
                if import_count > 0:
                    advantages.append(Advantage(
                        category="æ¥å£è®¾è®¡",
                        description=f"è‰¯å¥½çš„æ¨¡å—æ¥å£è®¾è®¡ï¼Œ{import_count}ä¸ªå¯¼å…¥",
                        impact_level="medium",
                        evidence=[f"å¯¼å…¥æ•°é‡: {import_count}"],
                        quantification=f"æ¥å£å¤æ‚åº¦: {import_count}ä¸ªå¯¼å…¥"
                    ))
        
        except Exception as e:
            advantages.append(Advantage(
                category="åˆ†æé™åˆ¶",
                description=f"æ¶æ„åˆ†æå—é™: {e}",
                impact_level="low",
                evidence=["åˆ†æé”™è¯¯"],
                quantification=None
            ))
        
        return advantages
    
    async def _analyze_disadvantages(self, file_path: str, 
                                   feature_characteristics: List[FeatureCharacteristic]) -> List[Disadvantage]:
        """åˆ†æåŠ£åŠ¿"""
        disadvantages = []
        
        # åŸºäºç‰¹å¾åˆ†æåŠ£åŠ¿
        for characteristic in feature_characteristics:
            category_disadvantages = await self._generate_disadvantages_from_characteristic(characteristic)
            disadvantages.extend(category_disadvantages)
        
        # åŸºäºä»£ç è´¨é‡åˆ†æåŠ£åŠ¿
        quality_disadvantages = await self._analyze_quality_disadvantages(file_path)
        disadvantages.extend(quality_disadvantages)
        
        # åŸºäºæ¶æ„åˆ†æåŠ£åŠ¿
        architecture_disadvantages = await self._analyze_architecture_disadvantages(file_path)
        disadvantages.extend(architecture_disadvantages)
        
        return disadvantages
    
    async def _generate_disadvantages_from_characteristic(self, characteristic: FeatureCharacteristic) -> List[Disadvantage]:
        """ä»ç‰¹å¾ç”ŸæˆåŠ£åŠ¿"""
        disadvantages = []
        
        if characteristic.complexity > 0.7:
            disadvantages.append(Disadvantage(
                category="å¤æ‚åº¦",
                description=f"å¤æ‚åº¦è¾ƒé«˜({characteristic.complexity:.1%})ï¼Œç»´æŠ¤å›°éš¾",
                impact_level="high",
                evidence=[f"å¤æ‚åº¦è¯„åˆ†: {characteristic.complexity:.1%}"],
                mitigation="é‡æ„ç®€åŒ–ï¼Œæé«˜å¯ç»´æŠ¤æ€§"
            ))
        
        if characteristic.technical_debt > 0.5:
            disadvantages.append(Disadvantage(
                category="æŠ€æœ¯å€ºåŠ¡",
                description=f"æŠ€æœ¯å€ºåŠ¡è¾ƒé«˜({characteristic.technical_debt:.1%})",
                impact_level="medium",
                evidence=[f"æŠ€æœ¯å€ºåŠ¡è¯„åˆ†: {characteristic.technical_debt:.1%}"],
                mitigation="é€æ­¥é‡æ„ï¼Œé™ä½æŠ€æœ¯å€ºåŠ¡"
            ))
        
        if characteristic.maturity < 0.5:
            disadvantages.append(Disadvantage(
                category="æˆç†Ÿåº¦",
                description=f"æˆç†Ÿåº¦è¾ƒä½({characteristic.maturity:.1%})ï¼Œå¯èƒ½å­˜åœ¨ä¸ç¨³å®šå› ç´ ",
                impact_level="medium",
                evidence=[f"æˆç†Ÿåº¦è¯„åˆ†: {characteristic.maturity:.1%}"],
                mitigation="åŠ å¼ºæµ‹è¯•ï¼Œæå‡æˆç†Ÿåº¦"
            ))
        
        return disadvantages
    
    async def _analyze_quality_disadvantages(self, file_path: str) -> List[Disadvantage]:
        """åˆ†æè´¨é‡åŠ£åŠ¿"""
        disadvantages = []
        
        try:
            content = await self._read_file_content(file_path)
            lines = content.split('\n')
            
            # æ£€æŸ¥ä»£ç é•¿åº¦
            if len(lines) > 500:
                disadvantages.append(Disadvantage(
                    category="ä»£ç é•¿åº¦",
                    description=f"ä»£ç è¿‡é•¿({len(lines)}è¡Œ)ï¼Œéš¾ä»¥ç»´æŠ¤",
                    impact_level="medium",
                    evidence=[f"ä»£ç è¡Œæ•°: {len(lines)}"],
                    mitigation="æ‹†åˆ†ä¸ºå¤šä¸ªæ¨¡å—"
                ))
            
            # æ£€æŸ¥æ³¨é‡Šè¦†ç›–ç‡
            comment_lines = len([line for line in lines if line.strip().startswith('#')])
            code_lines = len([line for line in lines if line.strip() and not line.strip().startswith('#')])
            if code_lines > 0:
                comment_ratio = comment_lines / code_lines
                if comment_ratio < 0.1:
                    disadvantages.append(Disadvantage(
                        category="æ³¨é‡Šä¸è¶³",
                        description=f"æ³¨é‡Šè¦†ç›–ç‡ä½({comment_ratio:.1%})",
                        impact_level="medium",
                        evidence=[f"æ³¨é‡Šæ¯”ä¾‹: {comment_ratio:.1%}"],
                        mitigation="å¢åŠ ä»£ç æ³¨é‡Š"
                    ))
            
            # æ£€æŸ¥ç¡¬ç¼–ç 
            if re.search(r'["\'][^"\']*["\']', content):
                hardcoded_strings = len(re.findall(r'["\'][^"\']*["\']', content))
                if hardcoded_strings > 10:
                    disadvantages.append(Disadvantage(
                        category="ç¡¬ç¼–ç ",
                        description=f"å­˜åœ¨è¾ƒå¤šç¡¬ç¼–ç å­—ç¬¦ä¸²({hardcoded_strings}ä¸ª)",
                        impact_level="low",
                        evidence=[f"ç¡¬ç¼–ç æ•°é‡: {hardcoded_strings}"],
                        mitigation="ä½¿ç”¨é…ç½®æ–‡ä»¶æˆ–å¸¸é‡"
                    ))
        
        except Exception as e:
            disadvantages.append(Disadvantage(
                category="åˆ†æé™åˆ¶",
                description=f"è´¨é‡åˆ†æå—é™: {e}",
                impact_level="low",
                evidence=["åˆ†æé”™è¯¯"],
                mitigation=None
            ))
        
        return disadvantages
    
    async def _analyze_architecture_disadvantages(self, file_path: str) -> List[Disadvantage]:
        """åˆ†ææ¶æ„åŠ£åŠ¿"""
        disadvantages = []
        
        try:
            content = await self._read_file_content(file_path)
            
            # æ£€æŸ¥ä¾èµ–æ•°é‡
            import_count = content.count("import")
            if import_count > 10:
                disadvantages.append(Disadvantage(
                    category="ä¾èµ–è¿‡å¤š",
                    description=f"å¤–éƒ¨ä¾èµ–è¿‡å¤š({import_count}ä¸ª)ï¼Œè€¦åˆåº¦é«˜",
                    impact_level="medium",
                    evidence=[f"å¯¼å…¥æ•°é‡: {import_count}"],
                    mitigation="å‡å°‘ä¸å¿…è¦çš„ä¾èµ–"
                ))
            
            # æ£€æŸ¥å‡½æ•°é•¿åº¦
            functions = re.findall(r'def\s+\w+\s*\([^)]*\):', content)
            for func in functions:
                # ç®€åŒ–çš„å‡½æ•°é•¿åº¦æ£€æŸ¥
                func_start = content.find(func)
                if func_start != -1:
                    # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªå‡½æ•°æˆ–ç±»å®šä¹‰
                    next_def = content.find('\ndef ', func_start + 1)
                    next_class = content.find('\nclass ', func_start + 1)
                    
                    func_end = len(content)
                    if next_def != -1:
                        func_end = min(func_end, next_def)
                    if next_class != -1:
                        func_end = min(func_end, next_class)
                    
                    func_content = content[func_start:func_end]
                    func_lines = len(func_content.split('\n'))
                    
                    if func_lines > 50:
                        disadvantages.append(Disadvantage(
                            category="å‡½æ•°è¿‡é•¿",
                            description="å­˜åœ¨è¶…è¿‡50è¡Œçš„é•¿å‡½æ•°",
                            impact_level="medium",
                            evidence=[f"å‡½æ•°è¡Œæ•°: {func_lines}"],
                            mitigation="æ‹†åˆ†é•¿å‡½æ•°"
                        ))
                        break
        
        except Exception as e:
            disadvantages.append(Disadvantage(
                category="åˆ†æé™åˆ¶",
                description=f"æ¶æ„åˆ†æå—é™: {e}",
                impact_level="low",
                evidence=["åˆ†æé”™è¯¯"],
                mitigation=None
            ))
        
        return disadvantages
    
    async def _analyze_alternatives(self, file_path: str, 
                                  feature_characteristics: List[FeatureCharacteristic]) -> List[Alternative]:
        """åˆ†ææ›¿ä»£æ–¹æ¡ˆ"""
        alternatives = []
        
        # åŸºäºç‰¹å¾ç”Ÿæˆæ›¿ä»£æ–¹æ¡ˆ
        for characteristic in feature_characteristics:
            characteristic_alternatives = await self._generate_alternatives_for_characteristic(characteristic)
            alternatives.extend(characteristic_alternatives)
        
        # é€šç”¨æ›¿ä»£æ–¹æ¡ˆ
        general_alternatives = await self._generate_general_alternatives(file_path)
        alternatives.extend(general_alternatives)
        
        return alternatives
    
    async def _generate_alternatives_for_characteristic(self, characteristic: FeatureCharacteristic) -> List[Alternative]:
        """ä¸ºç‰¹å¾ç”Ÿæˆæ›¿ä»£æ–¹æ¡ˆ"""
        alternatives = []
        
        if characteristic.category == FeatureCategory.CORE_ENGINE:
            alternatives.append(Alternative(
                name="é‡æ„æ ¸å¿ƒå¼•æ“",
                description="é‡æ–°è®¾è®¡æ ¸å¿ƒå¼•æ“æ¶æ„",
                feasibility=0.7,
                cost_estimate="é«˜",
                pros=["æå‡æ€§èƒ½", "é™ä½å¤æ‚åº¦", "å¢å¼ºå¯ç»´æŠ¤æ€§"],
                cons=["å¼€å‘å‘¨æœŸé•¿", "é£é™©é«˜", "éœ€è¦å……åˆ†æµ‹è¯•"],
                implementation_effort="é«˜"
            ))
        
        if characteristic.complexity > 0.7:
            alternatives.append(Alternative(
                name="ç®€åŒ–æ¨¡å—",
                description="ç®€åŒ–å¤æ‚æ¨¡å—ï¼Œæ‹†åˆ†ä¸ºå¤šä¸ªå°æ¨¡å—",
                feasibility=0.8,
                cost_estimate="ä¸­ç­‰",
                pros=["é™ä½å¤æ‚åº¦", "æé«˜å¯ç»´æŠ¤æ€§", "ä¾¿äºæµ‹è¯•"],
                cons=["éœ€è¦é‡æ–°è®¾è®¡", "å¯èƒ½å½±å“ç°æœ‰åŠŸèƒ½"],
                implementation_effort="ä¸­ç­‰"
            ))
        
        return alternatives
    
    async def _generate_general_alternatives(self, file_path: str) -> List[Alternative]:
        """ç”Ÿæˆé€šç”¨æ›¿ä»£æ–¹æ¡ˆ"""
        alternatives = []
        
        alternatives.append(Alternative(
            name="ä¿ç•™å¹¶ä¼˜åŒ–",
            description="ä¿ç•™ç°æœ‰æ–‡ä»¶ï¼Œè¿›è¡Œä¼˜åŒ–æ”¹è¿›",
            feasibility=0.9,
            cost_estimate="ä½",
            pros=["é£é™©ä½", "ä¿æŒè¿ç»­æ€§", "æ”¹è¿›ç°æœ‰åŠŸèƒ½"],
            cons=["å¯èƒ½æ— æ³•æ ¹æœ¬è§£å†³é—®é¢˜", "æŠ€æœ¯å€ºåŠ¡ä¾ç„¶å­˜åœ¨"],
            implementation_effort="ä½"
        ))
        
        alternatives.append(Alternative(
            name="å®Œå…¨é‡å†™",
            description="å®Œå…¨é‡å†™æ–‡ä»¶åŠŸèƒ½",
            feasibility=0.6,
            cost_estimate="é«˜",
            pros=["å½»åº•è§£å†³é—®é¢˜", "é‡‡ç”¨æœ€æ–°æŠ€æœ¯", "ä¼˜åŒ–æ¶æ„"],
            cons=["å¼€å‘å‘¨æœŸé•¿", "é£é™©é«˜", "éœ€è¦å……åˆ†æµ‹è¯•"],
            implementation_effort="é«˜"
        ))
        
        alternatives.append(Alternative(
            name="è¿ç§»åˆ°å…¶ä»–æ¨¡å—",
            description="å°†åŠŸèƒ½è¿ç§»åˆ°å…¶ä»–ç°æœ‰æ¨¡å—",
            feasibility=0.7,
            cost_estimate="ä¸­ç­‰",
            pros=["å‡å°‘æ–‡ä»¶æ•°é‡", "åŠŸèƒ½æ•´åˆ", "é™ä½ç»´æŠ¤æˆæœ¬"],
            cons=["å¯èƒ½å¢åŠ å…¶ä»–æ¨¡å—å¤æ‚åº¦", "éœ€è¦é‡æ„ä¾èµ–"],
            implementation_effort="ä¸­ç­‰"
        ))
        
        return alternatives
    
    async def _analyze_dependencies(self, file_path: str) -> Tuple[List[str], List[str]]:
        """åˆ†æä¾èµ–å…³ç³»"""
        dependencies = []
        dependents = []
        
        try:
            content = await self._read_file_content(file_path)
            
            # åˆ†æå¯¼å…¥ä¾èµ–
            import_matches = re.findall(r'import\s+(\w+)|from\s+(\w+)', content)
            for match in import_matches:
                dep = match[0] or match[1]
                if dep and not dep.startswith('.'):
                    dependencies.append(dep)
            
            # ç®€åŒ–çš„ä¾èµ–è€…åˆ†æï¼ˆå®é™…éœ€è¦æ‰«ææ•´ä¸ªé¡¹ç›®ï¼‰
            # è¿™é‡Œåªæ˜¯ç¤ºä¾‹
            project_files = list(self.project_root.rglob("*.py"))
            for other_file in project_files:
                if str(other_file.relative_to(self.project_root)) != file_path:
                    try:
                        with open(other_file, 'r', encoding='utf-8') as f:
                            other_content = f.read()
                        
                        # æ£€æŸ¥å…¶ä»–æ–‡ä»¶æ˜¯å¦å¯¼å…¥å½“å‰æ–‡ä»¶
                        current_module = Path(file_path).stem
                        if f"import {current_module}" in other_content or f"from {current_module}" in other_content:
                            dependents.append(str(other_file.relative_to(self.project_root)))
                    except:
                        continue
        
        except Exception as e:
            print(f"âš ï¸ ä¾èµ–åˆ†æå¤±è´¥ {file_path}: {e}")
        
        return dependencies, dependents
    
    async def _analyze_integration_points(self, file_path: str) -> List[str]:
        """åˆ†æé›†æˆç‚¹"""
        integration_points = []
        
        try:
            content = await self._read_file_content(file_path)
            
            # æ£€æŸ¥APIæ¥å£
            if re.search(r'def\s+api_|def\s+endpoint|@app\.|@router\.', content):
                integration_points.append("APIæ¥å£")
            
            # æ£€æŸ¥æ•°æ®åº“é›†æˆ
            if any(keyword in content.lower() for keyword in ['database', 'db.', 'sql', 'query']):
                integration_points.append("æ•°æ®åº“é›†æˆ")
            
            # æ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿé›†æˆ
            if any(keyword in content.lower() for keyword in ['file.', 'open(', 'path.', 'os.']):
                integration_points.append("æ–‡ä»¶ç³»ç»Ÿé›†æˆ")
            
            # æ£€æŸ¥ç½‘ç»œé›†æˆ
            if any(keyword in content.lower() for keyword in ['http', 'request', 'response', 'socket']):
                integration_points.append("ç½‘ç»œé›†æˆ")
            
            # æ£€æŸ¥ç¼“å­˜é›†æˆ
            if any(keyword in content.lower() for keyword in ['cache', 'redis', 'memcache']):
                integration_points.append("ç¼“å­˜é›†æˆ")
            
        except Exception as e:
            print(f"âš ï¸ é›†æˆç‚¹åˆ†æå¤±è´¥ {file_path}: {e}")
        
        return integration_points
    
    async def _generate_retention_justification(self, file_path: str,
                                             feature_characteristics: List[FeatureCharacteristic],
                                             advantages: List[Advantage],
                                             disadvantages: List[Disadvantage]) -> str:
        """ç”Ÿæˆä¿ç•™ç†ç”±"""
        justification_parts = []
        
        justification_parts.append(f"## ä¿ç•™ {file_path} çš„ç†ç”±")
        justification_parts.append("")
        
        # åŠŸèƒ½ä»·å€¼
        if feature_characteristics:
            justification_parts.append("### åŠŸèƒ½ä»·å€¼")
            for characteristic in feature_characteristics:
                if characteristic.value_level in [ValueLevel.CRITICAL, ValueLevel.HIGH]:
                    justification_parts.append(f"- **{characteristic.name}**: {characteristic.description}")
                    justification_parts.append(f"  - ä»·å€¼ç­‰çº§: {characteristic.value_level.value}")
                    justification_parts.append(f"  - ç‹¬ç‰¹æ€§: {characteristic.uniqueness:.1%}")
            justification_parts.append("")
        
        # ä¼˜åŠ¿åˆ†æ
        if advantages:
            justification_parts.append("### ä¸»è¦ä¼˜åŠ¿")
            high_impact_advantages = [adv for adv in advantages if adv.impact_level in ["high", "medium"]]
            for advantage in high_impact_advantages:
                justification_parts.append(f"- **{advantage.category}**: {advantage.description}")
                if advantage.quantification:
                    justification_parts.append(f"  - é‡åŒ–æŒ‡æ ‡: {advantage.quantification}")
            justification_parts.append("")
        
        # ä¾èµ–å…³ç³»
        try:
            dependencies, dependents = await self._analyze_dependencies(file_path)
            if dependents:
                justification_parts.append("### ä¾èµ–å…³ç³»")
                justification_parts.append(f"- è¢« {len(dependents)} ä¸ªå…¶ä»–æ¨¡å—ä¾èµ–:")
                for dependent in dependents[:5]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                    justification_parts.append(f"  - {dependent}")
                justification_parts.append("")
        except:
            pass
        
        # é›†æˆç‚¹
        try:
            integration_points = await self._analyze_integration_points(file_path)
            if integration_points:
                justification_parts.append("### é›†æˆç‚¹")
                for point in integration_points:
                    justification_parts.append(f"- {point}")
                justification_parts.append("")
        except:
            pass
        
        # ç»“è®º
        justification_parts.append("### ç»“è®º")
        if len(advantages) > len(disadvantages):
            justification_parts.append("åŸºäºä»¥ä¸Šåˆ†æï¼Œè¯¥æ–‡ä»¶çš„ä¼˜åŠ¿æ˜æ˜¾å¤§äºåŠ£åŠ¿ï¼Œå»ºè®®ä¿ç•™ã€‚")
        elif any(char.value_level == ValueLevel.CRITICAL for char in feature_characteristics):
            justification_parts.append("è¯¥æ–‡ä»¶åŒ…å«å…³é”®åŠŸèƒ½ï¼Œè™½ç„¶å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œä½†å»ºè®®ä¿ç•™å¹¶è¿›è¡Œä¼˜åŒ–ã€‚")
        else:
            justification_parts.append("è¯¥æ–‡ä»¶å…·æœ‰ä¸€å®šçš„ä»·å€¼ï¼Œå»ºè®®ä¿ç•™ä½†éœ€è¦æŒç»­æ”¹è¿›ã€‚")
        
        return "\n".join(justification_parts)
    
    async def _generate_removal_justification(self, file_path: str,
                                            feature_characteristics: List[FeatureCharacteristic],
                                            disadvantages: List[Disadvantage]) -> Optional[str]:
        """ç”Ÿæˆåˆ é™¤ç†ç”±"""
        # åªæœ‰åœ¨å……åˆ†ç†ç”±æ—¶æ‰ç”Ÿæˆåˆ é™¤ç†ç”±
        removal_reasons = []
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å……åˆ†çš„åˆ é™¤ç†ç”±
        high_impact_disadvantages = [dis for dis in disadvantages if dis.impact_level == "high"]
        low_value_features = [char for char in feature_characteristics if char.value_level in [ValueLevel.LOW, ValueLevel.NEGLIGIBLE]]
        
        if not high_impact_disadvantages and not low_value_features:
            return None
        
        justification_parts = []
        justification_parts.append(f"## åˆ é™¤ {file_path} çš„ç†ç”±")
        justification_parts.append("")
        
        # ä¸¥é‡é—®é¢˜
        if high_impact_disadvantages:
            justification_parts.append("### ä¸¥é‡é—®é¢˜")
            for disadvantage in high_impact_disadvantages:
                justification_parts.append(f"- **{disadvantage.category}**: {disadvantage.description}")
                if disadvantage.mitigation:
                    justification_parts.append(f"  - ç¼“è§£æ–¹æ¡ˆ: {disadvantage.mitigation}")
            justification_parts.append("")
        
        # ä½ä»·å€¼ç‰¹å¾
        if low_value_features:
            justification_parts.append("### ä½ä»·å€¼ç‰¹å¾")
            for characteristic in low_value_features:
                justification_parts.append(f"- **{characteristic.name}**: {characteristic.description}")
                justification_parts.append(f"  - ä»·å€¼ç­‰çº§: {characteristic.value_level.value}")
                justification_parts.append(f"  - æŠ€æœ¯å€ºåŠ¡: {characteristic.technical_debt:.1%}")
            justification_parts.append("")
        
        # æ›¿ä»£æ–¹æ¡ˆ
        try:
            alternatives = await self._generate_general_alternatives(file_path)
            if alternatives:
                justification_parts.append("### æ›¿ä»£æ–¹æ¡ˆ")
                for alternative in alternatives:
                    justification_parts.append(f"- **{alternative.name}**: {alternative.description}")
                    justification_parts.append(f"  - å¯è¡Œæ€§: {alternative.feasibility:.1%}")
                    justification_parts.append(f"  - å®æ–½éš¾åº¦: {alternative.implementation_effort}")
                justification_parts.append("")
        except:
            pass
        
        # ç»“è®º
        justification_parts.append("### ç»“è®º")
        justification_parts.append("åŸºäºä»¥ä¸Šåˆ†æï¼Œè¯¥æ–‡ä»¶å­˜åœ¨ä¸¥é‡é—®é¢˜ä¸”ä»·å€¼è¾ƒä½ï¼Œå»ºè®®åˆ é™¤ã€‚")
        
        return "\n".join(justification_parts)
    
    async def _analyze_replacement_options(self, file_path: str, alternatives: List[Alternative]) -> List[str]:
        """åˆ†ææ›¿æ¢é€‰é¡¹"""
        options = []
        
        for alternative in alternatives:
            if alternative.feasibility > 0.6:
                options.append(f"{alternative.name}: {alternative.description}")
        
        return options
    
    async def _perform_overall_assessment(self, feature_characteristics: List[FeatureCharacteristic],
                                         advantages: List[Advantage],
                                         disadvantages: List[Disadvantage]) -> str:
        """æ‰§è¡Œæ•´ä½“è¯„ä¼°"""
        assessment_parts = []
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†
        high_value_features = len([char for char in feature_characteristics if char.value_level in [ValueLevel.CRITICAL, ValueLevel.HIGH]])
        high_impact_advantages = len([adv for adv in advantages if adv.impact_level == "high"])
        high_impact_disadvantages = len([dis for dis in disadvantages if dis.impact_level == "high"])
        
        # è¯„ä¼°ç»“è®º
        if high_value_features > 0 or high_impact_advantages > high_impact_disadvantages:
            assessment = "è¯¥æ–‡ä»¶å…·æœ‰è¾ƒé«˜çš„ä»·å€¼å’Œé‡è¦æ€§ï¼Œå»ºè®®ä¿ç•™ã€‚"
        elif high_impact_disadvantages > high_impact_advantages:
            assessment = "è¯¥æ–‡ä»¶å­˜åœ¨è¾ƒå¤šä¸¥é‡é—®é¢˜ï¼Œå»ºè®®è€ƒè™‘åˆ é™¤æˆ–é‡æ„ã€‚"
        else:
            assessment = "è¯¥æ–‡ä»¶ä»·å€¼ä¸€èˆ¬ï¼Œéœ€è¦æ ¹æ®å…·ä½“æƒ…å†µå†³å®šä¿ç•™æˆ–åˆ é™¤ã€‚"
        
        assessment_parts.append("## æ•´ä½“è¯„ä¼°")
        assessment_parts.append("")
        assessment_parts.append(f"**è¯„ä¼°ç»“è®º**: {assessment}")
        assessment_parts.append("")
        assessment_parts.append(f"**ç»Ÿè®¡ä¿¡æ¯**:")
        assessment_parts.append(f"- é«˜ä»·å€¼ç‰¹å¾: {high_value_features}ä¸ª")
        assessment_parts.append(f"- é«˜å½±å“ä¼˜åŠ¿: {high_impact_advantages}ä¸ª")
        assessment_parts.append(f"- é«˜å½±å“åŠ£åŠ¿: {high_impact_disadvantages}ä¸ª")
        assessment_parts.append("")
        
        return "\n".join(assessment_parts)
    
    async def _generate_recommendation(self, file_path: str, 
                                     overall_assessment: str,
                                     alternatives: List[Alternative]) -> str:
        """ç”Ÿæˆæ¨èå»ºè®®"""
        recommendation_parts = []
        
        recommendation_parts.append("## æ¨èå»ºè®®")
        recommendation_parts.append("")
        
        # åŸºäºæ•´ä½“è¯„ä¼°ç”Ÿæˆæ¨è
        if "å»ºè®®ä¿ç•™" in overall_assessment:
            recommendation_parts.append("### ä¸»è¦å»ºè®®")
            recommendation_parts.append("1. **ä¿ç•™æ–‡ä»¶** - ç»§ç»­ç»´æŠ¤å’Œä½¿ç”¨è¯¥æ–‡ä»¶")
            recommendation_parts.append("2. **ä¼˜åŒ–æ”¹è¿›** - é’ˆå¯¹è¯†åˆ«çš„é—®é¢˜è¿›è¡Œä¼˜åŒ–")
            recommendation_parts.append("3. **ç›‘æ§è¯„ä¼°** - å®šæœŸè¯„ä¼°æ–‡ä»¶ä»·å€¼å’Œä½¿ç”¨æƒ…å†µ")
        elif "å»ºè®®è€ƒè™‘åˆ é™¤" in overall_assessment:
            recommendation_parts.append("### ä¸»è¦å»ºè®®")
            recommendation_parts.append("1. **è°¨æ…åˆ é™¤** - åœ¨å……åˆ†æµ‹è¯•åè€ƒè™‘åˆ é™¤")
            recommendation_parts.append("2. **åŠŸèƒ½è¿ç§»** - å°†æœ‰ç”¨åŠŸèƒ½è¿ç§»åˆ°å…¶ä»–æ¨¡å—")
            recommendation_parts.append("3. **å¤‡ä»½ä¿ç•™** - åˆ é™¤å‰å¤‡ä»½ä»¥é˜²éœ€è¦æ¢å¤")
        else:
            recommendation_parts.append("### ä¸»è¦å»ºè®®")
            recommendation_parts.append("1. **è¿›ä¸€æ­¥åˆ†æ** - æ”¶é›†æ›´å¤šä½¿ç”¨æ•°æ®å’Œåé¦ˆ")
            recommendation_parts.append("2. **è¯•ç‚¹æµ‹è¯•** - åœ¨å°èŒƒå›´å†…æµ‹è¯•æ›¿ä»£æ–¹æ¡ˆ")
            recommendation_parts.append("3. **å›¢é˜Ÿè®¨è®º** - ä¸å›¢é˜Ÿè®¨è®ºå†³å®šæœ€ç»ˆæ–¹æ¡ˆ")
        
        recommendation_parts.append("")
        
        # å®æ–½å»ºè®®
        if alternatives:
            best_alternative = max(alternatives, key=lambda x: x.feasibility)
            recommendation_parts.append("### å®æ–½å»ºè®®")
            recommendation_parts.append(f"æ¨èé‡‡ç”¨: **{best_alternative.name}**")
            recommendation_parts.append(f"ç†ç”±: {best_alternative.description}")
            recommendation_parts.append(f"å¯è¡Œæ€§: {best_alternative.feasibility:.1%}")
            recommendation_parts.append(f"å®æ–½éš¾åº¦: {best_alternative.implementation_effort}")
            recommendation_parts.append("")
        
        return "\n".join(recommendation_parts)
    
    async def _read_file_content(self, file_path: str) -> str:
        """è¯»å–æ–‡ä»¶å†…å®¹"""
        full_path = self.project_root / file_path
        try:
            with open(full_path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            print(f"âš ï¸ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return ""
    
    def _load_feature_patterns(self) -> Dict[str, Any]:
        """åŠ è½½åŠŸèƒ½æ¨¡å¼"""
        return {
            "arq_engine": {
                "name": "ARQå¼•æ“",
                "description": "è‡ªé€‚åº”æ¨ç†æŸ¥è¯¢å¼•æ“",
                "category": "core_engine",
                "value_level": "critical",
                "filename_patterns": [r".*arq.*engine.*", r".*adaptive.*reasoning.*"],
                "content_patterns": [r"class.*ARQ", r"def.*reasoning"],
                "keywords": ["reasoning", "query", "adaptive", "intelligent"],
                "usage_frequency": "high",
                "user_impact": "high",
                "business_value": "critical",
                "technical_debt": 0.3
            },
            "hrrk_kernel": {
                "name": "HRRKå†…æ ¸",
                "description": "é«˜æ€§èƒ½æ¨ç†å†…æ ¸",
                "category": "core_engine",
                "value_level": "critical",
                "filename_patterns": [r".*hrrk.*kernel.*", r".*high.*performance.*"],
                "content_patterns": [r"class.*HRRK", r"def.*kernel"],
                "keywords": ["kernel", "performance", "high-speed", "reasoning"],
                "usage_frequency": "high",
                "user_impact": "high",
                "business_value": "critical",
                "technical_debt": 0.2
            },
            "refrag_system": {
                "name": "REFRAGç³»ç»Ÿ",
                "description": "æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿ",
                "category": "core_engine",
                "value_level": "high",
                "filename_patterns": [r".*refrag.*", r".*retrieval.*"],
                "content_patterns": [r"class.*REFRAG", r"def.*retrieval"],
                "keywords": ["retrieval", "generation", "frag", "search"],
                "usage_frequency": "high",
                "user_impact": "high",
                "business_value": "high",
                "technical_debt": 0.3
            },
            "cache_system": {
                "name": "ç¼“å­˜ç³»ç»Ÿ",
                "description": "æ™ºèƒ½ç¼“å­˜ç®¡ç†",
                "category": "performance_module",
                "value_level": "high",
                "filename_patterns": [r".*cache.*", r".*caching.*"],
                "content_patterns": [r"class.*Cache", r"def.*cache"],
                "keywords": ["cache", "caching", "memory", "performance"],
                "usage_frequency": "high",
                "user_impact": "medium",
                "business_value": "high",
                "technical_debt": 0.2
            },
            "workflow_engine": {
                "name": "å·¥ä½œæµå¼•æ“",
                "description": "ä¸šåŠ¡æµç¨‹ç®¡ç†",
                "category": "workflow_system",
                "value_level": "high",
                "filename_patterns": [r".*workflow.*", r".*process.*"],
                "content_patterns": [r"class.*Workflow", r"def.*workflow"],
                "keywords": ["workflow", "process", "flow", "orchestration"],
                "usage_frequency": "medium",
                "user_impact": "medium",
                "business_value": "high",
                "technical_debt": 0.3
            },
            "security_module": {
                "name": "å®‰å…¨æ¨¡å—",
                "description": "ç³»ç»Ÿå®‰å…¨é˜²æŠ¤",
                "category": "security_module",
                "value_level": "high",
                "filename_patterns": [r".*security.*", r".*auth.*"],
                "content_patterns": [r"class.*Security", r"def.*security"],
                "keywords": ["security", "authentication", "authorization", "protection"],
                "usage_frequency": "medium",
                "user_impact": "high",
                "business_value": "critical",
                "technical_debt": 0.2
            },
            "test_module": {
                "name": "æµ‹è¯•æ¨¡å—",
                "description": "è‡ªåŠ¨åŒ–æµ‹è¯•",
                "category": "test_module",
                "value_level": "medium",
                "filename_patterns": [r".*test.*", r".*spec.*"],
                "content_patterns": [r"def test_", r"class.*Test"],
                "keywords": ["test", "testing", "spec", "assert"],
                "usage_frequency": "medium",
                "user_impact": "low",
                "business_value": "medium",
                "technical_debt": 0.4
            },
            "utility_module": {
                "name": "å·¥å…·æ¨¡å—",
                "description": "é€šç”¨å·¥å…·å‡½æ•°",
                "category": "utility_module",
                "value_level": "medium",
                "filename_patterns": [r".*util.*", r".*helper.*", r".*tool.*"],
                "content_patterns": [r"def.*util", r"def.*helper"],
                "keywords": ["utility", "helper", "tool", "common"],
                "usage_frequency": "medium",
                "user_impact": "low",
                "business_value": "medium",
                "technical_debt": 0.3
            }
        }
    
    def _load_value_criteria(self) -> Dict[str, Any]:
        """åŠ è½½ä»·å€¼è¯„ä¼°æ ‡å‡†"""
        return {
            "critical": {
                "description": "å…³é”®åŠŸèƒ½ï¼Œç³»ç»Ÿæ ¸å¿ƒç»„ä»¶",
                "impact": "åˆ é™¤ä¼šå¯¼è‡´ç³»ç»Ÿæ— æ³•æ­£å¸¸è¿è¡Œ",
                "usage_threshold": "> 80% ä½¿ç”¨é¢‘ç‡",
                "business_impact": "ç›´æ¥å½±å“æ ¸å¿ƒä¸šåŠ¡"
            },
            "high": {
                "description": "é‡è¦åŠŸèƒ½ï¼Œæ˜¾è‘—æå‡ç”¨æˆ·ä½“éªŒ",
                "impact": "åˆ é™¤ä¼šä¸¥é‡å½±å“ç³»ç»ŸåŠŸèƒ½",
                "usage_threshold": "50-80% ä½¿ç”¨é¢‘ç‡",
                "business_impact": "å½±å“é‡è¦ä¸šåŠ¡æµç¨‹"
            },
            "medium": {
                "description": "æœ‰ç”¨åŠŸèƒ½ï¼Œæä¾›å¢å€¼æœåŠ¡",
                "impact": "åˆ é™¤ä¼šå½±å“éƒ¨åˆ†ç”¨æˆ·ä½“éªŒ",
                "usage_threshold": "20-50% ä½¿ç”¨é¢‘ç‡",
                "business_impact": "å½±å“è¾…åŠ©ä¸šåŠ¡åŠŸèƒ½"
            },
            "low": {
                "description": "æ¬¡è¦åŠŸèƒ½ï¼Œä½¿ç”¨è¾ƒå°‘",
                "impact": "åˆ é™¤å½±å“æœ‰é™",
                "usage_threshold": "5-20% ä½¿ç”¨é¢‘ç‡",
                "business_impact": "å½±å“è¾¹ç¼˜ä¸šåŠ¡åŠŸèƒ½"
            },
            "negligible": {
                "description": "å‡ ä¹ä¸ä½¿ç”¨çš„åŠŸèƒ½",
                "impact": "åˆ é™¤å‡ ä¹æ— å½±å“",
                "usage_threshold": "< 5% ä½¿ç”¨é¢‘ç‡",
                "business_impact": "å‡ ä¹æ— ä¸šåŠ¡å½±å“"
            }
        }

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    """ä¸»å‡½æ•°"""
    project_root = "."
    
    analyzer = FeatureAnalysisModule(project_root)
    
    # ç¤ºä¾‹ï¼šåˆ†æä¸€ä¸ªæ–‡ä»¶
    file_path = "example_module.py"
    analysis = await analyzer.analyze_comprehensive_features(file_path)
    
    print(f"ğŸ‰ åŠŸèƒ½åˆ†æå®Œæˆ!")
    print(f"ğŸ“Š æ–‡ä»¶: {analysis.file_path}")
    print(f"ğŸ¯ ç‰¹å¾æ•°é‡: {len(analysis.feature_characteristics)}")
    print(f"ğŸ’ª ä¼˜åŠ¿æ•°é‡: {len(analysis.advantages)}")
    print(f"âš ï¸ åŠ£åŠ¿æ•°é‡: {len(analysis.disadvantages)}")
    print(f"ğŸ”„ æ›¿ä»£æ–¹æ¡ˆ: {len(analysis.alternatives)}")
    print(f"ğŸ’¡ æ¨è: {analysis.recommendation}")

if __name__ == "__main__":
    asyncio.run(main())