#!/usr/bin/env python3
"""
é¡¹ç›®ç»“æ„æ ‘å¯¹æ¯”åˆ†ææ¨¡å—
æä¾›è¯¦ç»†çš„é¡¹ç›®ç»“æ„å˜åŒ–åˆ†æå’Œå†³ç­–æ”¯æŒ
"""

import os
import json
import hashlib
import difflib
from pathlib import Path
from typing import Dict, List, Any, Tuple, Optional
from dataclasses import dataclass, asdict
from datetime import datetime
import ast
import re

@dataclass
class FileAnalysis:
    """æ–‡ä»¶åˆ†æç»“æœ"""
    path: str
    name: str
    size: int
    modified_time: float
    file_hash: str
    file_type: str
    functions: List[str]
    classes: List[str]
    imports: List[str]
    complexity_score: float
    dependencies: List[str]
    functionality_score: float
    maintenance_cost: float
    business_value: float
    risk_assessment: str
    retention_recommendation: str
    deletion_justification: Optional[str] = None
    retention_justification: Optional[str] = None

@dataclass
class StructureComparison:
    """ç»“æ„å¯¹æ¯”ç»“æœ"""
    timestamp: str
    files_added: List[FileAnalysis]
    files_removed: List[FileAnalysis]
    files_modified: List[Tuple[FileAnalysis, FileAnalysis]]
    directories_added: List[str]
    directories_removed: List[str]
    structure_changes: Dict[str, Any]
    impact_analysis: Dict[str, Any]
    recommendations: List[str]

class ProjectStructureAnalyzer:
    """é¡¹ç›®ç»“æ„åˆ†æå™¨"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.cache_dir = self.project_root / ".iflow" / "cache" / "structure_analysis"
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
    async def analyze_and_compare(self, baseline_snapshot: Optional[str] = None) -> StructureComparison:
        """åˆ†æå¹¶å¯¹æ¯”é¡¹ç›®ç»“æ„"""
        print("ğŸ” å¼€å§‹é¡¹ç›®ç»“æ„å¯¹æ¯”åˆ†æ...")
        
        # 1. è·å–å½“å‰é¡¹ç›®ç»“æ„
        current_structure = await self._analyze_current_structure()
        
        # 2. åŠ è½½åŸºçº¿ç»“æ„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        baseline_structure = await self._load_baseline_structure(baseline_snapshot)
        
        # 3. æ‰§è¡Œå¯¹æ¯”åˆ†æ
        comparison = await self._compare_structures(current_structure, baseline_structure)
        
        # 4. ç”Ÿæˆå½±å“åˆ†æ
        impact_analysis = await self._analyze_impact(comparison)
        comparison.impact_analysis = impact_analysis
        
        # 5. ç”Ÿæˆæ¨èå»ºè®®
        recommendations = await self._generate_recommendations(comparison)
        comparison.recommendations = recommendations
        
        # 6. ä¿å­˜å½“å‰å¿«ç…§ä½œä¸ºæ–°çš„åŸºçº¿
        await self._save_structure_snapshot(current_structure)
        
        print("âœ… é¡¹ç›®ç»“æ„å¯¹æ¯”åˆ†æå®Œæˆ")
        return comparison
    
    async def _analyze_current_structure(self) -> Dict[str, Any]:
        """åˆ†æå½“å‰é¡¹ç›®ç»“æ„"""
        print("ğŸ“Š åˆ†æå½“å‰é¡¹ç›®ç»“æ„...")
        
        structure = {
            "timestamp": datetime.now().isoformat(),
            "project_root": str(self.project_root),
            "files": {},
            "directories": set(),
            "statistics": {},
            "dependencies": {},
            "complexity_metrics": {}
        }
        
        total_files = 0
        total_size = 0
        python_files = 0
        test_files = 0
        
        # éå†é¡¹ç›®æ–‡ä»¶
        for root, dirs, files in os.walk(self.project_root):
            # è·³è¿‡ç‰¹å®šç›®å½•
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'node_modules']]
            
            rel_root = os.path.relpath(root, self.project_root)
            if rel_root == '.':
                rel_root = 'root'
            
            structure["directories"].add(rel_root)
            
            for file in files:
                if not file.startswith('.') and not file.endswith('.pyc'):
                    file_path = Path(root) / file
                    rel_path = str(file_path.relative_to(self.project_root))
                    
                    try:
                        file_analysis = await self._analyze_file(file_path)
                        structure["files"][rel_path] = file_analysis
                        
                        total_files += 1
                        total_size += file_analysis.size
                        
                        if file.endswith('.py'):
                            python_files += 1
                        if 'test' in file.lower():
                            test_files += 1
                        
                        # åˆ†æä¾èµ–å…³ç³»
                        deps = await self._analyze_file_dependencies(file_path)
                        structure["dependencies"][rel_path] = deps
                        
                        # è®¡ç®—å¤æ‚åº¦æŒ‡æ ‡
                        complexity = await self._calculate_file_complexity(file_path)
                        structure["complexity_metrics"][rel_path] = complexity
                        
                    except Exception as e:
                        print(f"âš ï¸ åˆ†ææ–‡ä»¶å¤±è´¥ {rel_path}: {e}")
        
        structure["statistics"] = {
            "total_files": total_files,
            "total_size": total_size,
            "python_files": python_files,
            "test_files": test_files,
            "directories": len(structure["directories"])
        }
        
        return structure
    
    async def _analyze_file(self, file_path: Path) -> FileAnalysis:
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'rb') as f:
                content_bytes = f.read()
            
            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
            file_hash = hashlib.md5(content_bytes).hexdigest()
            
            # å¦‚æœæ˜¯Pythonæ–‡ä»¶ï¼Œè¿›è¡Œæ·±åº¦åˆ†æ
            if file_path.suffix == '.py':
                try:
                    content = content_bytes.decode('utf-8')
                    tree = ast.parse(content)
                    
                    functions = []
                    classes = []
                    imports = []
                    
                    for node in ast.walk(tree):
                        if isinstance(node, ast.FunctionDef):
                            functions.append(node.name)
                        elif isinstance(node, ast.ClassDef):
                            classes.append(node.name)
                        elif isinstance(node, (ast.Import, ast.ImportFrom)):
                            if isinstance(node, ast.Import):
                                imports.extend([alias.name for alias in node.names])
                            else:
                                module = node.module or ""
                                imports.extend([f"{module}.{alias.name}" for alias in node.names])
                    
                    # è®¡ç®—å„é¡¹æŒ‡æ ‡
                    complexity_score = await self._calculate_complexity_score(content)
                    functionality_score = await self._calculate_functionality_score(content, file_path.name)
                    maintenance_cost = await self._calculate_maintenance_cost(content, functions, classes)
                    business_value = await self._calculate_business_value(content, file_path.name)
                    risk_assessment = await self._assess_file_risk(content, file_path.name)
                    retention_recommendation = await self._recommend_retention(business_value, maintenance_cost, risk_assessment)
                    
                    return FileAnalysis(
                        path=str(file_path.relative_to(self.project_root)),
                        name=file_path.name,
                        size=len(content_bytes),
                        modified_time=file_path.stat().st_mtime,
                        file_hash=file_hash,
                        file_type='python',
                        functions=functions,
                        classes=classes,
                        imports=imports,
                        complexity_score=complexity_score,
                        dependencies=[],
                        functionality_score=functionality_score,
                        maintenance_cost=maintenance_cost,
                        business_value=business_value,
                        risk_assessment=risk_assessment,
                        retention_recommendation=retention_recommendation
                    )
                    
                except Exception as e:
                    print(f"âš ï¸ Pythonæ–‡ä»¶åˆ†æå¤±è´¥ {file_path}: {e}")
            
            # éPythonæ–‡ä»¶çš„åŸºæœ¬åˆ†æ
            return FileAnalysis(
                path=str(file_path.relative_to(self.project_root)),
                name=file_path.name,
                size=len(content_bytes),
                modified_time=file_path.stat().st_mtime,
                file_hash=file_hash,
                file_type=file_path.suffix[1:] if file_path.suffix else 'unknown',
                functions=[],
                classes=[],
                imports=[],
                complexity_score=0.0,
                dependencies=[],
                functionality_score=0.5,
                maintenance_cost=0.5,
                business_value=0.5,
                risk_assessment="low",
                retention_recommendation="keep"
            )
            
        except Exception as e:
            print(f"âš ï¸ æ–‡ä»¶åˆ†æå¤±è´¥ {file_path}: {e}")
            return FileAnalysis(
                path=str(file_path.relative_to(self.project_root)),
                name=file_path.name,
                size=0,
                modified_time=0,
                file_hash="",
                file_type='error',
                functions=[],
                classes=[],
                imports=[],
                complexity_score=0.0,
                dependencies=[],
                functionality_score=0.0,
                maintenance_cost=0.0,
                business_value=0.0,
                risk_assessment="error",
                retention_recommendation="review"
            )
    
    async def _calculate_complexity_score(self, content: str) -> float:
        """è®¡ç®—å¤æ‚åº¦åˆ†æ•°"""
        lines = content.split('\n')
        code_lines = len([line for line in lines if line.strip() and not line.strip().startswith('#')])
        
        tree = ast.parse(content)
        
        # åœˆå¤æ‚åº¦
        complexity = 1
        for node in ast.walk(tree):
            if isinstance(node, (ast.If, ast.While, ast.For, ast.With)):
                complexity += 1
            elif isinstance(node, ast.ExceptHandler):
                complexity += 1
            elif isinstance(node, ast.BoolOp):
                complexity += len(node.values) - 1
        
        return float(complexity + code_lines * 0.1)
    
    async def _calculate_functionality_score(self, content: str, filename: str) -> float:
        """è®¡ç®—åŠŸèƒ½ä»·å€¼åˆ†æ•°"""
        score = 0.5  # åŸºç¡€åˆ†æ•°
        
        # åŸºäºæ–‡ä»¶å
        if 'engine' in filename.lower():
            score += 0.3
        if 'core' in filename.lower():
            score += 0.3
        if 'main' in filename.lower():
            score += 0.2
        if 'test' in filename.lower():
            score += 0.1
        if 'util' in filename.lower():
            score += 0.1
        if 'cache' in filename.lower():
            score += 0.15
        if 'security' in filename.lower():
            score += 0.25
        
        # åŸºäºå†…å®¹
        if 'class' in content:
            score += 0.1
        if 'def ' in content:
            score += 0.1
        if 'async def' in content:
            score += 0.15
        if 'import' in content:
            score += 0.05
        
        return min(score, 1.0)
    
    async def _calculate_maintenance_cost(self, content: str, functions: List[str], classes: List[str]) -> float:
        """è®¡ç®—ç»´æŠ¤æˆæœ¬"""
        cost = 0.1  # åŸºç¡€æˆæœ¬
        
        # åŸºäºä»£ç é‡
        lines = len(content.split('\n'))
        cost += lines * 0.001
        
        # åŸºäºå¤æ‚åº¦
        cost += len(functions) * 0.02
        cost += len(classes) * 0.03
        
        # åŸºäºå¯¼å…¥æ•°é‡
        imports = content.count('import')
        cost += imports * 0.01
        
        # åŸºäºæ³¨é‡Šè´¨é‡
        comment_lines = content.count('#')
        if comment_lines > 0:
            cost -= comment_lines * 0.0005
        
        return min(cost, 1.0)
    
    async def _calculate_business_value(self, content: str, filename: str) -> float:
        """è®¡ç®—ä¸šåŠ¡ä»·å€¼"""
        value = 0.3  # åŸºç¡€ä»·å€¼
        
        # æ ¸å¿ƒæ¨¡å—ä»·å€¼æ›´é«˜
        if any(keyword in filename.lower() for keyword in ['engine', 'core', 'main', 'kernel']):
            value += 0.4
        
        # å®‰å…¨åŠŸèƒ½ä»·å€¼é«˜
        if 'security' in filename.lower():
            value += 0.3
        
        # æ€§èƒ½ç›¸å…³ä»·å€¼é«˜
        if any(keyword in filename.lower() for keyword in ['cache', 'optimize', 'performance']):
            value += 0.2
        
        # ç”¨æˆ·æ¥å£ä»·å€¼é«˜
        if any(keyword in filename.lower() for keyword in ['api', 'interface', 'ui', 'cli']):
            value += 0.25
        
        # æ•°æ®å¤„ç†ä»·å€¼ä¸­ç­‰
        if any(keyword in filename.lower() for keyword in ['data', 'process', 'transform']):
            value += 0.15
        
        # æµ‹è¯•ä»·å€¼è¾ƒä½ä½†é‡è¦
        if 'test' in filename.lower():
            value += 0.1
        
        return min(value, 1.0)
    
    async def _assess_file_risk(self, content: str, filename: str) -> str:
        """è¯„ä¼°æ–‡ä»¶é£é™©"""
        risk_score = 0
        
        # å¤æ‚åº¦é£é™©
        if len(content) > 1000:
            risk_score += 1
        if content.count('class ') > 5:
            risk_score += 1
        if content.count('def ') > 20:
            risk_score += 1
        
        # å®‰å…¨é£é™©
        if any(keyword in content for keyword in ['eval', 'exec', 'compile']):
            risk_score += 3
        if 'password' in content.lower() or 'secret' in content.lower():
            risk_score += 2
        
        # ä¾èµ–é£é™©
        if content.count('import') > 10:
            risk_score += 1
        
        # ç¡®å®šé£é™©ç­‰çº§
        if risk_score >= 4:
            return "high"
        elif risk_score >= 2:
            return "medium"
        else:
            return "low"
    
    async def _recommend_retention(self, business_value: float, maintenance_cost: float, risk_assessment: str) -> str:
        """æ¨èä¿ç•™æˆ–åˆ é™¤"""
        # è®¡ç®—å‡€ä»·å€¼
        net_value = business_value - maintenance_cost
        
        # é£é™©è°ƒæ•´
        if risk_assessment == "high":
            net_value -= 0.2
        elif risk_assessment == "medium":
            net_value -= 0.1
        
        # å†³ç­–
        if net_value >= 0.3:
            return "keep"
        elif net_value >= 0.1:
            return "review"
        else:
            return "consider_remove"
    
    async def _analyze_file_dependencies(self, file_path: Path) -> List[str]:
        """åˆ†ææ–‡ä»¶ä¾èµ–"""
        if file_path.suffix != '.py':
            return []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            dependencies = []
            
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        dependencies.append(alias.name)
                elif isinstance(node, ast.ImportFrom):
                    module = node.module or ""
                    for alias in node.names:
                        dependencies.append(f"{module}.{alias.name}")
            
            return dependencies
            
        except Exception:
            return []
    
    async def _calculate_file_complexity(self, file_path: Path) -> Dict[str, float]:
        """è®¡ç®—æ–‡ä»¶å¤æ‚åº¦æŒ‡æ ‡"""
        if file_path.suffix != '.py':
            return {"complexity": 0.0}
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            metrics = {
                "cyclomatic_complexity": 1,
                "cognitive_complexity": 0,
                "halstead_volume": 0.0,
                "maintainability_index": 100.0
            }
            
            # åœˆå¤æ‚åº¦
            for node in ast.walk(tree):
                if isinstance(node, (ast.If, ast.While, ast.For, ast.With)):
                    metrics["cyclomatic_complexity"] += 1
                elif isinstance(node, ast.ExceptHandler):
                    metrics["cyclomatic_complexity"] += 1
                elif isinstance(node, ast.BoolOp):
                    metrics["cyclomatic_complexity"] += len(node.values) - 1
            
            # ç®€åŒ–çš„å¯ç»´æŠ¤æ€§æŒ‡æ•°
            lines = len(content.split('\n'))
            metrics["maintainability_index"] = max(0, 100 - metrics["cyclomatic_complexity"] * 2 - lines * 0.1)
            
            return metrics
            
        except Exception:
            return {"complexity": 0.0}
    
    async def _load_baseline_structure(self, baseline_snapshot: Optional[str] = None) -> Optional[Dict[str, Any]]:
        """åŠ è½½åŸºçº¿ç»“æ„"""
        if baseline_snapshot:
            snapshot_file = self.cache_dir / f"structure_snapshot_{baseline_snapshot}.json"
        else:
            # åŠ è½½æœ€æ–°çš„å¿«ç…§
            snapshot_files = list(self.cache_dir.glob("structure_snapshot_*.json"))
            if not snapshot_files:
                return None
            
            snapshot_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            snapshot_file = snapshot_files[0]
        
        try:
            with open(snapshot_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âš ï¸ åŠ è½½åŸºçº¿ç»“æ„å¤±è´¥: {e}")
            return None
    
    async def _compare_structures(self, current: Dict[str, Any], baseline: Optional[Dict[str, Any]]) -> StructureComparison:
        """å¯¹æ¯”ç»“æ„"""
        print("ğŸ”„ æ‰§è¡Œç»“æ„å¯¹æ¯”...")
        
        comparison = StructureComparison(
            timestamp=datetime.now().isoformat(),
            files_added=[],
            files_removed=[],
            files_modified=[],
            directories_added=[],
            directories_removed=[],
            structure_changes={},
            impact_analysis={},
            recommendations=[]
        )
        
        if not baseline:
            print("â„¹ï¸ æœªæ‰¾åˆ°åŸºçº¿ç»“æ„ï¼Œåˆ›å»ºåˆå§‹å¿«ç…§")
            return comparison
        
        current_files = set(current["files"].keys())
        baseline_files = set(baseline["files"].keys())
        
        # æ‰¾å‡ºæ–°å¢æ–‡ä»¶
        added_paths = current_files - baseline_files
        for path in added_paths:
            comparison.files_added.append(current["files"][path])
        
        # æ‰¾å‡ºåˆ é™¤æ–‡ä»¶
        removed_paths = baseline_files - current_files
        for path in removed_paths:
            comparison.files_removed.append(baseline["files"][path])
        
        # æ‰¾å‡ºä¿®æ”¹æ–‡ä»¶
        common_paths = current_files & baseline_files
        for path in common_paths:
            current_file = current["files"][path]
            baseline_file = baseline["files"][path]
            
            if current_file["file_hash"] != baseline_file["file_hash"]:
                comparison.files_modified.append((current_file, baseline_file))
        
        # ç›®å½•å˜åŒ–
        current_dirs = set(current["directories"])
        baseline_dirs = set(baseline["directories"])
        
        comparison.directories_added = list(current_dirs - baseline_dirs)
        comparison.directories_removed = list(baseline_dirs - current_dirs)
        
        # ç»“æ„å˜åŒ–ç»Ÿè®¡
        comparison.structure_changes = {
            "files_added_count": len(comparison.files_added),
            "files_removed_count": len(comparison.files_removed),
            "files_modified_count": len(comparison.files_modified),
            "directories_added_count": len(comparison.directories_added),
            "directories_removed_count": len(comparison.directories_removed),
            "total_files_before": len(baseline_files),
            "total_files_after": len(current_files)
        }
        
        return comparison
    
    async def _analyze_impact(self, comparison: StructureComparison) -> Dict[str, Any]:
        """åˆ†æå½±å“"""
        print("ğŸ“ˆ åˆ†æå˜åŒ–å½±å“...")
        
        impact = {
            "functional_impact": {},
            "performance_impact": {},
            "security_impact": {},
            "maintenance_impact": {},
            "dependency_impact": {},
            "overall_risk": "low"
        }
        
        # åŠŸèƒ½å½±å“åˆ†æ
        functional_score = 0
        for file in comparison.files_removed:
            functional_score += file.get("business_value", 0)
        
        for current_file, baseline_file in comparison.files_modified:
            # ç®€åŒ–çš„å½±å“è®¡ç®—
            functional_score += abs(current_file.get("functionality_score", 0) - baseline_file.get("functionality_score", 0))
        
        impact["functional_impact"] = {
            "score": functional_score,
            "level": "high" if functional_score > 0.5 else "medium" if functional_score > 0.2 else "low"
        }
        
        # æ€§èƒ½å½±å“åˆ†æ
        performance_impact = 0
        for file in comparison.files_added:
            if "engine" in file["name"].lower() or "cache" in file["name"].lower():
                performance_impact += 0.3
        
        impact["performance_impact"] = {
            "score": performance_impact,
            "level": "high" if performance_impact > 0.3 else "medium" if performance_impact > 0.1 else "low"
        }
        
        # å®‰å…¨å½±å“åˆ†æ
        security_impact = 0
        for file in comparison.files_removed:
            if file.get("risk_assessment") == "low":
                security_impact += 0.1
            elif file.get("risk_assessment") == "medium":
                security_impact += 0.2
            elif file.get("risk_assessment") == "high":
                security_impact += 0.3
        
        impact["security_impact"] = {
            "score": security_impact,
            "level": "high" if security_impact > 0.3 else "medium" if security_impact > 0.1 else "low"
        }
        
        # ç»´æŠ¤å½±å“åˆ†æ
        maintenance_impact = 0
        for file in comparison.files_added:
            maintenance_impact += file.get("maintenance_cost", 0)
        
        for current_file, baseline_file in comparison.files_modified:
            maintenance_impact += abs(current_file.get("maintenance_cost", 0) - baseline_file.get("maintenance_cost", 0))
        
        impact["maintenance_impact"] = {
            "score": maintenance_impact,
            "level": "high" if maintenance_impact > 0.5 else "medium" if maintenance_impact > 0.2 else "low"
        }
        
        # ä¾èµ–å½±å“åˆ†æ
        dependency_changes = len(comparison.files_added) + len(comparison.files_removed)
        impact["dependency_impact"] = {
            "score": dependency_changes * 0.1,
            "level": "high" if dependency_changes > 10 else "medium" if dependency_changes > 5 else "low"
        }
        
        # æ•´ä½“é£é™©è¯„ä¼°
        risk_scores = [
            impact["functional_impact"]["score"],
            impact["performance_impact"]["score"],
            impact["security_impact"]["score"],
            impact["maintenance_impact"]["score"],
            impact["dependency_impact"]["score"]
        ]
        
        total_risk = sum(risk_scores)
        if total_risk > 1.5:
            impact["overall_risk"] = "high"
        elif total_risk > 0.8:
            impact["overall_risk"] = "medium"
        else:
            impact["overall_risk"] = "low"
        
        return impact
    
    async def _generate_recommendations(self, comparison: StructureComparison) -> List[str]:
        """ç”Ÿæˆæ¨èå»ºè®®"""
        recommendations = []
        
        # åŸºäºæ–‡ä»¶å˜åŒ–çš„å»ºè®®
        if comparison.files_removed:
            high_value_removed = [f for f in comparison.files_removed if f.get("business_value", 0) > 0.5]
            if high_value_removed:
                recommendations.append(f"è­¦å‘Šï¼šåˆ é™¤äº†{len(high_value_removed)}ä¸ªé«˜ä»·å€¼æ–‡ä»¶ï¼Œå»ºè®®é‡æ–°è¯„ä¼°")
        
        if comparison.files_added:
            high_cost_added = [f for f in comparison.files_added if f.get("maintenance_cost", 0) > 0.7]
            if high_cost_added:
                recommendations.append(f"æ³¨æ„ï¼šæ–°å¢äº†{len(high_cost_added)}ä¸ªé«˜ç»´æŠ¤æˆæœ¬æ–‡ä»¶ï¼Œéœ€è¦å…³æ³¨")
        
        # åŸºäºå½±å“çš„å»ºè®®
        impact = comparison.impact_analysis
        
        if impact["functional_impact"]["level"] == "high":
            recommendations.append("åŠŸèƒ½å½±å“è¾ƒå¤§ï¼Œå»ºè®®è¿›è¡Œå›å½’æµ‹è¯•")
        
        if impact["security_impact"]["level"] == "high":
            recommendations.append("å®‰å…¨å½±å“è¾ƒå¤§ï¼Œå»ºè®®è¿›è¡Œå®‰å…¨å®¡è®¡")
        
        if impact["performance_impact"]["level"] == "high":
            recommendations.append("æ€§èƒ½å½±å“è¾ƒå¤§ï¼Œå»ºè®®è¿›è¡Œæ€§èƒ½æµ‹è¯•")
        
        if impact["maintenance_impact"]["level"] == "high":
            recommendations.append("ç»´æŠ¤æˆæœ¬å¢åŠ è¾ƒå¤šï¼Œå»ºè®®ä¼˜åŒ–ä»£ç ç»“æ„")
        
        # åŸºäºæ•´ä½“é£é™©çš„å»ºè®®
        if impact["overall_risk"] == "high":
            recommendations.append("æ•´ä½“é£é™©è¾ƒé«˜ï¼Œå»ºè®®åˆ†é˜¶æ®µéƒ¨ç½²")
        elif impact["overall_risk"] == "medium":
            recommendations.append("æ•´ä½“é£é™©ä¸­ç­‰ï¼Œå»ºè®®åŠ å¼ºç›‘æ§")
        
        # ç»“æ„ä¼˜åŒ–å»ºè®®
        if comparison.structure_changes["files_added_count"] > comparison.structure_changes["files_removed_count"] * 2:
            recommendations.append("æ–‡ä»¶å¢é•¿è¾ƒå¿«ï¼Œå»ºè®®æ£€æŸ¥æ˜¯å¦æœ‰å†—ä½™ä»£ç ")
        
        return recommendations
    
    async def _save_structure_snapshot(self, structure: Dict[str, Any]):
        """ä¿å­˜ç»“æ„å¿«ç…§"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        snapshot_file = self.cache_dir / f"structure_snapshot_{timestamp}.json"
        
        try:
            with open(snapshot_file, 'w', encoding='utf-8') as f:
                json.dump(structure, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“¸ ç»“æ„å¿«ç…§å·²ä¿å­˜: {snapshot_file}")
            
            # æ¸…ç†æ—§å¿«ç…§ï¼ˆä¿ç•™æœ€è¿‘10ä¸ªï¼‰
            snapshot_files = list(self.cache_dir.glob("structure_snapshot_*.json"))
            snapshot_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            
            for old_snapshot in snapshot_files[10:]:
                old_snapshot.unlink()
                
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ç»“æ„å¿«ç…§å¤±è´¥: {e}")
    
    async def generate_detailed_report(self, comparison: StructureComparison) -> str:
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        report = []
        report.append("# é¡¹ç›®ç»“æ„å¯¹æ¯”åˆ†ææŠ¥å‘Š")
        report.append(f"ç”Ÿæˆæ—¶é—´: {comparison.timestamp}")
        report.append("")
        
        # å˜åŒ–æ¦‚è§ˆ
        report.append("## ğŸ“Š å˜åŒ–æ¦‚è§ˆ")
        changes = comparison.structure_changes
        report.append(f"- æ–°å¢æ–‡ä»¶: {changes['files_added_count']}ä¸ª")
        report.append(f"- åˆ é™¤æ–‡ä»¶: {changes['files_removed_count']}ä¸ª")
        report.append(f"- ä¿®æ”¹æ–‡ä»¶: {changes['files_modified_count']}ä¸ª")
        report.append(f"- æ–°å¢ç›®å½•: {changes['directories_added_count']}ä¸ª")
        report.append(f"- åˆ é™¤ç›®å½•: {changes['directories_removed_count']}ä¸ª")
        report.append("")
        
        # æ–°å¢æ–‡ä»¶è¯¦æƒ…
        if comparison.files_added:
            report.append("## ğŸ“ æ–°å¢æ–‡ä»¶")
            for file in comparison.files_added:
                report.append(f"### {file['name']}")
                report.append(f"- è·¯å¾„: {file['path']}")
                report.append(f"- å¤§å°: {file['size']}å­—èŠ‚")
                report.append(f"- åŠŸèƒ½ä»·å€¼: {file.get('functionality_score', 0):.2f}")
                report.append(f"- ç»´æŠ¤æˆæœ¬: {file.get('maintenance_cost', 0):.2f}")
                report.append(f"- æ¨èæ“ä½œ: {file.get('retention_recommendation', 'unknown')}")
                report.append("")
        
        # åˆ é™¤æ–‡ä»¶è¯¦æƒ…
        if comparison.files_removed:
            report.append("## ğŸ—‘ï¸ åˆ é™¤æ–‡ä»¶")
            for file in comparison.files_removed:
                report.append(f"### {file['name']}")
                report.append(f"- è·¯å¾„: {file['path']}")
                report.append(f"- å¤§å°: {file['size']}å­—èŠ‚")
                report.append(f"- ä¸šåŠ¡ä»·å€¼: {file.get('business_value', 0):.2f}")
                report.append(f"- é£é™©è¯„ä¼°: {file.get('risk_assessment', 'unknown')}")
                report.append(f"- åˆ é™¤ç†ç”±: {file.get('deletion_justification', 'æœªæä¾›')}")
                report.append("")
        
        # å½±å“åˆ†æ
        report.append("## ğŸ“ˆ å½±å“åˆ†æ")
        impact = comparison.impact_analysis
        report.append(f"### åŠŸèƒ½å½±å“: {impact['functional_impact']['level']} ({impact['functional_impact']['score']:.2f})")
        report.append(f"### æ€§èƒ½å½±å“: {impact['performance_impact']['level']} ({impact['performance_impact']['score']:.2f})")
        report.append(f"### å®‰å…¨å½±å“: {impact['security_impact']['level']} ({impact['security_impact']['score']:.2f})")
        report.append(f"### ç»´æŠ¤å½±å“: {impact['maintenance_impact']['level']} ({impact['maintenance_impact']['score']:.2f})")
        report.append(f"### ä¾èµ–å½±å“: {impact['dependency_impact']['level']} ({impact['dependency_impact']['score']:.2f})")
        report.append(f"### æ•´ä½“é£é™©: {impact['overall_risk']}")
        report.append("")
        
        # æ¨èå»ºè®®
        if comparison.recommendations:
            report.append("## ğŸ’¡ æ¨èå»ºè®®")
            for i, rec in enumerate(comparison.recommendations, 1):
                report.append(f"{i}. {rec}")
            report.append("")
        
        return "\n".join(report)

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    """ä¸»å‡½æ•°"""
    project_root = "."
    
    analyzer = ProjectStructureAnalyzer(project_root)
    comparison = await analyzer.analyze_and_compare()
    
    # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    report = await analyzer.generate_detailed_report(comparison)
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = Path(project_root) / "structure_comparison_report.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"ğŸ“‹ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())