#!/usr/bin/env python3
"""
AIå¼ºåˆ¶ä¿¡æ¯ä¼ é€’ç³»ç»Ÿ
ç¡®ä¿AIå®Œå…¨ç†è§£é¡¹ç›®çŠ¶æ€å’Œæµ‹è¯•è¦æ±‚
"""

import json
import os
from pathlib import Path
from typing import Dict, Any, List
from datetime import datetime
import hashlib

class AIInformationForcer:
    """AIä¿¡æ¯å¼ºåˆ¶ä¼ é€’å™¨"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.ai_context_dir = self.project_root / ".iflow" / "temp_docs" / "ai_context"
        self.ai_context_dir.mkdir(parents=True, exist_ok=True)
        
    async def force_ai_awareness(self, test_results: Dict[str, Any] = None) -> Dict[str, Any]:
        """å¼ºåˆ¶AIä¿¡æ¯ä¼ é€’"""
        print("ğŸ¤– å¯åŠ¨AIå¼ºåˆ¶ä¿¡æ¯ä¼ é€’ç³»ç»Ÿ...")
        
        # 1. åˆ›å»ºå®Œæ•´é¡¹ç›®ä¸Šä¸‹æ–‡
        project_context = await self._create_project_context()
        
        # 2. åˆ›å»ºæµ‹è¯•è¦æ±‚ä¸Šä¸‹æ–‡
        test_requirements = await self._create_test_requirements()
        
        # 3. åˆ›å»ºå†³ç­–ä¾æ®ä¸Šä¸‹æ–‡
        decision_context = await self._create_decision_context()
        
        # 4. åˆ›å»ºåŠŸèƒ½åˆ†æä¸Šä¸‹æ–‡
        functionality_context = await self._create_functionality_context()
        
        # 5. ä¿å­˜æ‰€æœ‰ä¸Šä¸‹æ–‡
        context_files = await self._save_contexts({
            "project_context": project_context,
            "test_requirements": test_requirements,
            "decision_context": decision_context,
            "functionality_context": functionality_context
        })
        
        # 6. åˆ›å»ºå¼ºåˆ¶ä¼ é€’æŒ‡ä»¤
        force_commands = await self._create_force_commands(context_files)
        
        # 7. ç”ŸæˆAIç†è§£éªŒè¯
        verification = await self._create_ai_verification()
        
        print("âœ… AIå¼ºåˆ¶ä¿¡æ¯ä¼ é€’å®Œæˆ")
        print(f"ğŸ“ ä¸Šä¸‹æ–‡æ–‡ä»¶å·²ä¿å­˜åˆ°: {self.ai_context_dir}")
        
        return {
            "status": "success",
            "context_files": context_files,
            "force_commands": force_commands,
            "verification": verification
        }
    
    async def _create_project_context(self) -> Dict[str, Any]:
        """åˆ›å»ºé¡¹ç›®ä¸Šä¸‹æ–‡"""
        print("ğŸ“‹ åˆ›å»ºé¡¹ç›®ä¸Šä¸‹æ–‡...")
        
        context = {
            "project_name": "iFlow CLI V16 Quantum Evolution",
            "project_description": "ä¼ä¸šçº§æ™ºèƒ½CLIå·¥å…·ï¼Œé›†æˆARQå¼•æ“ã€HRRKå†…æ ¸ã€REFRAGç³»ç»Ÿç­‰æ ¸å¿ƒç»„ä»¶",
            "project_root": str(self.project_root),
            "timestamp": datetime.now().isoformat(),
            "project_structure": await self._get_project_structure(),
            "core_modules": await self._get_core_modules(),
            "dependencies": await self._get_dependencies(),
            "configuration": await self._get_configuration(),
            "recent_changes": await self._get_recent_changes(),
            "critical_files": await self._get_critical_files()
        }
        
        return context
    
    async def _create_test_requirements(self) -> Dict[str, Any]:
        """åˆ›å»ºæµ‹è¯•è¦æ±‚ä¸Šä¸‹æ–‡"""
        print("ğŸ§ª åˆ›å»ºæµ‹è¯•è¦æ±‚ä¸Šä¸‹æ–‡...")
        
        requirements = {
            "test_objectives": [
                {
                    "objective": "å…¨é¢æµ‹è¯•è¦†ç›–åˆ†æ",
                    "description": "ç¡®ä¿æ‰€æœ‰æ ¸å¿ƒæ¨¡å—éƒ½æœ‰å……åˆ†çš„æµ‹è¯•è¦†ç›–",
                    "success_criteria": "è¦†ç›–ç‡ >= 25%",
                    "priority": "high"
                },
                {
                    "objective": "æ·±åº¦ä»£ç è´¨é‡å®¡æŸ¥",
                    "description": "æ£€æŸ¥ä»£ç è´¨é‡ã€å¤æ‚åº¦ã€é‡å¤ä»£ç ç­‰é—®é¢˜",
                    "success_criteria": "æ— ä¸¥é‡ä»£ç è´¨é‡é—®é¢˜",
                    "priority": "high"
                },
                {
                    "objective": "å®‰å…¨æ€§æ¼æ´æ‰«æ",
                    "description": "è¯†åˆ«æ½œåœ¨çš„å®‰å…¨é£é™©å’Œæ¼æ´",
                    "success_criteria": "æ— é«˜å±å®‰å…¨é—®é¢˜",
                    "priority": "critical"
                },
                {
                    "objective": "æ€§èƒ½åŸºå‡†æµ‹è¯•",
                    "description": "è¯„ä¼°ç³»ç»Ÿæ€§èƒ½å’Œèµ„æºä½¿ç”¨æƒ…å†µ",
                    "success_criteria": "æ€§èƒ½æŒ‡æ ‡åœ¨å¯æ¥å—èŒƒå›´å†…",
                    "priority": "medium"
                },
                {
                    "objective": "é¡¹ç›®ç»“æ„ä¼˜åŒ–åˆ†æ",
                    "description": "åˆ†æé¡¹ç›®ç»“æ„åˆç†æ€§ï¼Œæå‡ºä¼˜åŒ–å»ºè®®",
                    "success_criteria": "ç»“æ„æ¸…æ™°ï¼Œæ— å†—ä½™æ–‡ä»¶",
                    "priority": "medium"
                }
            ],
            "mandatory_requirements": [
                "æ¯ä¸€æ­¥éƒ½å¿…é¡»æä¾›å®Œæ•´ä¾æ®å’Œè§£é‡Š",
                "æ‰€æœ‰æ–‡ä»¶å†³ç­–éƒ½éœ€è¦è¯¦ç»†æ¨ç†è¿‡ç¨‹",
                "åŠŸèƒ½ç‰¹ç‚¹å’Œä¼˜ç¼ºç‚¹å¿…é¡»æ˜ç¡®åˆ—å‡º",
                "åˆ é™¤æ–‡ä»¶å¿…é¡»æœ‰å……åˆ†ç†ç”±å’Œè¯æ®",
                "ä¿ç•™æ–‡ä»¶éœ€è¦è¯´æ˜å…¶ç‹¬ç‰¹ä»·å€¼å’Œä¸å¯æ›¿ä»£æ€§",
                "å¿…é¡»æä¾›è‡ªæˆ‘åçœå’Œæ¨ç†è¿‡ç¨‹",
                "å¿…é¡»å¯¹æ¯”åˆ†æåˆ é™¤å‰åçš„å½±å“"
            ],
            "decision_framework": {
                "file_retention_criteria": [
                    "æ ¸å¿ƒåŠŸèƒ½æ¨¡å—",
                    "æ— é‡å¤å®ç°",
                    "æ€§èƒ½å…³é”®è·¯å¾„",
                    "å®‰å…¨å…³é”®ç»„ä»¶",
                    "ç”¨æˆ·ç›´æ¥æ¥å£",
                    "é…ç½®å’Œè®¾ç½®æ–‡ä»¶",
                    "æ–‡æ¡£å’Œè¯´æ˜æ–‡ä»¶"
                ],
                "file_removal_criteria": [
                    "åŠŸèƒ½å®Œå…¨é‡å¤",
                    "æ— å®é™…ç”¨é€”",
                    "è¿‡æ—¶ç‰ˆæœ¬",
                    "æµ‹è¯•ç”¨ä¸´æ—¶æ–‡ä»¶",
                    "è°ƒè¯•ä»£ç ",
                    "å†—ä½™ä¾èµ–"
                ],
                "analysis_requirements": [
                    "åŠŸèƒ½å®Œæ•´æ€§åˆ†æ",
                    "æ€§èƒ½å½±å“è¯„ä¼°",
                    "ä¾èµ–å…³ç³»åˆ†æ",
                    "å®‰å…¨æ€§è¯„ä¼°",
                    "ç»´æŠ¤æˆæœ¬åˆ†æ",
                    "ç”¨æˆ·ä½“éªŒå½±å“"
                ]
            }
        }
        
        return requirements
    
    async def _create_decision_context(self) -> Dict[str, Any]:
        """åˆ›å»ºå†³ç­–ä¾æ®ä¸Šä¸‹æ–‡"""
        print("âš–ï¸ åˆ›å»ºå†³ç­–ä¾æ®ä¸Šä¸‹æ–‡...")
        
        context = {
            "decision_principles": [
                {
                    "principle": "è¯æ®é©±åŠ¨å†³ç­–",
                    "description": "æ‰€æœ‰å†³ç­–å¿…é¡»åŸºäºå…·ä½“çš„è¯æ®å’Œæ•°æ®",
                    "application": "æ–‡ä»¶åˆ†æã€æ€§èƒ½æµ‹è¯•ã€ç”¨æˆ·åé¦ˆ"
                },
                {
                    "principle": "å½±å“æœ€å°åŒ–",
                    "description": "ç¡®ä¿å†³ç­–å¯¹ç³»ç»Ÿçš„å½±å“æœ€å°åŒ–",
                    "application": "å‘åå…¼å®¹æ€§ã€APIç¨³å®šæ€§"
                },
                {
                    "principle": "ä»·å€¼æœ€å¤§åŒ–",
                    "description": "ç¡®ä¿æ¯ä¸ªç»„ä»¶éƒ½ä¸ºç”¨æˆ·æä¾›æœ€å¤§ä»·å€¼",
                    "application": "åŠŸèƒ½å¿…è¦æ€§ã€æ€§èƒ½æå‡"
                }
            ],
            "analysis_templates": {
                "file_analysis": {
                    "required_fields": [
                        "æ–‡ä»¶è·¯å¾„å’Œå¤§å°",
                        "æœ€åä¿®æ”¹æ—¶é—´",
                        "åŠŸèƒ½æè¿°",
                        "ä¾èµ–å…³ç³»",
                        "è°ƒç”¨å…³ç³»",
                        "æ€§èƒ½æŒ‡æ ‡",
                        "å®‰å…¨æ€§è¯„ä¼°",
                        "ç»´æŠ¤å¤æ‚åº¦"
                    ],
                    "decision_factors": [
                        "åŠŸèƒ½ç‹¬ç‰¹æ€§",
                        "æ€§èƒ½è´¡çŒ®",
                        "å®‰å…¨é‡è¦æ€§",
                        "ç”¨æˆ·ä½“éªŒå½±å“",
                        "ç»´æŠ¤æˆæœ¬",
                        "æœªæ¥å‘å±•è§„åˆ’"
                    ]
                },
                "retention_justification": {
                    "structure": [
                        "åŠŸèƒ½æ¦‚è¿°",
                        "ç‹¬ç‰¹ä»·å€¼åˆ†æ",
                        "æ›¿ä»£æ–¹æ¡ˆå¯¹æ¯”",
                        "åˆ é™¤å½±å“è¯„ä¼°",
                        "ä¿ç•™ç†ç”±æ€»ç»“"
                    ],
                    "evidence_required": [
                        "ä»£ç åˆ†æç»“æœ",
                        "æ€§èƒ½æµ‹è¯•æ•°æ®",
                        "ä¾èµ–å…³ç³»å›¾",
                        "ç”¨æˆ·ä½¿ç”¨ç»Ÿè®¡",
                        "å®‰å…¨è¯„ä¼°æŠ¥å‘Š"
                    ]
                }
            }
        }
        
        return context
    
    async def _create_functionality_context(self) -> Dict[str, Any]:
        """åˆ›å»ºåŠŸèƒ½åˆ†æä¸Šä¸‹æ–‡"""
        print("ğŸ” åˆ›å»ºåŠŸèƒ½åˆ†æä¸Šä¸‹æ–‡...")
        
        context = {
            "functionality_categories": {
                "core_engine": {
                    "description": "æ ¸å¿ƒå¼•æ“æ¨¡å—",
                    "examples": ["ARQå¼•æ“", "HRRKå†…æ ¸", "REFRAGç³»ç»Ÿ"],
                    "characteristics": ["é«˜æ€§èƒ½", "æ ¸å¿ƒåŠŸèƒ½", "å¤æ‚ç®—æ³•"],
                    "retention_priority": "critical",
                    "analysis_focus": ["æ€§èƒ½", "ç¨³å®šæ€§", "å®‰å…¨æ€§"]
                },
                "workflow_system": {
                    "description": "å·¥ä½œæµç³»ç»Ÿ",
                    "examples": ["å·¥ä½œæµå¼•æ“", "ä»»åŠ¡è°ƒåº¦å™¨", "çŠ¶æ€ç®¡ç†å™¨"],
                    "characteristics": ["æµç¨‹æ§åˆ¶", "çŠ¶æ€ç®¡ç†", "ä»»åŠ¡åè°ƒ"],
                    "retention_priority": "high",
                    "analysis_focus": ["å¯é æ€§", "æ‰©å±•æ€§", "æ˜“ç”¨æ€§"]
                },
                "knowledge_base": {
                    "description": "çŸ¥è¯†åº“ç³»ç»Ÿ",
                    "examples": ["çŸ¥è¯†åº“ç®¡ç†å™¨", "å‘é‡å­˜å‚¨", "æœç´¢å¼•æ“"],
                    "characteristics": ["æ•°æ®å­˜å‚¨", "æ£€ç´¢åŠŸèƒ½", "æ™ºèƒ½åˆ†æ"],
                    "retention_priority": "high",
                    "analysis_focus": ["æ•°æ®å®Œæ•´æ€§", "æ£€ç´¢æ•ˆç‡", "æ™ºèƒ½ç¨‹åº¦"]
                },
                "utility_modules": {
                    "description": "å·¥å…·æ¨¡å—",
                    "examples": ["ç¼“å­˜ç³»ç»Ÿ", "é”™è¯¯å¤„ç†å™¨", "æ—¥å¿—ç³»ç»Ÿ"],
                    "characteristics": ["è¾…åŠ©åŠŸèƒ½", "æ€§èƒ½ä¼˜åŒ–", "ç³»ç»Ÿæ”¯æŒ"],
                    "retention_priority": "medium",
                    "analysis_focus": ["æ€§èƒ½æå‡", "ç¨³å®šæ€§", "ç»´æŠ¤æˆæœ¬"]
                },
                "test_modules": {
                    "description": "æµ‹è¯•æ¨¡å—",
                    "examples": ["å•å…ƒæµ‹è¯•", "é›†æˆæµ‹è¯•", "æ€§èƒ½æµ‹è¯•"],
                    "characteristics": ["è´¨é‡ä¿è¯", "å›å½’æµ‹è¯•", "è‡ªåŠ¨åŒ–"],
                    "retention_priority": "medium",
                    "analysis_focus": ["è¦†ç›–ç‡", "æœ‰æ•ˆæ€§", "ç»´æŠ¤æ€§"]
                }
            },
            "analysis_checklist": {
                "functionality_assessment": [
                    "ä¸»è¦åŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ",
                    "è§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Ÿ",
                    "ç”¨æˆ·ä»·å€¼æ˜¯ä»€ä¹ˆï¼Ÿ",
                    "ä½¿ç”¨é¢‘ç‡å¦‚ä½•ï¼Ÿ",
                    "æ˜¯å¦æœ‰æ›¿ä»£æ–¹æ¡ˆï¼Ÿ"
                ],
                "technical_analysis": [
                    "ä»£ç å¤æ‚åº¦å¦‚ä½•ï¼Ÿ",
                    "æ€§èƒ½è¡¨ç°å¦‚ä½•ï¼Ÿ",
                    "ä¾èµ–å…³ç³»å¤æ‚å—ï¼Ÿ",
                    "å®‰å…¨æ€§å¦‚ä½•ï¼Ÿ",
                    "ç»´æŠ¤æˆæœ¬é«˜å—ï¼Ÿ"
                ],
                "business_value": [
                    "å¯¹ç”¨æˆ·çš„ä»·å€¼æ˜¯ä»€ä¹ˆï¼Ÿ",
                    "å¯¹ä¸šåŠ¡çš„é‡è¦æ€§å¦‚ä½•ï¼Ÿ",
                    "ç«äº‰ä¼˜åŠ¿åœ¨å“ªé‡Œï¼Ÿ",
                    "æœªæ¥å‘å±•æ½œåŠ›å¦‚ä½•ï¼Ÿ",
                    "é£é™©å½±å“ç¨‹åº¦å¦‚ä½•ï¼Ÿ"
                ]
            }
        }
        
        return context
    
    async def _get_project_structure(self) -> Dict[str, Any]:
        """è·å–é¡¹ç›®ç»“æ„"""
        structure = {
            "directories": {},
            "files": {},
            "statistics": {}
        }
        
        total_files = 0
        total_dirs = 0
        python_files = 0
        test_files = 0
        
        for root, dirs, files in os.walk(self.project_root):
            # è·³è¿‡éšè—ç›®å½•å’Œç¼“å­˜
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'node_modules']]
            
            rel_root = os.path.relpath(root, self.project_root)
            if rel_root == '.':
                rel_root = 'root'
            
            structure["directories"][rel_root] = dirs
            structure["files"][rel_root] = files
            
            total_dirs += len(dirs)
            total_files += len(files)
            
            for file in files:
                if file.endswith('.py'):
                    python_files += 1
                if 'test' in file.lower():
                    test_files += 1
        
        structure["statistics"] = {
            "total_files": total_files,
            "total_directories": total_dirs,
            "python_files": python_files,
            "test_files": test_files
        }
        
        return structure
    
    async def _get_core_modules(self) -> List[Dict[str, Any]]:
        """è·å–æ ¸å¿ƒæ¨¡å—ä¿¡æ¯"""
        core_dir = self.project_root / ".iflow" / "core"
        modules = []
        
        if core_dir.exists():
            for file_path in core_dir.glob("*.py"):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # ç®€å•åˆ†ææ¨¡å—
                    module_info = {
                        "name": file_path.stem,
                        "path": str(file_path.relative_to(self.project_root)),
                        "size": file_path.stat().st_size,
                        "functions": content.count('def '),
                        "classes": content.count('class '),
                        "imports": content.count('import'),
                        "description": self._extract_module_description(content)
                    }
                    
                    modules.append(module_info)
                    
                except Exception as e:
                    print(f"âš ï¸ åˆ†ææ¨¡å—å¤±è´¥ {file_path}: {e}")
        
        return modules
    
    def _extract_module_description(self, content: str) -> str:
        """æå–æ¨¡å—æè¿°"""
        lines = content.split('\n')
        for line in lines[:10]:  # åªæ£€æŸ¥å‰10è¡Œ
            if line.strip().startswith('"""') or line.strip().startswith("'''"):
                return "æœ‰æ–‡æ¡£å­—ç¬¦ä¸²çš„æ¨¡å—"
            elif 'engine' in line.lower():
                return "å¼•æ“ç›¸å…³æ¨¡å—"
            elif 'cache' in line.lower():
                return "ç¼“å­˜ç›¸å…³æ¨¡å—"
            elif 'security' in line.lower():
                return "å®‰å…¨ç›¸å…³æ¨¡å—"
            elif 'workflow' in line.lower():
                return "å·¥ä½œæµç›¸å…³æ¨¡å—"
        
        return "é€šç”¨åŠŸèƒ½æ¨¡å—"
    
    async def _get_dependencies(self) -> Dict[str, Any]:
        """è·å–ä¾èµ–ä¿¡æ¯"""
        dependencies = {
            "python_version": "3.10+",
            "core_libraries": [],
            "external_libraries": [],
            "dev_dependencies": []
        }
        
        # è¯»å–requirementsæ–‡ä»¶
        req_files = ["requirements.txt", "requirements-dev.txt", "pyproject.toml"]
        
        for req_file in req_files:
            file_path = self.project_root / req_file
            if file_path.exists():
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    if req_file == "pyproject.toml":
                        # è§£æpyproject.toml
                        pass  # ç®€åŒ–å¤„ç†
                    else:
                        # è§£ærequirementsæ–‡ä»¶
                        lines = content.split('\n')
                        for line in lines:
                            if line.strip() and not line.startswith('#'):
                                if 'dev' in req_file:
                                    dependencies["dev_dependencies"].append(line.strip())
                                else:
                                    dependencies["external_libraries"].append(line.strip())
                
                except Exception as e:
                    print(f"âš ï¸ è¯»å–ä¾èµ–æ–‡ä»¶å¤±è´¥ {req_file}: {e}")
        
        return dependencies
    
    async def _get_configuration(self) -> Dict[str, Any]:
        """è·å–é…ç½®ä¿¡æ¯"""
        config = {
            "project_config": {},
            "build_config": {},
            "test_config": {}
        }
        
        # è¯»å–é…ç½®æ–‡ä»¶
        config_files = ["pyproject.toml", "setup.cfg", "pytest.ini"]
        
        for config_file in config_files:
            file_path = self.project_root / config_file
            if file_path.exists():
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    config["project_config"][config_file] = {
                        "exists": True,
                        "size": len(content),
                        "last_modified": file_path.stat().st_mtime
                    }
                
                except Exception as e:
                    print(f"âš ï¸ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥ {config_file}: {e}")
        
        return config
    
    async def _get_recent_changes(self) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘å˜æ›´"""
        changes = []
        
        # è·å–æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶
        import time
        current_time = time.time()
        one_day_ago = current_time - 24 * 60 * 60
        
        for root, dirs, files in os.walk(self.project_root):
            # è·³è¿‡éšè—ç›®å½•
            dirs[:] = [d for d in dirs if not d.startswith('.')]
            
            for file in files:
                if file.endswith('.py'):
                    file_path = Path(root) / file
                    if file_path.stat().st_mtime > one_day_ago:
                        changes.append({
                            "file": str(file_path.relative_to(self.project_root)),
                            "modified_time": file_path.stat().st_mtime,
                            "size": file_path.stat().st_size
                        })
        
        return sorted(changes, key=lambda x: x["modified_time"], reverse=True)[:10]
    
    async def _get_critical_files(self) -> List[Dict[str, Any]]:
        """è·å–å…³é”®æ–‡ä»¶"""
        critical_patterns = [
            "*.py",
            "*.toml",
            "*.cfg",
            "*.ini",
            "*.md",
            "*.bat"
        ]
        
        critical_files = []
        
        for pattern in critical_patterns:
            for file_path in self.project_root.glob(pattern):
                if file_path.is_file():
                    critical_files.append({
                        "name": file_path.name,
                        "path": str(file_path.relative_to(self.project_root)),
                        "size": file_path.stat().st_size,
                        "type": file_path.suffix
                    })
        
        return critical_files[:50]  # é™åˆ¶æ•°é‡
    
    async def _save_contexts(self, contexts: Dict[str, Any]) -> Dict[str, str]:
        """ä¿å­˜ä¸Šä¸‹æ–‡æ–‡ä»¶"""
        saved_files = {}
        
        for context_name, context_data in contexts.items():
            file_path = self.ai_context_dir / f"{context_name}.json"
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(context_data, f, ensure_ascii=False, indent=2)
            
            saved_files[context_name] = str(file_path)
        
        return saved_files
    
    async def _create_force_commands(self, context_files: Dict[str, str]) -> List[str]:
        """åˆ›å»ºå¼ºåˆ¶ä¼ é€’æŒ‡ä»¤"""
        commands = []
        
        commands.append("# AIå¼ºåˆ¶ä¿¡æ¯ä¼ é€’æŒ‡ä»¤")
        commands.append("## å¿…é¡»æ‰§è¡Œçš„æ“ä½œ")
        commands.append("")
        commands.append("1. **ç«‹å³è¯»å–æ‰€æœ‰ä¸Šä¸‹æ–‡æ–‡ä»¶**:")
        for name, path in context_files.items():
            commands.append(f"   - `{path}`")
        
        commands.append("")
        commands.append("2. **å®Œå…¨ç†è§£é¡¹ç›®çŠ¶æ€**:")
        commands.append("   - é˜…è¯»é¡¹ç›®ä¸Šä¸‹æ–‡äº†è§£æ•´ä½“æ¶æ„")
        commands.append("   - ç†è§£æµ‹è¯•è¦æ±‚æ˜ç¡®åˆ†æç›®æ ‡")
        commands.append("   - æŒæ¡å†³ç­–æ¡†æ¶ç¡®ä¿åˆ†æè´¨é‡")
        commands.append("   - ç†Ÿæ‚‰åŠŸèƒ½åˆ†ç±»å‡†ç¡®è¯„ä¼°ä»·å€¼")
        
        commands.append("")
        commands.append("3. **ä¸¥æ ¼æ‰§è¡Œåˆ†ææ ‡å‡†**:")
        commands.append("   - æ¯ä¸ªæ–‡ä»¶å†³ç­–å¿…é¡»æä¾›å®Œæ•´ä¾æ®")
        commands.append("   - æ‰€æœ‰æ¨ç†è¿‡ç¨‹å¿…é¡»è¯¦ç»†è®°å½•")
        commands.append("   - åŠŸèƒ½ç‰¹ç‚¹åˆ†æå¿…é¡»å…¨é¢å®¢è§‚")
        commands.append("   - ä¿ç•™/åˆ é™¤å†³ç­–å¿…é¡»æœ‰å……åˆ†è¯æ®")
        
        commands.append("")
        commands.append("4. **è¾“å‡ºæ ¼å¼è¦æ±‚**:")
        commands.append("   - ä½¿ç”¨ç»“æ„åŒ–æŠ¥å‘Šæ ¼å¼")
        commands.append("   - åŒ…å«å®Œæ•´çš„æ¨ç†é“¾æ¡")
        commands.append("   - æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®")
        commands.append("   - æ ‡æ³¨æ‰€æœ‰æ•°æ®æ¥æº")
        
        return commands
    
    async def _create_ai_verification(self) -> Dict[str, Any]:
        """åˆ›å»ºAIç†è§£éªŒè¯"""
        verification = {
            "verification_questions": [
                "ä½ æ˜¯å¦å®Œå…¨ç†è§£é¡¹ç›®çš„æ•´ä½“æ¶æ„å’Œæ ¸å¿ƒåŠŸèƒ½ï¼Ÿ",
                "ä½ æ˜¯å¦æ¸…æ¥šæµ‹è¯•çš„å…·ä½“è¦æ±‚å’ŒæˆåŠŸæ ‡å‡†ï¼Ÿ",
                "ä½ æ˜¯å¦æŒæ¡äº†æ–‡ä»¶åˆ†æçš„å†³ç­–æ¡†æ¶ï¼Ÿ",
                "ä½ æ˜¯å¦äº†è§£åŠŸèƒ½åˆ†ç±»å’Œè¯„ä¼°æ ‡å‡†ï¼Ÿ"
            ],
            "understanding_check": {
                "project_name": "iFlow CLI V16 Quantum Evolution",
                "core_components": ["ARQå¼•æ“", "HRRKå†…æ ¸", "REFRAGç³»ç»Ÿ"],
                "test_objectives": ["æµ‹è¯•è¦†ç›–", "ä»£ç è´¨é‡", "å®‰å…¨æ‰«æ", "æ€§èƒ½æµ‹è¯•"],
                "decision_principles": ["è¯æ®é©±åŠ¨", "å½±å“æœ€å°åŒ–", "ä»·å€¼æœ€å¤§åŒ–"]
            },
            "quality_assurance": [
                "ç¡®ä¿æ‰€æœ‰åˆ†æéƒ½æœ‰å…·ä½“æ•°æ®æ”¯æ’‘",
                "ç¡®ä¿æ‰€æœ‰å†³ç­–éƒ½æœ‰è¯¦ç»†æ¨ç†è¿‡ç¨‹",
                "ç¡®ä¿æ‰€æœ‰å»ºè®®éƒ½æœ‰å¯è¡Œæ€§è¯„ä¼°",
                "ç¡®ä¿æ‰€æœ‰ç»“è®ºéƒ½æœ‰éªŒè¯æ–¹æ³•"
            ]
        }
        
        return verification

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    """ä¸»å‡½æ•°"""
    project_root = "."  # å½“å‰ç›®å½•
    
    forcer = AIInformationForcer(project_root)
    result = await forcer.force_ai_awareness()
    
    print("ğŸ¯ AIå¼ºåˆ¶ä¿¡æ¯ä¼ é€’ç»“æœ:")
    print(f"çŠ¶æ€: {result['status']}")
    print(f"ä¸Šä¸‹æ–‡æ–‡ä»¶: {len(result['context_files'])}ä¸ª")
    print(f"å¼ºåˆ¶æŒ‡ä»¤: {len(result['force_commands'])}æ¡")
    
    # ä¿å­˜å¼ºåˆ¶æŒ‡ä»¤åˆ°æ–‡ä»¶
    commands_file = Path(project_root) / ".iflow" / "temp_docs" / "ai_force_commands.md"
    with open(commands_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(result['force_commands']))
    
    print(f"ğŸ“ å¼ºåˆ¶æŒ‡ä»¤å·²ä¿å­˜åˆ°: {commands_file}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())