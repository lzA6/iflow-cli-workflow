#!/usr/bin/env python3
"""
è‡ªåŠ¨ä¼˜åŒ–æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ
åŸºäºé¡¹ç›®ç»“æ„æ ‘é€ä¸€æ’æŸ¥ï¼Œç”Ÿæˆå…¨é¢çš„ä¼˜åŒ–æŠ¥å‘Š
"""

import json
import os
import re
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
import asyncio
import subprocess

@dataclass
class OptimizationItem:
    """ä¼˜åŒ–é¡¹"""
    file_path: str
    issue_type: str
    severity: str
    description: str
    evidence: List[str]
    recommendation: str
    impact_assessment: str
    implementation_effort: str
    priority_score: float
    dependencies: List[str]

@dataclass
class FileAnalysisResult:
    """æ–‡ä»¶åˆ†æç»“æœ"""
    file_path: str
    file_size: int
    line_count: int
    function_count: int
    class_count: int
    import_count: int
    complexity_score: float
    maintainability_index: float
    duplication_ratio: float
    test_coverage: float
    security_issues: List[str]
    performance_issues: List[str]
    code_quality_issues: List[str]
    optimization_potential: float
    functionality_description: str
    advantages: List[str]
    disadvantages: List[str]
    retention_justification: str
    removal_justification: Optional[str]

class OptimizationReportGenerator:
    """ä¼˜åŒ–æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.reports_dir = self.project_root / "reports"
        self.reports_dir.mkdir(exist_ok=True)
        
    async def generate_comprehensive_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆä¼˜åŒ–æŠ¥å‘Š"""
        print("ğŸ“ˆ å¼€å§‹ç”Ÿæˆç»¼åˆä¼˜åŒ–æŠ¥å‘Š...")
        
        # 1. é¡¹ç›®ç»“æ„åˆ†æ
        print("ğŸ” åˆ†æé¡¹ç›®ç»“æ„...")
        structure_analysis = await self._analyze_project_structure()
        
        # 2. é€ä¸€æ–‡ä»¶åˆ†æ
        print("ğŸ“ é€ä¸€åˆ†ææ–‡ä»¶...")
        file_analyses = await self._analyze_all_files(structure_analysis)
        
        # 3. é—®é¢˜åˆ†ç±»å’Œä¼˜å…ˆçº§æ’åº
        print("ğŸ·ï¸ åˆ†ç±»é—®é¢˜å’Œæ’åºä¼˜å…ˆçº§...")
        optimization_items = await self._classify_and_prioritize_issues(file_analyses)
        
        # 4. ç”Ÿæˆä¼˜åŒ–ç­–ç•¥
        print("ğŸ’¡ ç”Ÿæˆä¼˜åŒ–ç­–ç•¥...")
        optimization_strategies = await self._generate_optimization_strategies(optimization_items)
        
        # 5. å½±å“è¯„ä¼°
        print("ğŸ“Š è¯„ä¼°ä¼˜åŒ–å½±å“...")
        impact_assessment = await self._assess_optimization_impact(optimization_items)
        
        # 6. å®æ–½è®¡åˆ’
        print("ğŸ“‹ åˆ¶å®šå®æ–½è®¡åˆ’...")
        implementation_plan = await self._create_implementation_plan(optimization_items)
        
        # 7. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        print("ğŸ“ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
        final_report = await self._create_final_report(
            structure_analysis, file_analyses, optimization_items,
            optimization_strategies, impact_assessment, implementation_plan
        )
        
        # 8. ä¿å­˜æŠ¥å‘Š
        await self._save_report(final_report)
        
        print("âœ… ç»¼åˆä¼˜åŒ–æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        return final_report
    
    async def _analyze_project_structure(self) -> Dict[str, Any]:
        """åˆ†æé¡¹ç›®ç»“æ„"""
        structure = {
            "total_files": 0,
            "python_files": 0,
            "test_files": 0,
            "config_files": 0,
            "doc_files": 0,
            "directories": [],
            "file_tree": {},
            "size_distribution": {},
            "complexity_distribution": {}
        }
        
        file_sizes = []
        complexity_scores = []
        
        for root, dirs, files in os.walk(self.project_root):
            # è·³è¿‡éšè—ç›®å½•å’Œç¼“å­˜
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'node_modules']]
            
            rel_root = os.path.relpath(root, self.project_root)
            if rel_root == '.':
                rel_root = 'root'
            
            structure["directories"].append(rel_root)
            structure["file_tree"][rel_root] = files
            
            for file in files:
                if not file.startswith('.'):
                    file_path = Path(root) / file
                    structure["total_files"] += 1
                    
                    if file.endswith('.py'):
                        structure["python_files"] += 1
                    elif 'test' in file.lower():
                        structure["test_files"] += 1
                    elif file in ['pyproject.toml', 'setup.cfg', 'requirements.txt']:
                        structure["config_files"] += 1
                    elif file.endswith('.md'):
                        structure["doc_files"] += 1
                    
                    # æ”¶é›†æ–‡ä»¶å¤§å°
                    if file_path.exists():
                        size = file_path.stat().st_size
                        file_sizes.append(size)
                        
                        # ç®€å•å¤æ‚åº¦è¯„ä¼°
                        if file.endswith('.py'):
                            try:
                                with open(file_path, 'r', encoding='utf-8') as f:
                                    content = f.read()
                                complexity = len(content.split('\n')) + content.count('def ') * 2 + content.count('class ') * 3
                                complexity_scores.append(complexity)
                            except:
                                pass
        
        # è®¡ç®—åˆ†å¸ƒ
        if file_sizes:
            structure["size_distribution"] = {
                "min": min(file_sizes),
                "max": max(file_sizes),
                "avg": sum(file_sizes) / len(file_sizes),
                "median": sorted(file_sizes)[len(file_sizes)//2]
            }
        
        if complexity_scores:
            structure["complexity_distribution"] = {
                "min": min(complexity_scores),
                "max": max(complexity_scores),
                "avg": sum(complexity_scores) / len(complexity_scores),
                "median": sorted(complexity_scores)[len(complexity_scores)//2]
            }
        
        return structure
    
    async def _analyze_all_files(self, structure_analysis: Dict[str, Any]) -> List[FileAnalysisResult]:
        """é€ä¸€åˆ†ææ‰€æœ‰æ–‡ä»¶"""
        file_analyses = []
        
        for root, dirs, files in os.walk(self.project_root):
            # è·³è¿‡éšè—ç›®å½•å’Œç¼“å­˜
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'node_modules']]
            
            for file in files:
                if file.endswith('.py') and not file.startswith('.'):
                    file_path = Path(root) / file
                    rel_path = str(file_path.relative_to(self.project_root))
                    
                    try:
                        analysis = await self._analyze_single_file(file_path)
                        file_analyses.append(analysis)
                    except Exception as e:
                        print(f"âš ï¸ åˆ†ææ–‡ä»¶å¤±è´¥ {rel_path}: {e}")
        
        return file_analyses
    
    async def _analyze_single_file(self, file_path: Path) -> FileAnalysisResult:
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.split('\n')
            
            # åŸºæœ¬ç»Ÿè®¡
            line_count = len(lines)
            function_count = content.count('def ')
            class_count = content.count('class ')
            import_count = content.count('import')
            file_size = file_path.stat().st_size
            
            # å¤æ‚åº¦åˆ†æ
            complexity_score = await self._calculate_complexity(content)
            maintainability_index = await self._calculate_maintainability_index(content)
            
            # é‡å¤ä»£ç åˆ†æ
            duplication_ratio = await self._analyze_duplication(content)
            
            # æµ‹è¯•è¦†ç›–ç‡ï¼ˆç®€åŒ–ï¼‰
            test_coverage = await self._estimate_test_coverage(file_path)
            
            # é—®é¢˜æ£€æµ‹
            security_issues = await self._detect_security_issues(content)
            performance_issues = await self._detect_performance_issues(content)
            code_quality_issues = await self._detect_code_quality_issues(content)
            
            # ä¼˜åŒ–æ½œåŠ›
            optimization_potential = await self._calculate_optimization_potential(
                security_issues, performance_issues, code_quality_issues
            )
            
            # åŠŸèƒ½åˆ†æ
            functionality_description = await self._analyze_functionality(content, file_path.name)
            advantages, disadvantages = await self._analyze_advantages_disadvantages(content, file_path.name)
            
            # ä¿ç•™/åˆ é™¤ç†ç”±
            retention_justification = await self._generate_retention_justification(
                functionality_description, advantages, disadvantages
            )
            removal_justification = await self._generate_removal_justification(
                functionality_description, disadvantages, security_issues
            )
            
            return FileAnalysisResult(
                file_path=str(file_path.relative_to(self.project_root)),
                file_size=file_size,
                line_count=line_count,
                function_count=function_count,
                class_count=class_count,
                import_count=import_count,
                complexity_score=complexity_score,
                maintainability_index=maintainability_index,
                duplication_ratio=duplication_ratio,
                test_coverage=test_coverage,
                security_issues=security_issues,
                performance_issues=performance_issues,
                code_quality_issues=code_quality_issues,
                optimization_potential=optimization_potential,
                functionality_description=functionality_description,
                advantages=advantages,
                disadvantages=disadvantages,
                retention_justification=retention_justification,
                removal_justification=removal_justification
            )
            
        except Exception as e:
            print(f"âš ï¸ æ–‡ä»¶åˆ†æé”™è¯¯ {file_path}: {e}")
            # è¿”å›é»˜è®¤åˆ†æç»“æœ
            return FileAnalysisResult(
                file_path=str(file_path.relative_to(self.project_root)),
                file_size=0,
                line_count=0,
                function_count=0,
                class_count=0,
                import_count=0,
                complexity_score=0.0,
                maintainability_index=0.0,
                duplication_ratio=0.0,
                test_coverage=0.0,
                security_issues=[f"åˆ†æé”™è¯¯: {e}"],
                performance_issues=[],
                code_quality_issues=[],
                optimization_potential=0.0,
                functionality_description="åˆ†æå¤±è´¥",
                advantages=[],
                disadvantages=[f"æ— æ³•åˆ†ææ–‡ä»¶: {e}"],
                retention_justification="éœ€è¦æ‰‹åŠ¨å®¡æŸ¥",
                removal_justification=None
            )
    
    async def _calculate_complexity(self, content: str) -> float:
        """è®¡ç®—å¤æ‚åº¦"""
        complexity = 1.0  # åŸºç¡€å¤æ‚åº¦
        
        # åŸºäºä»£ç ç»“æ„
        complexity += content.count('if ') * 0.5
        complexity += content.count('for ') * 0.5
        complexity += content.count('while ') * 0.5
        complexity += content.count('def ') * 0.3
        complexity += content.count('class ') * 0.5
        complexity += content.count('try:') * 0.3
        complexity += content.count('except ') * 0.3
        
        # åŸºäºåµŒå¥—
        max_indent = 0
        for line in content.split('\n'):
            if line.strip():
                indent = len(line) - len(line.lstrip())
                max_indent = max(max_indent, indent)
        
        complexity += max_indent * 0.1
        
        return complexity
    
    async def _calculate_maintainability_index(self, content: str) -> float:
        """è®¡ç®—å¯ç»´æŠ¤æ€§æŒ‡æ•°"""
        lines = len([line for line in content.split('\n') if line.strip()])
        
        # ç®€åŒ–çš„å¯ç»´æŠ¤æ€§æŒ‡æ•°è®¡ç®—
        base_score = 100.0
        
        # ä»£ç é‡å½±å“
        if lines > 1000:
            base_score -= 20
        elif lines > 500:
            base_score -= 10
        elif lines > 200:
            base_score -= 5
        
        # å¤æ‚åº¦å½±å“
        complexity = await self._calculate_complexity(content)
        base_score -= complexity * 2
        
        # æ³¨é‡Šå½±å“ï¼ˆæ­£é¢ï¼‰
        comment_lines = content.count('#')
        comment_ratio = comment_lines / max(lines, 1)
        base_score += comment_ratio * 10
        
        return max(0, min(100, base_score))
    
    async def _analyze_duplication(self, content: str) -> float:
        """åˆ†æä»£ç é‡å¤ç‡"""
        lines = [line.strip() for line in content.split('\n') if line.strip() and len(line.strip()) > 10]
        
        if len(lines) < 10:
            return 0.0
        
        # ç®€å•çš„é‡å¤æ£€æµ‹
        unique_lines = set(lines)
        duplication_ratio = 1.0 - (len(unique_lines) / len(lines))
        
        return duplication_ratio
    
    async def _estimate_test_coverage(self, file_path: Path) -> float:
        """ä¼°ç®—æµ‹è¯•è¦†ç›–ç‡"""
        # ç®€åŒ–çš„æµ‹è¯•è¦†ç›–ç‡ä¼°ç®—
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„æµ‹è¯•æ–‡ä»¶
        test_patterns = [
            f"test_{file_path.stem}.py",
            f"{file_path.stem}_test.py",
            f"tests/test_{file_path.stem}.py"
        ]
        
        for pattern in test_patterns:
            test_file = file_path.parent / pattern
            if test_file.exists():
                return 0.8  # å‡è®¾æœ‰æµ‹è¯•æ–‡ä»¶å°±æœ‰80%è¦†ç›–ç‡
        
        # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ…å«test
        if 'test' in file_path.name.lower():
            return 0.9  # æµ‹è¯•æ–‡ä»¶æœ¬èº«è¦†ç›–ç‡å¾ˆé«˜
        
        return 0.3  # é»˜è®¤è¦†ç›–ç‡è¾ƒä½
    
    async def _detect_security_issues(self, content: str) -> List[str]:
        """æ£€æµ‹å®‰å…¨é—®é¢˜"""
        issues = []
        
        # å±é™©å‡½æ•°
        dangerous_functions = ['eval(', 'exec(', 'compile(']
        for func in dangerous_functions:
            if func in content:
                issues.append(f"ä½¿ç”¨äº†å±é™©å‡½æ•°: {func}")
        
        # ç¡¬ç¼–ç å¯†ç 
        if re.search(r'password\s*=\s*["\'][^"\']+["\']', content, re.IGNORECASE):
            issues.append("å¯èƒ½å­˜åœ¨ç¡¬ç¼–ç å¯†ç ")
        
        # SQLæ³¨å…¥é£é™©
        if 'execute(' in content and '%' in content:
            issues.append("å¯èƒ½å­˜åœ¨SQLæ³¨å…¥é£é™©")
        
        # æ–‡ä»¶è·¯å¾„éå†
        if '../' in content:
            issues.append("å¯èƒ½å­˜åœ¨è·¯å¾„éå†é£é™©")
        
        return issues
    
    async def _detect_performance_issues(self, content: str) -> List[str]:
        """æ£€æµ‹æ€§èƒ½é—®é¢˜"""
        issues = []
        
        # å¾ªç¯ä¸­çš„æ•°æ®åº“æŸ¥è¯¢
        if re.search(r'for.*in.*:.*\.query\(', content):
            issues.append("å¾ªç¯ä¸­å¯èƒ½å­˜åœ¨æ•°æ®åº“æŸ¥è¯¢")
        
        # å¤§æ–‡ä»¶ä¸€æ¬¡æ€§è¯»å–
        if 'file.read()' in content and 'with open' in content:
            issues.append("å¯èƒ½å­˜åœ¨å¤§æ–‡ä»¶ä¸€æ¬¡æ€§è¯»å–")
        
        # ä½æ•ˆå­—ç¬¦ä¸²æ“ä½œ
        if content.count('+') > 50 and 'str' in content:
            issues.append("å¯èƒ½å­˜åœ¨ä½æ•ˆå­—ç¬¦ä¸²æ“ä½œ")
        
        # æœªä½¿ç”¨ç¼“å­˜
        if 'database' in content.lower() and 'cache' not in content.lower():
            issues.append("æ•°æ®åº“æ“ä½œæœªä½¿ç”¨ç¼“å­˜")
        
        return issues
    
    async def _detect_code_quality_issues(self, content: str) -> List[str]:
        """æ£€æµ‹ä»£ç è´¨é‡é—®é¢˜"""
        issues = []
        
        lines = content.split('\n')
        
        for i, line in enumerate(lines, 1):
            # è¡Œé•¿åº¦
            if len(line) > 120:
                issues.append(f"ç¬¬{i}è¡Œè¿‡é•¿ ({len(line)}å­—ç¬¦)")
            
            # TODOæ³¨é‡Š
            if 'TODO' in line or 'FIXME' in line:
                issues.append(f"ç¬¬{i}è¡Œæœ‰å¾…åŠäº‹é¡¹")
            
            # è°ƒè¯•ä»£ç 
            if 'print(' in line and 'debug' not in line.lower():
                issues.append(f"ç¬¬{i}è¡Œå¯èƒ½æœ‰è°ƒè¯•ä»£ç ")
            
            # ç©ºå‡½æ•°/ç±»
            if 'def ' in line and 'pass' in line:
                issues.append(f"ç¬¬{i}è¡Œæœ‰ç©ºå‡½æ•°")
        
        return issues
    
    async def _calculate_optimization_potential(self, security_issues: List[str], 
                                               performance_issues: List[str], 
                                               code_quality_issues: List[str]) -> float:
        """è®¡ç®—ä¼˜åŒ–æ½œåŠ›"""
        potential = 0.0
        
        # å®‰å…¨é—®é¢˜æƒé‡é«˜
        potential += len(security_issues) * 0.3
        
        # æ€§èƒ½é—®é¢˜æƒé‡ä¸­ç­‰
        potential += len(performance_issues) * 0.2
        
        # ä»£ç è´¨é‡é—®é¢˜æƒé‡ä½
        potential += len(code_quality_issues) * 0.1
        
        return min(potential, 1.0)
    
    async def _analyze_functionality(self, content: str, filename: str) -> str:
        """åˆ†æåŠŸèƒ½æè¿°"""
        # åŸºäºæ–‡ä»¶åå’Œå†…å®¹åˆ†æåŠŸèƒ½
        if 'engine' in filename.lower():
            return "æ ¸å¿ƒå¼•æ“æ¨¡å—ï¼Œè´Ÿè´£ç³»ç»Ÿçš„ä¸»è¦åŠŸèƒ½å®ç°"
        elif 'cache' in filename.lower():
            return "ç¼“å­˜ç³»ç»Ÿæ¨¡å—ï¼Œæä¾›æ•°æ®ç¼“å­˜å’Œæ€§èƒ½ä¼˜åŒ–åŠŸèƒ½"
        elif 'security' in filename.lower():
            return "å®‰å…¨æ¨¡å—ï¼Œè´Ÿè´£ç³»ç»Ÿå®‰å…¨é˜²æŠ¤å’Œæƒé™æ§åˆ¶"
        elif 'test' in filename.lower():
            return "æµ‹è¯•æ¨¡å—ï¼Œç¡®ä¿ç³»ç»ŸåŠŸèƒ½æ­£ç¡®æ€§å’Œç¨³å®šæ€§"
        elif 'workflow' in filename.lower():
            return "å·¥ä½œæµæ¨¡å—ï¼Œç®¡ç†å’Œåè°ƒä¸šåŠ¡æµç¨‹"
        elif 'api' in filename.lower():
            return "APIæ¥å£æ¨¡å—ï¼Œæä¾›å¤–éƒ¨æ¥å£æœåŠ¡"
        elif 'util' in filename.lower():
            return "å·¥å…·æ¨¡å—ï¼Œæä¾›é€šç”¨å·¥å…·å’Œè¾…åŠ©åŠŸèƒ½"
        elif 'config' in filename.lower():
            return "é…ç½®æ¨¡å—ï¼Œç®¡ç†ç³»ç»Ÿé…ç½®å’Œå‚æ•°"
        else:
            return "é€šç”¨åŠŸèƒ½æ¨¡å—ï¼Œæä¾›ç‰¹å®šçš„ä¸šåŠ¡åŠŸèƒ½"
    
    async def _analyze_advantages_disadvantages(self, content: str, filename: str) -> Tuple[List[str], List[str]]:
        """åˆ†æä¼˜ç¼ºç‚¹"""
        advantages = []
        disadvantages = []
        
        # åŸºäºæ–‡ä»¶ç±»å‹åˆ†æ
        if 'engine' in filename.lower():
            advantages.append("æ ¸å¿ƒåŠŸèƒ½å®ç°")
            advantages.append("é«˜æ€§èƒ½å¤„ç†")
            disadvantages.append("å¤æ‚åº¦é«˜")
            disadvantages.append("ç»´æŠ¤æˆæœ¬é«˜")
        
        elif 'cache' in filename.lower():
            advantages.append("æå‡æ€§èƒ½")
            advantages.append("å‡å°‘é‡å¤è®¡ç®—")
            disadvantages.append("å†…å­˜å ç”¨")
            disadvantages.append("æ•°æ®ä¸€è‡´æ€§æŒ‘æˆ˜")
        
        elif 'test' in filename.lower():
            advantages.append("ä¿è¯ä»£ç è´¨é‡")
            advantages.append("é˜²æ­¢å›å½’é”™è¯¯")
            disadvantages.append("éœ€è¦ç»´æŠ¤")
            disadvantages.append("æ‰§è¡Œæ—¶é—´å¼€é”€")
        
        # åŸºäºå†…å®¹åˆ†æ
        if 'class' in content:
            advantages.append("é¢å‘å¯¹è±¡è®¾è®¡")
        
        if 'async def' in content:
            advantages.append("å¼‚æ­¥å¤„ç†èƒ½åŠ›")
            disadvantages.append("è°ƒè¯•å¤æ‚åº¦å¢åŠ ")
        
        if len(content) > 1000:
            disadvantages.append("ä»£ç é‡è¾ƒå¤§")
        
        if 'import' in content:
            advantages.append("æ¨¡å—åŒ–è®¾è®¡")
            disadvantages.append("å¤–éƒ¨ä¾èµ–")
        
        return advantages, disadvantages
    
    async def _generate_retention_justification(self, functionality: str, 
                                              advantages: List[str], 
                                              disadvantages: List[str]) -> str:
        """ç”Ÿæˆä¿ç•™ç†ç”±"""
        justification = f"åŠŸèƒ½æè¿°ï¼š{functionality}\n\n"
        
        if advantages:
            justification += "ä¼˜åŠ¿ï¼š\n"
            for advantage in advantages:
                justification += f"- {advantage}\n"
        
        if disadvantages:
            justification += "\nåŠ£åŠ¿ï¼š\n"
            for disadvantage in disadvantages:
                justification += f"- {disadvantage}\n"
        
        justification += f"\nä¿ç•™ç†ç”±ï¼šè¯¥æ¨¡å—æä¾›äº†{functionality}ï¼Œ"
        
        if len(advantages) > len(disadvantages):
            justification += "ä¼˜åŠ¿å¤§äºåŠ£åŠ¿ï¼Œå¯¹ç³»ç»Ÿæœ‰é‡è¦ä»·å€¼ã€‚"
        else:
            justification += "è™½ç„¶æœ‰ä¸è¶³ï¼Œä½†åŠŸèƒ½ä¸å¯æ›¿ä»£ï¼Œéœ€è¦ä¿ç•™ã€‚"
        
        return justification
    
    async def _generate_removal_justification(self, functionality: str, 
                                            disadvantages: List[str], 
                                            security_issues: List[str]) -> Optional[str]:
        """ç”Ÿæˆåˆ é™¤ç†ç”±"""
        if not security_issues and len(disadvantages) < 3:
            return None
        
        justification = f"åˆ é™¤ç†ç”±ï¼šè¯¥æ¨¡å—({functionality})"
        
        if security_issues:
            justification += f"å­˜åœ¨{len(security_issues)}ä¸ªå®‰å…¨é—®é¢˜ï¼Œ"
        
        if len(disadvantages) > 2:
            justification += f"æœ‰{len(disadvantages)}ä¸ªä¸»è¦ç¼ºç‚¹ï¼Œ"
        
        justification += "ç»´æŠ¤æˆæœ¬é«˜ä¸”åŠŸèƒ½å¯è¢«æ›¿ä»£ã€‚"
        
        return justification
    
    async def _classify_and_prioritize_issues(self, file_analyses: List[FileAnalysisResult]) -> List[OptimizationItem]:
        """åˆ†ç±»å’Œä¼˜å…ˆçº§æ’åºé—®é¢˜"""
        optimization_items = []
        
        for analysis in file_analyses:
            # å®‰å…¨é—®é¢˜
            for issue in analysis.security_issues:
                item = OptimizationItem(
                    file_path=analysis.file_path,
                    issue_type="security",
                    severity="high",
                    description=issue,
                    evidence=[f"æ–‡ä»¶: {analysis.file_path}"],
                    recommendation="ç«‹å³ä¿®å¤å®‰å…¨é—®é¢˜",
                    impact_assessment="é«˜",
                    implementation_effort="ä¸­ç­‰",
                    priority_score=0.9,
                    dependencies=[]
                )
                optimization_items.append(item)
            
            # æ€§èƒ½é—®é¢˜
            for issue in analysis.performance_issues:
                item = OptimizationItem(
                    file_path=analysis.file_path,
                    issue_type="performance",
                    severity="medium",
                    description=issue,
                    evidence=[f"æ–‡ä»¶: {analysis.file_path}"],
                    recommendation="ä¼˜åŒ–æ€§èƒ½ç“¶é¢ˆ",
                    impact_assessment="ä¸­ç­‰",
                    implementation_effort="ä¸­ç­‰",
                    priority_score=0.7,
                    dependencies=[]
                )
                optimization_items.append(item)
            
            # ä»£ç è´¨é‡é—®é¢˜
            for issue in analysis.code_quality_issues:
                item = OptimizationItem(
                    file_path=analysis.file_path,
                    issue_type="code_quality",
                    severity="low",
                    description=issue,
                    evidence=[f"æ–‡ä»¶: {analysis.file_path}"],
                    recommendation="æ”¹è¿›ä»£ç è´¨é‡",
                    impact_assessment="ä½",
                    implementation_effort="ä½",
                    priority_score=0.5,
                    dependencies=[]
                )
                optimization_items.append(item)
            
            # æ–‡ä»¶çº§åˆ«ä¼˜åŒ–å»ºè®®
            if analysis.optimization_potential > 0.5:
                item = OptimizationItem(
                    file_path=analysis.file_path,
                    issue_type="file_optimization",
                    severity="medium",
                    description=f"æ–‡ä»¶ä¼˜åŒ–æ½œåŠ›: {analysis.optimization_potential:.2f}",
                    evidence=[
                        f"å¤æ‚åº¦: {analysis.complexity_score:.2f}",
                        f"å¯ç»´æŠ¤æ€§: {analysis.maintainability_index:.2f}",
                        f"é‡å¤ç‡: {analysis.duplication_ratio:.2f}"
                    ],
                    recommendation="é‡æ„æ–‡ä»¶ä»¥æå‡è´¨é‡",
                    impact_assessment="ä¸­ç­‰",
                    implementation_effort="é«˜",
                    priority_score=analysis.optimization_potential,
                    dependencies=[]
                )
                optimization_items.append(item)
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        optimization_items.sort(key=lambda x: x.priority_score, reverse=True)
        
        return optimization_items
    
    async def _generate_optimization_strategies(self, optimization_items: List[OptimizationItem]) -> Dict[str, Any]:
        """ç”Ÿæˆä¼˜åŒ–ç­–ç•¥"""
        strategies = {
            "immediate_actions": [],
            "short_term_goals": [],
            "long_term_plans": [],
            "resource_requirements": {},
            "risk_mitigation": []
        }
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç±»
        high_priority = [item for item in optimization_items if item.severity == "high"]
        medium_priority = [item for item in optimization_items if item.severity == "medium"]
        low_priority = [item for item in optimization_items if item.severity == "low"]
        
        # ç«‹å³è¡ŒåŠ¨é¡¹
        if high_priority:
            strategies["immediate_actions"].append({
                "action": "ä¿®å¤æ‰€æœ‰é«˜ä¸¥é‡æ€§é—®é¢˜",
                "items_count": len(high_priority),
                "estimated_effort": "é«˜",
                "impact": "æ˜¾è‘—æå‡ç³»ç»Ÿå®‰å…¨æ€§å’Œç¨³å®šæ€§"
            })
        
        # çŸ­æœŸç›®æ ‡
        if medium_priority:
            strategies["short_term_goals"].append({
                "goal": "ä¼˜åŒ–æ€§èƒ½å’Œä»£ç è´¨é‡",
                "items_count": len(medium_priority),
                "estimated_effort": "ä¸­ç­‰",
                "impact": "æå‡ç³»ç»Ÿæ€§èƒ½å’Œå¯ç»´æŠ¤æ€§"
            })
        
        # é•¿æœŸè®¡åˆ’
        if low_priority:
            strategies["long_term_plans"].append({
                "plan": "æŒç»­æ”¹è¿›å’Œé‡æ„",
                "items_count": len(low_priority),
                "estimated_effort": "æŒç»­",
                "impact": "ä¿æŒä»£ç è´¨é‡å’ŒæŠ€æœ¯å€ºåŠ¡æ§åˆ¶"
            })
        
        # èµ„æºéœ€æ±‚
        total_items = len(optimization_items)
        strategies["resource_requirements"] = {
            "developer_days": total_items * 0.5,  # ä¼°ç®—
            "testing_days": total_items * 0.2,
            "review_days": total_items * 0.1
        }
        
        # é£é™©ç¼“è§£
        strategies["risk_mitigation"] = [
            "åˆ†é˜¶æ®µå®æ–½ï¼Œé™ä½é£é™©",
            "å……åˆ†æµ‹è¯•ï¼Œç¡®ä¿åŠŸèƒ½æ­£å¸¸",
            "å¤‡ä»½ä»£ç ï¼Œæ”¯æŒå¿«é€Ÿå›æ»š",
            "å›¢é˜Ÿåä½œï¼Œäº¤å‰å®¡æŸ¥"
        ]
        
        return strategies
    
    async def _assess_optimization_impact(self, optimization_items: List[OptimizationItem]) -> Dict[str, Any]:
        """è¯„ä¼°ä¼˜åŒ–å½±å“"""
        impact = {
            "security_improvement": 0,
            "performance_improvement": 0,
            "code_quality_improvement": 0,
            "maintainability_improvement": 0,
            "overall_benefit": 0
        }
        
        for item in optimization_items:
            if item.issue_type == "security":
                impact["security_improvement"] += item.priority_score
            elif item.issue_type == "performance":
                impact["performance_improvement"] += item.priority_score
            elif item.issue_type == "code_quality":
                impact["code_quality_improvement"] += item.priority_score
            elif item.issue_type == "file_optimization":
                impact["maintainability_improvement"] += item.priority_score
        
        # è®¡ç®—æ•´ä½“æ”¶ç›Š
        impact["overall_benefit"] = (
            impact["security_improvement"] * 0.4 +
            impact["performance_improvement"] * 0.3 +
            impact["code_quality_improvement"] * 0.2 +
            impact["maintainability_improvement"] * 0.1
        )
        
        return impact
    
    async def _create_implementation_plan(self, optimization_items: List[OptimizationItem]) -> Dict[str, Any]:
        """åˆ›å»ºå®æ–½è®¡åˆ’"""
        plan = {
            "phases": [],
            "timeline": {},
            "milestones": [],
            "success_criteria": []
        }
        
        # åˆ†é˜¶æ®µè®¡åˆ’
        total_items = len(optimization_items)
        
        # ç¬¬ä¸€é˜¶æ®µï¼šé«˜ä¼˜å…ˆçº§é—®é¢˜
        high_priority_items = [item for item in optimization_items if item.severity == "high"]
        if high_priority_items:
            plan["phases"].append({
                "phase": 1,
                "name": "ç´§æ€¥ä¿®å¤",
                "duration": "1-2å‘¨",
                "items": high_priority_items[:10],  # é™åˆ¶æ•°é‡
                "focus": "å®‰å…¨é—®é¢˜å’Œé«˜ä¼˜å…ˆçº§é—®é¢˜"
            })
        
        # ç¬¬äºŒé˜¶æ®µï¼šæ€§èƒ½ä¼˜åŒ–
        performance_items = [item for item in optimization_items if item.issue_type == "performance"]
        if performance_items:
            plan["phases"].append({
                "phase": 2,
                "name": "æ€§èƒ½ä¼˜åŒ–",
                "duration": "2-3å‘¨",
                "items": performance_items[:10],
                "focus": "æ€§èƒ½ç“¶é¢ˆä¼˜åŒ–"
            })
        
        # ç¬¬ä¸‰é˜¶æ®µï¼šä»£ç è´¨é‡æå‡
        quality_items = [item for item in optimization_items if item.issue_type == "code_quality"]
        if quality_items:
            plan["phases"].append({
                "phase": 3,
                "name": "ä»£ç è´¨é‡æå‡",
                "duration": "3-4å‘¨",
                "items": quality_items[:20],
                "focus": "ä»£ç è´¨é‡å’Œå¯ç»´æŠ¤æ€§"
            })
        
        # æ—¶é—´çº¿
        plan["timeline"] = {
            "total_duration": f"{len(plan['phases']) * 2}-{len(plan['phases']) * 3}å‘¨",
            "start_date": datetime.now().strftime("%Y-%m-%d"),
            "estimated_completion": "åŸºäºé˜¶æ®µæŒç»­æ—¶é—´è®¡ç®—"
        }
        
        # é‡Œç¨‹ç¢‘
        for phase in plan["phases"]:
            plan["milestones"].append({
                "milestone": f"{phase['name']}å®Œæˆ",
                "criteria": f"æ‰€æœ‰{phase['name']}é¡¹ç›®å®Œæˆå¹¶æµ‹è¯•é€šè¿‡",
                "deliverables": f"{phase['name']}æŠ¥å‘Šå’Œä»£ç æ›´æ–°"
            })
        
        # æˆåŠŸæ ‡å‡†
        plan["success_criteria"] = [
            "æ‰€æœ‰é«˜ä¸¥é‡æ€§é—®é¢˜å·²è§£å†³",
            "æ€§èƒ½æŒ‡æ ‡æå‡20%ä»¥ä¸Š",
            "ä»£ç è´¨é‡è¯„åˆ†æå‡è‡³80åˆ†ä»¥ä¸Š",
            "æµ‹è¯•è¦†ç›–ç‡æå‡è‡³30%ä»¥ä¸Š",
            "ç³»ç»Ÿç¨³å®šæ€§æ˜¾è‘—æ”¹å–„"
        ]
        
        return plan
    
    async def _create_final_report(self, structure_analysis: Dict[str, Any],
                                 file_analyses: List[FileAnalysisResult],
                                 optimization_items: List[OptimizationItem],
                                 optimization_strategies: Dict[str, Any],
                                 impact_assessment: Dict[str, Any],
                                 implementation_plan: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºæœ€ç»ˆæŠ¥å‘Š"""
        report = {
            "metadata": {
                "generated_at": datetime.now().isoformat(),
                "project_root": str(self.project_root),
                "report_version": "1.0",
                "analysis_scope": "comprehensive"
            },
            "executive_summary": {
                "total_files_analyzed": len(file_analyses),
                "total_optimization_items": len(optimization_items),
                "high_priority_items": len([item for item in optimization_items if item.severity == "high"]),
                "estimated_effort": f"{len(optimization_items) * 0.5}äººå¤©",
                "overall_benefit_score": impact_assessment["overall_benefit"],
                "recommendation": "æŒ‰è®¡åˆ’åˆ†é˜¶æ®µå®æ–½ä¼˜åŒ–"
            },
            "structure_analysis": structure_analysis,
            "file_analyses": [asdict(analysis) for analysis in file_analyses],
            "optimization_items": [asdict(item) for item in optimization_items],
            "optimization_strategies": optimization_strategies,
            "impact_assessment": impact_assessment,
            "implementation_plan": implementation_plan,
            "conclusions_and_next_steps": [
                "é¡¹ç›®æ•´ä½“ç»“æ„è‰¯å¥½ï¼Œä½†å­˜åœ¨ä¼˜åŒ–ç©ºé—´",
                "å®‰å…¨é—®é¢˜éœ€è¦ä¼˜å…ˆå¤„ç†",
                "æ€§èƒ½ä¼˜åŒ–å¯ä»¥æ˜¾è‘—æå‡ç”¨æˆ·ä½“éªŒ",
                "ä»£ç è´¨é‡æ”¹è¿›æœ‰åŠ©äºé•¿æœŸç»´æŠ¤",
                "å»ºè®®æŒ‰ç…§å®æ–½è®¡åˆ’åˆ†é˜¶æ®µæ‰§è¡Œ"
            ]
        }
        
        return report
    
    async def _save_report(self, report: Dict[str, Any]):
        """ä¿å­˜æŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜JSONæŠ¥å‘Š
        json_file = self.reports_dir / f"optimization_report_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜MarkdownæŠ¥å‘Š
        markdown_file = self.reports_dir / f"optimization_report_{timestamp}.md"
        markdown_content = await self._generate_markdown_report(report)
        with open(markdown_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        print(f"ğŸ“„ ä¼˜åŒ–æŠ¥å‘Šå·²ä¿å­˜:")
        print(f"  JSON: {json_file}")
        print(f"  Markdown: {markdown_file}")
    
    async def _generate_markdown_report(self, report: Dict[str, Any]) -> str:
        """ç”ŸæˆMarkdownæŠ¥å‘Š"""
        content = []
        
        # æ ‡é¢˜
        content.append("# é¡¹ç›®ä¼˜åŒ–æŠ¥å‘Š")
        content.append(f"ç”Ÿæˆæ—¶é—´: {report['metadata']['generated_at']}")
        content.append("")
        
        # æ‰§è¡Œæ‘˜è¦
        content.append("## ğŸ“Š æ‰§è¡Œæ‘˜è¦")
        summary = report["executive_summary"]
        content.append(f"- åˆ†ææ–‡ä»¶æ€»æ•°: {summary['total_files_analyzed']}")
        content.append(f"- ä¼˜åŒ–é¡¹æ€»æ•°: {summary['total_optimization_items']}")
        content.append(f"- é«˜ä¼˜å…ˆçº§é¡¹: {summary['high_priority_items']}")
        content.append(f"- é¢„ä¼°å·¥ä½œé‡: {summary['estimated_effort']}")
        content.append(f"- æ•´ä½“æ”¶ç›Šè¯„åˆ†: {summary['overall_benefit_score']:.2f}")
        content.append(f"- æ€»ä½“å»ºè®®: {summary['recommendation']}")
        content.append("")
        
        # ç»“æ„åˆ†æ
        content.append("## ğŸ—ï¸ é¡¹ç›®ç»“æ„åˆ†æ")
        structure = report["structure_analysis"]
        content.append(f"- æ€»æ–‡ä»¶æ•°: {structure['total_files']}")
        content.append(f"- Pythonæ–‡ä»¶: {structure['python_files']}")
        content.append(f"- æµ‹è¯•æ–‡ä»¶: {structure['test_files']}")
        content.append(f"- é…ç½®æ–‡ä»¶: {structure['config_files']}")
        content.append(f"- æ–‡æ¡£æ–‡ä»¶: {structure['doc_files']}")
        content.append("")
        
        # ä¼˜åŒ–é¡¹ç»Ÿè®¡
        content.append("## ğŸ¯ ä¼˜åŒ–é¡¹ç»Ÿè®¡")
        items = report["optimization_items"]
        
        # æŒ‰ç±»å‹ç»Ÿè®¡
        type_counts = {}
        severity_counts = {}
        
        for item in items:
            type_counts[item["issue_type"]] = type_counts.get(item["issue_type"], 0) + 1
            severity_counts[item["severity"]] = severity_counts.get(item["severity"], 0) + 1
        
        content.append("### æŒ‰ç±»å‹åˆ†ç±»")
        for issue_type, count in type_counts.items():
            content.append(f"- {issue_type}: {count}ä¸ª")
        
        content.append("\n### æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç±»")
        for severity, count in severity_counts.items():
            content.append(f"- {severity}: {count}ä¸ª")
        content.append("")
        
        # é«˜ä¼˜å…ˆçº§é¡¹è¯¦æƒ…
        high_priority_items = [item for item in items if item["severity"] == "high"]
        if high_priority_items:
            content.append("## ğŸš¨ é«˜ä¼˜å…ˆçº§ä¼˜åŒ–é¡¹")
            for item in high_priority_items[:10]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                content.append(f"### {item['file_path']}")
                content.append(f"- **é—®é¢˜**: {item['description']}")
                content.append(f"- **å»ºè®®**: {item['recommendation']}")
                content.append(f"- **å½±å“**: {item['impact_assessment']}")
                content.append(f"- **ä¼˜å…ˆçº§**: {item['priority_score']:.2f}")
                content.append("")
        
        # å®æ–½è®¡åˆ’
        content.append("## ğŸ“‹ å®æ–½è®¡åˆ’")
        plan = report["implementation_plan"]
        
        content.append("### é˜¶æ®µè§„åˆ’")
        for phase in plan["phases"]:
            content.append(f"#### é˜¶æ®µ{phase['phase']}: {phase['name']}")
            content.append(f"- æŒç»­æ—¶é—´: {phase['duration']}")
            content.append(f"- é‡ç‚¹å…³æ³¨: {phase['focus']}")
            content.append(f"- é¡¹ç›®æ•°é‡: {len(phase['items'])}")
            content.append("")
        
        # æˆåŠŸæ ‡å‡†
        content.append("### æˆåŠŸæ ‡å‡†")
        for criteria in plan["success_criteria"]:
            content.append(f"- {criteria}")
        content.append("")
        
        # ç»“è®º
        content.append("## ğŸ¯ ç»“è®ºå’Œä¸‹ä¸€æ­¥")
        for conclusion in report["conclusions_and_next_steps"]:
            content.append(f"- {conclusion}")
        content.append("")
        
        return "\n".join(content)

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    """ä¸»å‡½æ•°"""
    project_root = "."
    
    generator = OptimizationReportGenerator(project_root)
    report = await generator.generate_comprehensive_report()
    
    print("ğŸ‰ ä¼˜åŒ–æŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
    print(f"ğŸ“Š åˆ†æäº† {report['executive_summary']['total_files_analyzed']} ä¸ªæ–‡ä»¶")
    print(f"ğŸ¯ å‘ç°äº† {report['executive_summary']['total_optimization_items']} ä¸ªä¼˜åŒ–é¡¹")
    print(f"âš ï¸ é«˜ä¼˜å…ˆçº§é¡¹: {report['executive_summary']['high_priority_items']} ä¸ª")

if __name__ == "__main__":
    asyncio.run(main())